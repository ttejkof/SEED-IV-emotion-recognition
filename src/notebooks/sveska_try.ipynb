{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import scipy\n",
    "import scipy.io\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import optuna\n",
    "\n",
    "from utils import load_dataset, flatten_data, select_emotions, train_test_split\n",
    "from utils import Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Emotion 0 vs 1: 0.5135449735449735\n",
      "Emotion 0 vs 2: 0.5143253968253968\n",
      "Emotion 0 vs 3: 0.5226587301587301\n",
      "Emotion 1 vs 2: 0.5139814814814815\n",
      "Emotion 1 vs 3: 0.5307275132275132\n",
      "Emotion 2 vs 3: 0.5310317460317461\n"
     ]
    }
   ],
   "source": [
    "data, labels, groups = load_dataset(\"all_features_4sec_epoch.npy\")\n",
    "data, labels, groups = flatten_data(data, labels, groups)\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(data)\n",
    "data = scaler.transform(data)\n",
    "for em1 in range(4):\n",
    "    for em2 in range(em1+1, 4):\n",
    "        accs = []\n",
    "        for human_test in range(15):\n",
    "            e_data, e_labels, e_groups = select_emotions(data, labels, groups, em1, em2)\n",
    "            train_data, train_labels, test_data, test_labels = train_test_split(e_data, e_labels, e_groups, human_test)\n",
    "\n",
    "            xgboost = XGBClassifier()\n",
    "            xgboost.fit(train_data, train_labels)\n",
    "            pred = xgboost.predict(test_data)\n",
    "            acc = accuracy_score(test_labels, pred)\n",
    "            accs.append(acc)\n",
    "        print(f\"Emotion {em1} vs {em2}: {np.mean(accs)}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data, labels, groups = load_dataset(\"all_features_4sec_epoch.npy\")\n",
    "data, labels, groups = flatten_data(data, labels, groups)\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(data)\n",
    "data = scaler.transform(data)\n",
    "for em1 in range(4):\n",
    "    for em2 in range(em1+1, 4):\n",
    "        accs = []\n",
    "        for human_test in range(15):\n",
    "            e_data, e_labels, e_groups = select_emotions(data, labels, groups, em1, em2)\n",
    "            train_data, train_labels, test_data, test_labels = train_test_split(e_data, e_labels, e_groups, human_test)\n",
    "\n",
    "            knn = KNeighborsClassifier(n_neighbors=10)\n",
    "            knn.fit(train_data, train_labels)\n",
    "            pred = knn.predict(test_data)\n",
    "            acc = accuracy_score(test_labels, pred)\n",
    "            accs.append(acc)\n",
    "        print(f\"Emotion {em1} vs {em2}: {np.mean(accs)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Emotion 0 vs 1: 0.5132407407407408\n",
      "Emotion 0 vs 2: 0.5143518518518518\n",
      "Emotion 0 vs 3: 0.5098809523809523\n",
      "Emotion 1 vs 2: 0.5104629629629629\n",
      "Emotion 1 vs 3: 0.5152777777777777\n",
      "Emotion 2 vs 3: 0.505925925925926\n"
     ]
    }
   ],
   "source": [
    "data, labels, groups = load_dataset(\"all_features_4sec_epoch.npy\")\n",
    "data, labels, groups = flatten_data(data, labels, groups)\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(data)\n",
    "data = scaler.transform(data)\n",
    "\n",
    "pca = PCA(n_components=10)\n",
    "pca.fit(data)\n",
    "data = pca.transform(data)\n",
    "\n",
    "for em1 in range(4):\n",
    "    for em2 in range(em1+1, 4):\n",
    "        accs = []\n",
    "        for human_test in range(15):\n",
    "            e_data, e_labels, e_groups = select_emotions(data, labels, groups, em1, em2)\n",
    "            train_data, train_labels, test_data, test_labels = train_test_split(e_data, e_labels, e_groups, human_test)\n",
    "\n",
    "            knn = KNeighborsClassifier(n_neighbors=10)\n",
    "            knn.fit(train_data, train_labels)\n",
    "            pred = knn.predict(test_data)\n",
    "            acc = accuracy_score(test_labels, pred)\n",
    "            accs.append(acc)\n",
    "        print(f\"Emotion {em1} vs {em2}: {np.mean(accs)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5400, 2480)\n"
     ]
    }
   ],
   "source": [
    "data, labels, groups = load_dataset(\"all_features_4sec_epoch.npy\")\n",
    "data, labels, groups = flatten_data(data, labels, groups)\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(data)\n",
    "data = scaler.transform(data)\n",
    "\n",
    "data, labels, groups = select_emotions(data, labels, groups, 0, 2)\n",
    "\n",
    "train_data, train_labels, test_data, test_labels = train_test_split(data, labels, groups, 0)\n",
    "\n",
    "print(data.shape)\n",
    "\n",
    "data_tensor = torch.tensor(train_data, dtype=torch.float32)\n",
    "data_labels = torch.tensor(train_labels, dtype=torch.float32)[..., None]\n",
    "batch_size = 1024\n",
    "dataset = TensorDataset(data_tensor, data_labels)\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "test_data_tensor = torch.tensor(test_data, dtype=torch.float32)\n",
    "test_labels = torch.tensor(test_labels, dtype=torch.float32)[..., None]\n",
    "\n",
    "# Initialize the autoencoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    batch_size = trial.suggest_int('batch_size', 128, 2048)\n",
    "    lr = trial.suggest_float('lr', 1e-6, 1e-2, log=True)\n",
    "    input_dim = data.shape[1]\n",
    "    encoding_dim = 128  # Set the desired encoding dimension\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "    autoencoder = Autoencoder(input_dim, encoding_dim)\n",
    "\n",
    "    # Initialize weights of the autoencoder\n",
    "    def init_weights(m):\n",
    "        if type(m) == torch.nn.Linear:\n",
    "            torch.nn.init.xavier_uniform_(m.weight)\n",
    "            m.bias.data.fill_(0.01)\n",
    "    autoencoder.apply(init_weights)\n",
    "\n",
    "    # Loss function and optimizer\n",
    "    criterion_enc = torch.nn.MSELoss()\n",
    "    criterion_cls = torch.nn.BCELoss()\n",
    "    optimizer = optim.Adam(autoencoder.parameters(), lr=lr)\n",
    "\n",
    "    # Training loop\n",
    "    num_epochs = 50\n",
    "    best_acc = 0\n",
    "    for epoch in range(num_epochs):\n",
    "        for data_batch, labels_batch in dataloader:\n",
    "            reconstructed, cls = autoencoder(data_batch)\n",
    "            loss1 = criterion_cls(cls, labels_batch) * 0.1\n",
    "            loss2 = criterion_enc(reconstructed, data_batch) \n",
    "            loss = loss1 + loss2\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            reconstructed, cls = autoencoder(data_tensor)\n",
    "            cls = cls > 0.5\n",
    "            train_acc = torch.sum(cls == data_labels) / data_labels.shape[0]\n",
    "            # test acc\n",
    "\n",
    "            reconstructed, cls = autoencoder(test_data_tensor)\n",
    "            cls = cls > 0.5\n",
    "            test_acc = torch.sum(cls == test_labels) / test_labels.shape[0]\n",
    "            if epoch > 15 and test_acc < 0.5:\n",
    "                break\n",
    "            if test_acc > best_acc:\n",
    "                best_acc = test_acc\n",
    "                print(f\"New best acc: {best_acc} epoch {epoch}\")\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}, Train Acc: {train_acc.item()}, Test Acc: {test_acc.item()}')\n",
    "    return best_acc\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-04 00:37:09,772] A new study created in memory with name: no-name-5361f203-13bd-47e1-8e26-fc05af1ad764\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best acc: 0.5123015642166138 epoch 0\n",
      "Epoch [1/50], Loss: 0.8480, Train Acc: 0.5333333611488342, Test Acc: 0.5123015642166138\n",
      "Epoch [2/50], Loss: 0.8454, Train Acc: 0.49166667461395264, Test Acc: 0.5021825432777405\n",
      "Epoch [3/50], Loss: 0.8340, Train Acc: 0.5444444417953491, Test Acc: 0.5051587224006653\n",
      "Epoch [4/50], Loss: 0.8302, Train Acc: 0.5083333253860474, Test Acc: 0.4968253970146179\n",
      "Epoch [5/50], Loss: 0.8224, Train Acc: 0.5222222208976746, Test Acc: 0.5019841194152832\n",
      "Epoch [6/50], Loss: 0.8277, Train Acc: 0.4972222149372101, Test Acc: 0.49861112236976624\n",
      "New best acc: 0.5174603462219238 epoch 6\n",
      "Epoch [7/50], Loss: 0.8191, Train Acc: 0.5222222208976746, Test Acc: 0.5174603462219238\n",
      "Epoch [8/50], Loss: 0.8142, Train Acc: 0.5416666865348816, Test Acc: 0.509325385093689\n",
      "Epoch [9/50], Loss: 0.8099, Train Acc: 0.519444465637207, Test Acc: 0.5134920477867126\n",
      "Epoch [10/50], Loss: 0.8016, Train Acc: 0.5055555701255798, Test Acc: 0.5067460536956787\n",
      "Epoch [11/50], Loss: 0.8056, Train Acc: 0.5083333253860474, Test Acc: 0.49940475821495056\n",
      "Epoch [12/50], Loss: 0.7977, Train Acc: 0.5416666865348816, Test Acc: 0.4982142746448517\n",
      "New best acc: 0.5204365253448486 epoch 12\n",
      "Epoch [13/50], Loss: 0.7957, Train Acc: 0.5361111164093018, Test Acc: 0.5204365253448486\n",
      "Epoch [14/50], Loss: 0.7904, Train Acc: 0.4972222149372101, Test Acc: 0.5128968358039856\n",
      "Epoch [15/50], Loss: 0.7775, Train Acc: 0.5166666507720947, Test Acc: 0.4950396716594696\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-04 00:37:13,148] Trial 0 finished with value: 0.5204365253448486 and parameters: {'batch_size': 901, 'lr': 6.302275618557322e-05}. Best is trial 0 with value: 0.5204365253448486.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [16/50], Loss: 0.7750, Train Acc: 0.5416666865348816, Test Acc: 0.5152778029441833\n",
      "New best acc: 0.5017856955528259 epoch 0\n",
      "Epoch [1/50], Loss: 0.8442, Train Acc: 0.5083333253860474, Test Acc: 0.5017856955528259\n",
      "New best acc: 0.5063492059707642 epoch 1\n",
      "Epoch [2/50], Loss: 0.7707, Train Acc: 0.5222222208976746, Test Acc: 0.5063492059707642\n",
      "Epoch [3/50], Loss: 0.7359, Train Acc: 0.5, Test Acc: 0.49960318207740784\n",
      "Epoch [4/50], Loss: 0.7169, Train Acc: 0.5916666388511658, Test Acc: 0.5039682388305664\n",
      "Epoch [5/50], Loss: 0.6868, Train Acc: 0.5666666626930237, Test Acc: 0.5051587224006653\n",
      "New best acc: 0.5178571343421936 epoch 5\n",
      "Epoch [6/50], Loss: 0.6683, Train Acc: 0.5611110925674438, Test Acc: 0.5178571343421936\n",
      "Epoch [7/50], Loss: 0.6395, Train Acc: 0.6083333492279053, Test Acc: 0.5089285969734192\n",
      "Epoch [8/50], Loss: 0.6327, Train Acc: 0.6361111402511597, Test Acc: 0.5172619223594666\n",
      "New best acc: 0.5281745791435242 epoch 8\n",
      "Epoch [9/50], Loss: 0.6245, Train Acc: 0.625, Test Acc: 0.5281745791435242\n",
      "Epoch [10/50], Loss: 0.5992, Train Acc: 0.6472222208976746, Test Acc: 0.5142857432365417\n",
      "Epoch [11/50], Loss: 0.5994, Train Acc: 0.6805555820465088, Test Acc: 0.5263888835906982\n",
      "Epoch [12/50], Loss: 0.5898, Train Acc: 0.7111111283302307, Test Acc: 0.5257936716079712\n",
      "New best acc: 0.5355158448219299 epoch 12\n",
      "Epoch [13/50], Loss: 0.5826, Train Acc: 0.6972222328186035, Test Acc: 0.5355158448219299\n",
      "New best acc: 0.5400793552398682 epoch 13\n",
      "Epoch [14/50], Loss: 0.5781, Train Acc: 0.7555555701255798, Test Acc: 0.5400793552398682\n",
      "New best acc: 0.5434523820877075 epoch 14\n",
      "Epoch [15/50], Loss: 0.5688, Train Acc: 0.7444444298744202, Test Acc: 0.5434523820877075\n",
      "Epoch [16/50], Loss: 0.5656, Train Acc: 0.7277777791023254, Test Acc: 0.5378968119621277\n",
      "Epoch [17/50], Loss: 0.5635, Train Acc: 0.7416666746139526, Test Acc: 0.5382936596870422\n",
      "New best acc: 0.5458333492279053 epoch 17\n",
      "Epoch [18/50], Loss: 0.5489, Train Acc: 0.7972221970558167, Test Acc: 0.5458333492279053\n",
      "Epoch [19/50], Loss: 0.5475, Train Acc: 0.8083333373069763, Test Acc: 0.5390872955322266\n",
      "Epoch [20/50], Loss: 0.5426, Train Acc: 0.8111110925674438, Test Acc: 0.541269838809967\n",
      "Epoch [21/50], Loss: 0.5434, Train Acc: 0.8500000238418579, Test Acc: 0.5426587462425232\n",
      "New best acc: 0.5561507940292358 epoch 21\n",
      "Epoch [22/50], Loss: 0.5302, Train Acc: 0.8666666746139526, Test Acc: 0.5561507940292358\n",
      "Epoch [23/50], Loss: 0.5245, Train Acc: 0.8388888835906982, Test Acc: 0.5555555820465088\n",
      "Epoch [24/50], Loss: 0.5186, Train Acc: 0.8833333253860474, Test Acc: 0.5478174686431885\n",
      "New best acc: 0.5565476417541504 epoch 24\n",
      "Epoch [25/50], Loss: 0.5179, Train Acc: 0.8666666746139526, Test Acc: 0.5565476417541504\n",
      "Epoch [26/50], Loss: 0.5156, Train Acc: 0.9194444417953491, Test Acc: 0.5527777671813965\n",
      "New best acc: 0.5646825432777405 epoch 26\n",
      "Epoch [27/50], Loss: 0.5084, Train Acc: 0.9166666865348816, Test Acc: 0.5646825432777405\n",
      "Epoch [28/50], Loss: 0.5020, Train Acc: 0.9138888716697693, Test Acc: 0.5537698268890381\n",
      "Epoch [29/50], Loss: 0.5011, Train Acc: 0.9416666626930237, Test Acc: 0.543055534362793\n",
      "Epoch [30/50], Loss: 0.4953, Train Acc: 0.9333333373069763, Test Acc: 0.5484126806259155\n",
      "Epoch [31/50], Loss: 0.4892, Train Acc: 0.9583333134651184, Test Acc: 0.5464285612106323\n",
      "Epoch [32/50], Loss: 0.4818, Train Acc: 0.9361110925674438, Test Acc: 0.5466269850730896\n",
      "Epoch [33/50], Loss: 0.4839, Train Acc: 0.9750000238418579, Test Acc: 0.5597222447395325\n",
      "Epoch [34/50], Loss: 0.4782, Train Acc: 0.9777777791023254, Test Acc: 0.5460317730903625\n",
      "Epoch [35/50], Loss: 0.4725, Train Acc: 0.980555534362793, Test Acc: 0.5521825551986694\n",
      "Epoch [36/50], Loss: 0.4705, Train Acc: 0.9611111283302307, Test Acc: 0.550595223903656\n",
      "Epoch [37/50], Loss: 0.4711, Train Acc: 0.9916666746139526, Test Acc: 0.5609126687049866\n",
      "Epoch [38/50], Loss: 0.4645, Train Acc: 0.9777777791023254, Test Acc: 0.550595223903656\n",
      "Epoch [39/50], Loss: 0.4618, Train Acc: 0.9861111044883728, Test Acc: 0.5551587343215942\n",
      "Epoch [40/50], Loss: 0.4590, Train Acc: 0.9888888597488403, Test Acc: 0.5646825432777405\n",
      "Epoch [41/50], Loss: 0.4598, Train Acc: 0.9861111044883728, Test Acc: 0.5577380657196045\n",
      "Epoch [42/50], Loss: 0.4575, Train Acc: 0.9916666746139526, Test Acc: 0.5591269731521606\n",
      "Epoch [43/50], Loss: 0.4561, Train Acc: 0.9916666746139526, Test Acc: 0.5496031641960144\n",
      "Epoch [44/50], Loss: 0.4527, Train Acc: 0.9944444298744202, Test Acc: 0.5625\n",
      "Epoch [45/50], Loss: 0.4517, Train Acc: 0.9916666746139526, Test Acc: 0.5603174567222595\n",
      "Epoch [46/50], Loss: 0.4516, Train Acc: 0.9944444298744202, Test Acc: 0.5498015880584717\n",
      "Epoch [47/50], Loss: 0.4520, Train Acc: 0.9972222447395325, Test Acc: 0.5492063760757446\n",
      "Epoch [48/50], Loss: 0.4433, Train Acc: 0.9944444298744202, Test Acc: 0.5547618865966797\n",
      "Epoch [49/50], Loss: 0.4437, Train Acc: 1.0, Test Acc: 0.5591269731521606\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-04 00:37:24,140] Trial 1 finished with value: 0.5646825432777405 and parameters: {'batch_size': 1422, 'lr': 0.0010608231272589844}. Best is trial 1 with value: 0.5646825432777405.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [50/50], Loss: 0.4431, Train Acc: 0.9916666746139526, Test Acc: 0.5607143044471741\n",
      "New best acc: 0.5029761791229248 epoch 0\n",
      "Epoch [1/50], Loss: 0.8539, Train Acc: 0.519444465637207, Test Acc: 0.5029761791229248\n",
      "New best acc: 0.5045635104179382 epoch 1\n",
      "Epoch [2/50], Loss: 0.8521, Train Acc: 0.5277777910232544, Test Acc: 0.5045635104179382\n",
      "Epoch [3/50], Loss: 0.8450, Train Acc: 0.49444442987442017, Test Acc: 0.4920634925365448\n",
      "Epoch [4/50], Loss: 0.8502, Train Acc: 0.4555555582046509, Test Acc: 0.49761903285980225\n",
      "Epoch [5/50], Loss: 0.8530, Train Acc: 0.5305555462837219, Test Acc: 0.4932539761066437\n",
      "New best acc: 0.5079365372657776 epoch 5\n",
      "Epoch [6/50], Loss: 0.8514, Train Acc: 0.5361111164093018, Test Acc: 0.5079365372657776\n",
      "Epoch [7/50], Loss: 0.8568, Train Acc: 0.49166667461395264, Test Acc: 0.504365086555481\n",
      "Epoch [8/50], Loss: 0.8453, Train Acc: 0.5277777910232544, Test Acc: 0.49146825075149536\n",
      "Epoch [9/50], Loss: 0.8435, Train Acc: 0.48055556416511536, Test Acc: 0.49761903285980225\n",
      "Epoch [10/50], Loss: 0.8440, Train Acc: 0.5, Test Acc: 0.49742063879966736\n",
      "Epoch [11/50], Loss: 0.8488, Train Acc: 0.49166667461395264, Test Acc: 0.5063492059707642\n",
      "Epoch [12/50], Loss: 0.8479, Train Acc: 0.5222222208976746, Test Acc: 0.48174601793289185\n",
      "Epoch [13/50], Loss: 0.8400, Train Acc: 0.4305555522441864, Test Acc: 0.4952380955219269\n",
      "Epoch [14/50], Loss: 0.8464, Train Acc: 0.5055555701255798, Test Acc: 0.5019841194152832\n",
      "New best acc: 0.5172619223594666 epoch 14\n",
      "Epoch [15/50], Loss: 0.8419, Train Acc: 0.5333333611488342, Test Acc: 0.5172619223594666\n",
      "New best acc: 0.5210317373275757 epoch 15\n",
      "Epoch [16/50], Loss: 0.8384, Train Acc: 0.5249999761581421, Test Acc: 0.5210317373275757\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-04 00:37:27,592] Trial 2 finished with value: 0.5210317373275757 and parameters: {'batch_size': 1270, 'lr': 7.0778063412968455e-06}. Best is trial 1 with value: 0.5646825432777405.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best acc: 0.5099206566810608 epoch 0\n",
      "Epoch [1/50], Loss: 0.8461, Train Acc: 0.5611110925674438, Test Acc: 0.5099206566810608\n",
      "New best acc: 0.5182539820671082 epoch 1\n",
      "Epoch [2/50], Loss: 1.1271, Train Acc: 0.5944444537162781, Test Acc: 0.5182539820671082\n",
      "Epoch [3/50], Loss: 0.6908, Train Acc: 0.644444465637207, Test Acc: 0.5176587104797363\n",
      "New best acc: 0.5283730030059814 epoch 3\n",
      "Epoch [4/50], Loss: 0.6258, Train Acc: 0.5972222089767456, Test Acc: 0.5283730030059814\n",
      "New best acc: 0.5305555462837219 epoch 4\n",
      "Epoch [5/50], Loss: 0.6332, Train Acc: 0.6361111402511597, Test Acc: 0.5305555462837219\n",
      "Epoch [6/50], Loss: 0.6514, Train Acc: 0.6944444179534912, Test Acc: 0.5281745791435242\n",
      "Epoch [7/50], Loss: 0.6340, Train Acc: 0.6861110925674438, Test Acc: 0.5269841551780701\n",
      "New best acc: 0.5390872955322266 epoch 7\n",
      "Epoch [8/50], Loss: 0.6025, Train Acc: 0.7250000238418579, Test Acc: 0.5390872955322266\n",
      "Epoch [9/50], Loss: 0.5872, Train Acc: 0.7749999761581421, Test Acc: 0.5279762148857117\n",
      "Epoch [10/50], Loss: 0.5692, Train Acc: 0.8500000238418579, Test Acc: 0.538095235824585\n",
      "New best acc: 0.554960310459137 epoch 10\n",
      "Epoch [11/50], Loss: 0.5509, Train Acc: 0.8388888835906982, Test Acc: 0.554960310459137\n",
      "Epoch [12/50], Loss: 0.5470, Train Acc: 0.8361111283302307, Test Acc: 0.5539682507514954\n",
      "Epoch [13/50], Loss: 0.5362, Train Acc: 0.8805555701255798, Test Acc: 0.5547618865966797\n",
      "New best acc: 0.5652777552604675 epoch 13\n",
      "Epoch [14/50], Loss: 0.5299, Train Acc: 0.9083333611488342, Test Acc: 0.5652777552604675\n",
      "Epoch [15/50], Loss: 0.5199, Train Acc: 0.8972222208976746, Test Acc: 0.5563492178916931\n",
      "Epoch [16/50], Loss: 0.5049, Train Acc: 0.9277777671813965, Test Acc: 0.5498015880584717\n",
      "Epoch [17/50], Loss: 0.5032, Train Acc: 0.9416666626930237, Test Acc: 0.5464285612106323\n",
      "Epoch [18/50], Loss: 0.4935, Train Acc: 0.9638888835906982, Test Acc: 0.5507936477661133\n",
      "Epoch [19/50], Loss: 0.4895, Train Acc: 0.9722222089767456, Test Acc: 0.5503968000411987\n",
      "Epoch [20/50], Loss: 0.4900, Train Acc: 0.9694444537162781, Test Acc: 0.5603174567222595\n",
      "Epoch [21/50], Loss: 0.4765, Train Acc: 0.9888888597488403, Test Acc: 0.5547618865966797\n",
      "Epoch [22/50], Loss: 0.4781, Train Acc: 0.9861111044883728, Test Acc: 0.5551587343215942\n",
      "Epoch [23/50], Loss: 0.4794, Train Acc: 0.9944444298744202, Test Acc: 0.5589285492897034\n",
      "Epoch [24/50], Loss: 0.4669, Train Acc: 0.9916666746139526, Test Acc: 0.5513888597488403\n",
      "Epoch [25/50], Loss: 0.4625, Train Acc: 0.9861111044883728, Test Acc: 0.5547618865966797\n",
      "Epoch [26/50], Loss: 0.4626, Train Acc: 0.9916666746139526, Test Acc: 0.5559523701667786\n",
      "Epoch [27/50], Loss: 0.4608, Train Acc: 0.9944444298744202, Test Acc: 0.5547618865966797\n",
      "Epoch [28/50], Loss: 0.4529, Train Acc: 0.9833333492279053, Test Acc: 0.5567460060119629\n",
      "Epoch [29/50], Loss: 0.4571, Train Acc: 0.9888888597488403, Test Acc: 0.558134913444519\n",
      "Epoch [30/50], Loss: 0.4586, Train Acc: 0.9944444298744202, Test Acc: 0.5555555820465088\n",
      "Epoch [31/50], Loss: 0.4553, Train Acc: 0.9972222447395325, Test Acc: 0.5422618985176086\n",
      "Epoch [32/50], Loss: 0.4462, Train Acc: 0.9972222447395325, Test Acc: 0.5551587343215942\n",
      "Epoch [33/50], Loss: 0.4417, Train Acc: 1.0, Test Acc: 0.5515872836112976\n",
      "Epoch [34/50], Loss: 0.4488, Train Acc: 1.0, Test Acc: 0.553174614906311\n",
      "Epoch [35/50], Loss: 0.4377, Train Acc: 0.9944444298744202, Test Acc: 0.5472221970558167\n",
      "Epoch [36/50], Loss: 0.4482, Train Acc: 0.9972222447395325, Test Acc: 0.557539701461792\n",
      "Epoch [37/50], Loss: 0.4444, Train Acc: 0.9972222447395325, Test Acc: 0.5533730387687683\n",
      "Epoch [38/50], Loss: 0.4389, Train Acc: 0.9944444298744202, Test Acc: 0.5628968477249146\n",
      "Epoch [39/50], Loss: 0.4308, Train Acc: 1.0, Test Acc: 0.5593253970146179\n",
      "Epoch [40/50], Loss: 0.4302, Train Acc: 0.9972222447395325, Test Acc: 0.5577380657196045\n",
      "Epoch [41/50], Loss: 0.4539, Train Acc: 0.9972222447395325, Test Acc: 0.558134913444519\n",
      "Epoch [42/50], Loss: 0.4269, Train Acc: 1.0, Test Acc: 0.5613095164299011\n",
      "Epoch [43/50], Loss: 0.4296, Train Acc: 0.9944444298744202, Test Acc: 0.5547618865966797\n",
      "Epoch [44/50], Loss: 0.4261, Train Acc: 0.9972222447395325, Test Acc: 0.553174614906311\n",
      "Epoch [45/50], Loss: 0.4224, Train Acc: 0.9972222447395325, Test Acc: 0.5513888597488403\n",
      "Epoch [46/50], Loss: 0.4235, Train Acc: 0.9972222447395325, Test Acc: 0.5515872836112976\n",
      "Epoch [47/50], Loss: 0.4224, Train Acc: 1.0, Test Acc: 0.5597222447395325\n",
      "Epoch [48/50], Loss: 0.4277, Train Acc: 1.0, Test Acc: 0.5525793433189392\n",
      "Epoch [49/50], Loss: 0.4169, Train Acc: 0.9944444298744202, Test Acc: 0.5547618865966797\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-04 00:37:37,748] Trial 3 finished with value: 0.5652777552604675 and parameters: {'batch_size': 1315, 'lr': 0.006184819544441288}. Best is trial 3 with value: 0.5652777552604675.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [50/50], Loss: 0.4159, Train Acc: 0.9972222447395325, Test Acc: 0.5507936477661133\n",
      "New best acc: 0.49563491344451904 epoch 0\n",
      "Epoch [1/50], Loss: 0.8060, Train Acc: 0.5222222208976746, Test Acc: 0.49563491344451904\n",
      "New best acc: 0.5041666626930237 epoch 1\n",
      "Epoch [2/50], Loss: 0.8550, Train Acc: 0.5249999761581421, Test Acc: 0.5041666626930237\n",
      "New best acc: 0.5077381134033203 epoch 2\n",
      "Epoch [3/50], Loss: 0.8055, Train Acc: 0.519444465637207, Test Acc: 0.5077381134033203\n",
      "Epoch [4/50], Loss: 0.8420, Train Acc: 0.5361111164093018, Test Acc: 0.49960318207740784\n",
      "Epoch [5/50], Loss: 0.7148, Train Acc: 0.4694444537162781, Test Acc: 0.49742063879966736\n",
      "Epoch [6/50], Loss: 0.6967, Train Acc: 0.5277777910232544, Test Acc: 0.4982142746448517\n",
      "Epoch [7/50], Loss: 0.9006, Train Acc: 0.5277777910232544, Test Acc: 0.48869046568870544\n",
      "Epoch [8/50], Loss: 0.7812, Train Acc: 0.5249999761581421, Test Acc: 0.5045635104179382\n",
      "Epoch [9/50], Loss: 0.6898, Train Acc: 0.5166666507720947, Test Acc: 0.49563491344451904\n",
      "Epoch [10/50], Loss: 0.6712, Train Acc: 0.5027777552604675, Test Acc: 0.4980158805847168\n",
      "Epoch [11/50], Loss: 0.6262, Train Acc: 0.5027777552604675, Test Acc: 0.49563491344451904\n",
      "Epoch [12/50], Loss: 0.6974, Train Acc: 0.5638889074325562, Test Acc: 0.494047611951828\n",
      "Epoch [13/50], Loss: 0.9072, Train Acc: 0.5305555462837219, Test Acc: 0.49365079402923584\n",
      "Epoch [14/50], Loss: 0.8566, Train Acc: 0.46388888359069824, Test Acc: 0.4948412775993347\n",
      "New best acc: 0.5132936239242554 epoch 14\n",
      "Epoch [15/50], Loss: 0.6907, Train Acc: 0.5583333373069763, Test Acc: 0.5132936239242554\n",
      "Epoch [16/50], Loss: 0.6396, Train Acc: 0.4694444537162781, Test Acc: 0.5130952596664429\n",
      "Epoch [17/50], Loss: 0.7318, Train Acc: 0.5166666507720947, Test Acc: 0.5055555701255798\n",
      "Epoch [18/50], Loss: 1.1990, Train Acc: 0.4888888895511627, Test Acc: 0.5111111402511597\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-04 00:37:42,027] Trial 4 finished with value: 0.5132936239242554 and parameters: {'batch_size': 307, 'lr': 4.701942139846833e-05}. Best is trial 3 with value: 0.5652777552604675.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best acc: 0.4948412775993347 epoch 0\n",
      "Epoch [1/50], Loss: 0.8484, Train Acc: 0.4833333194255829, Test Acc: 0.4948412775993347\n",
      "Epoch [2/50], Loss: 0.8517, Train Acc: 0.519444465637207, Test Acc: 0.49365079402923584\n",
      "New best acc: 0.5017856955528259 epoch 2\n",
      "Epoch [3/50], Loss: 0.8530, Train Acc: 0.5305555462837219, Test Acc: 0.5017856955528259\n",
      "Epoch [4/50], Loss: 0.8465, Train Acc: 0.4749999940395355, Test Acc: 0.49940475821495056\n",
      "Epoch [5/50], Loss: 0.8475, Train Acc: 0.5027777552604675, Test Acc: 0.488095223903656\n",
      "New best acc: 0.5083333253860474 epoch 5\n",
      "Epoch [6/50], Loss: 0.8457, Train Acc: 0.5333333611488342, Test Acc: 0.5083333253860474\n",
      "Epoch [7/50], Loss: 0.8473, Train Acc: 0.4861111044883728, Test Acc: 0.4978174567222595\n",
      "Epoch [8/50], Loss: 0.8506, Train Acc: 0.5, Test Acc: 0.4882936477661133\n",
      "Epoch [9/50], Loss: 0.8525, Train Acc: 0.5055555701255798, Test Acc: 0.4998015761375427\n",
      "Epoch [10/50], Loss: 0.8562, Train Acc: 0.4611110985279083, Test Acc: 0.49761903285980225\n",
      "Epoch [11/50], Loss: 0.8440, Train Acc: 0.4583333432674408, Test Acc: 0.49047619104385376\n",
      "Epoch [12/50], Loss: 0.8504, Train Acc: 0.5388888716697693, Test Acc: 0.4950396716594696\n",
      "Epoch [13/50], Loss: 0.8476, Train Acc: 0.49444442987442017, Test Acc: 0.5017856955528259\n",
      "Epoch [14/50], Loss: 0.8447, Train Acc: 0.5416666865348816, Test Acc: 0.49563491344451904\n",
      "Epoch [15/50], Loss: 0.8491, Train Acc: 0.5, Test Acc: 0.5037698149681091\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-04 00:37:45,567] Trial 5 finished with value: 0.5083333253860474 and parameters: {'batch_size': 799, 'lr': 4.674023170495918e-06}. Best is trial 3 with value: 0.5652777552604675.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [16/50], Loss: 0.8428, Train Acc: 0.48055556416511536, Test Acc: 0.49047619104385376\n",
      "New best acc: 0.5029761791229248 epoch 0\n",
      "Epoch [1/50], Loss: 0.8551, Train Acc: 0.4972222149372101, Test Acc: 0.5029761791229248\n",
      "Epoch [2/50], Loss: 0.8576, Train Acc: 0.5055555701255798, Test Acc: 0.49642857909202576\n",
      "Epoch [3/50], Loss: 0.8562, Train Acc: 0.4861111044883728, Test Acc: 0.4998015761375427\n",
      "Epoch [4/50], Loss: 0.8503, Train Acc: 0.5333333611488342, Test Acc: 0.49940475821495056\n",
      "Epoch [5/50], Loss: 0.8780, Train Acc: 0.5083333253860474, Test Acc: 0.48908731341362\n",
      "Epoch [6/50], Loss: 0.8574, Train Acc: 0.519444465637207, Test Acc: 0.5\n",
      "Epoch [7/50], Loss: 0.8429, Train Acc: 0.4888888895511627, Test Acc: 0.502579391002655\n",
      "Epoch [8/50], Loss: 0.8480, Train Acc: 0.47777777910232544, Test Acc: 0.49940475821495056\n",
      "New best acc: 0.5031746029853821 epoch 8\n",
      "Epoch [9/50], Loss: 0.8462, Train Acc: 0.5472221970558167, Test Acc: 0.5031746029853821\n",
      "Epoch [10/50], Loss: 0.8468, Train Acc: 0.550000011920929, Test Acc: 0.4928571283817291\n",
      "Epoch [11/50], Loss: 0.8436, Train Acc: 0.5055555701255798, Test Acc: 0.4922619163990021\n",
      "New best acc: 0.5053571462631226 epoch 11\n",
      "Epoch [12/50], Loss: 0.8457, Train Acc: 0.4722222089767456, Test Acc: 0.5053571462631226\n",
      "Epoch [13/50], Loss: 0.8396, Train Acc: 0.5138888955116272, Test Acc: 0.5045635104179382\n",
      "Epoch [14/50], Loss: 0.8388, Train Acc: 0.5305555462837219, Test Acc: 0.5029761791229248\n",
      "Epoch [15/50], Loss: 0.8372, Train Acc: 0.4972222149372101, Test Acc: 0.5045635104179382\n",
      "Epoch [16/50], Loss: 0.8323, Train Acc: 0.5111111402511597, Test Acc: 0.5037698149681091\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-04 00:37:49,003] Trial 6 finished with value: 0.5053571462631226 and parameters: {'batch_size': 855, 'lr': 1.4226441269704264e-05}. Best is trial 3 with value: 0.5652777552604675.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best acc: 0.5009920597076416 epoch 0\n",
      "Epoch [1/50], Loss: 0.8557, Train Acc: 0.5249999761581421, Test Acc: 0.5009920597076416\n",
      "Epoch [2/50], Loss: 0.8467, Train Acc: 0.5222222208976746, Test Acc: 0.48650792241096497\n",
      "New best acc: 0.5083333253860474 epoch 2\n",
      "Epoch [3/50], Loss: 0.8512, Train Acc: 0.5472221970558167, Test Acc: 0.5083333253860474\n",
      "Epoch [4/50], Loss: 0.8452, Train Acc: 0.5138888955116272, Test Acc: 0.49563491344451904\n",
      "Epoch [5/50], Loss: 0.8424, Train Acc: 0.4888888895511627, Test Acc: 0.49563491344451904\n",
      "New best acc: 0.5091269612312317 epoch 5\n",
      "Epoch [6/50], Loss: 0.8306, Train Acc: 0.49166667461395264, Test Acc: 0.5091269612312317\n",
      "Epoch [7/50], Loss: 0.8342, Train Acc: 0.4749999940395355, Test Acc: 0.5041666626930237\n",
      "Epoch [8/50], Loss: 0.8277, Train Acc: 0.5138888955116272, Test Acc: 0.4922619163990021\n",
      "Epoch [9/50], Loss: 0.8314, Train Acc: 0.5, Test Acc: 0.5021825432777405\n",
      "Epoch [10/50], Loss: 0.8231, Train Acc: 0.550000011920929, Test Acc: 0.5001984238624573\n",
      "Epoch [11/50], Loss: 0.8246, Train Acc: 0.5, Test Acc: 0.5017856955528259\n",
      "Epoch [12/50], Loss: 0.8240, Train Acc: 0.5138888955116272, Test Acc: 0.4932539761066437\n",
      "Epoch [13/50], Loss: 0.8216, Train Acc: 0.5027777552604675, Test Acc: 0.5059523582458496\n",
      "Epoch [14/50], Loss: 0.8155, Train Acc: 0.5222222208976746, Test Acc: 0.5051587224006653\n",
      "Epoch [15/50], Loss: 0.7971, Train Acc: 0.48055556416511536, Test Acc: 0.5001984238624573\n",
      "New best acc: 0.5156745910644531 epoch 15\n",
      "Epoch [16/50], Loss: 0.8084, Train Acc: 0.43888887763023376, Test Acc: 0.5156745910644531\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-04 00:37:52,449] Trial 7 finished with value: 0.5156745910644531 and parameters: {'batch_size': 954, 'lr': 3.66473569833003e-05}. Best is trial 3 with value: 0.5652777552604675.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best acc: 0.5136904716491699 epoch 0\n",
      "Epoch [1/50], Loss: 0.8469, Train Acc: 0.5138888955116272, Test Acc: 0.5136904716491699\n",
      "New best acc: 0.5192460417747498 epoch 1\n",
      "Epoch [2/50], Loss: 1.1556, Train Acc: 0.5694444179534912, Test Acc: 0.5192460417747498\n",
      "New best acc: 0.521230161190033 epoch 2\n",
      "Epoch [3/50], Loss: 0.6930, Train Acc: 0.6111111044883728, Test Acc: 0.521230161190033\n",
      "New best acc: 0.5216270089149475 epoch 3\n",
      "Epoch [4/50], Loss: 0.6332, Train Acc: 0.6972222328186035, Test Acc: 0.5216270089149475\n",
      "New best acc: 0.5488095283508301 epoch 4\n",
      "Epoch [5/50], Loss: 0.6631, Train Acc: 0.6777777671813965, Test Acc: 0.5488095283508301\n",
      "Epoch [6/50], Loss: 0.6616, Train Acc: 0.7027778029441833, Test Acc: 0.523809552192688\n",
      "Epoch [7/50], Loss: 0.6539, Train Acc: 0.7722222208976746, Test Acc: 0.5416666865348816\n",
      "Epoch [8/50], Loss: 0.6118, Train Acc: 0.8083333373069763, Test Acc: 0.5390872955322266\n",
      "Epoch [9/50], Loss: 0.5853, Train Acc: 0.8138889074325562, Test Acc: 0.5345237851142883\n",
      "Epoch [10/50], Loss: 0.5633, Train Acc: 0.8388888835906982, Test Acc: 0.543055534362793\n",
      "Epoch [11/50], Loss: 0.5485, Train Acc: 0.8305555582046509, Test Acc: 0.5458333492279053\n",
      "New best acc: 0.5545634627342224 epoch 11\n",
      "Epoch [12/50], Loss: 0.5349, Train Acc: 0.875, Test Acc: 0.5545634627342224\n",
      "Epoch [13/50], Loss: 0.5272, Train Acc: 0.9027777910232544, Test Acc: 0.5503968000411987\n",
      "Epoch [14/50], Loss: 0.5160, Train Acc: 0.8999999761581421, Test Acc: 0.5517857074737549\n",
      "Epoch [15/50], Loss: 0.5137, Train Acc: 0.9277777671813965, Test Acc: 0.543055534362793\n",
      "Epoch [16/50], Loss: 0.5102, Train Acc: 0.9472222328186035, Test Acc: 0.5515872836112976\n",
      "New best acc: 0.5589285492897034 epoch 16\n",
      "Epoch [17/50], Loss: 0.4957, Train Acc: 0.949999988079071, Test Acc: 0.5589285492897034\n",
      "Epoch [18/50], Loss: 0.4953, Train Acc: 0.9527778029441833, Test Acc: 0.5539682507514954\n",
      "New best acc: 0.5634920597076416 epoch 18\n",
      "Epoch [19/50], Loss: 0.4853, Train Acc: 0.9833333492279053, Test Acc: 0.5634920597076416\n",
      "Epoch [20/50], Loss: 0.4940, Train Acc: 0.9777777791023254, Test Acc: 0.5517857074737549\n",
      "Epoch [21/50], Loss: 0.4762, Train Acc: 0.9777777791023254, Test Acc: 0.5509920716285706\n",
      "Epoch [22/50], Loss: 0.4703, Train Acc: 0.9750000238418579, Test Acc: 0.5607143044471741\n",
      "Epoch [23/50], Loss: 0.4726, Train Acc: 0.9888888597488403, Test Acc: 0.5472221970558167\n",
      "Epoch [24/50], Loss: 0.4747, Train Acc: 0.9861111044883728, Test Acc: 0.5571428537368774\n",
      "Epoch [25/50], Loss: 0.4586, Train Acc: 1.0, Test Acc: 0.5605158805847168\n",
      "Epoch [26/50], Loss: 0.4527, Train Acc: 0.9888888597488403, Test Acc: 0.557539701461792\n",
      "Epoch [27/50], Loss: 0.4578, Train Acc: 0.9888888597488403, Test Acc: 0.5595238208770752\n",
      "Epoch [28/50], Loss: 0.4485, Train Acc: 0.9888888597488403, Test Acc: 0.5601190328598022\n",
      "New best acc: 0.5648809671401978 epoch 28\n",
      "Epoch [29/50], Loss: 0.4454, Train Acc: 0.9916666746139526, Test Acc: 0.5648809671401978\n",
      "Epoch [30/50], Loss: 0.4431, Train Acc: 0.9916666746139526, Test Acc: 0.557539701461792\n",
      "Epoch [31/50], Loss: 0.4473, Train Acc: 0.9861111044883728, Test Acc: 0.5511904954910278\n",
      "Epoch [32/50], Loss: 0.4415, Train Acc: 0.9944444298744202, Test Acc: 0.5579364895820618\n",
      "Epoch [33/50], Loss: 0.4442, Train Acc: 0.9972222447395325, Test Acc: 0.558134913444519\n",
      "Epoch [34/50], Loss: 0.4344, Train Acc: 0.9972222447395325, Test Acc: 0.559920608997345\n",
      "Epoch [35/50], Loss: 0.4430, Train Acc: 0.9972222447395325, Test Acc: 0.5607143044471741\n",
      "Epoch [36/50], Loss: 0.4367, Train Acc: 0.9944444298744202, Test Acc: 0.5541666746139526\n",
      "Epoch [37/50], Loss: 0.4364, Train Acc: 0.9972222447395325, Test Acc: 0.559920608997345\n",
      "New best acc: 0.5664682388305664 epoch 37\n",
      "Epoch [38/50], Loss: 0.4361, Train Acc: 0.9944444298744202, Test Acc: 0.5664682388305664\n",
      "Epoch [39/50], Loss: 0.4339, Train Acc: 0.9972222447395325, Test Acc: 0.5507936477661133\n",
      "Epoch [40/50], Loss: 0.4354, Train Acc: 0.9972222447395325, Test Acc: 0.5563492178916931\n",
      "Epoch [41/50], Loss: 0.4349, Train Acc: 0.9944444298744202, Test Acc: 0.5603174567222595\n",
      "Epoch [42/50], Loss: 0.4323, Train Acc: 0.9972222447395325, Test Acc: 0.5611110925674438\n",
      "Epoch [43/50], Loss: 0.4287, Train Acc: 0.9944444298744202, Test Acc: 0.5472221970558167\n",
      "Epoch [44/50], Loss: 0.4359, Train Acc: 1.0, Test Acc: 0.5559523701667786\n",
      "Epoch [45/50], Loss: 0.4228, Train Acc: 0.9916666746139526, Test Acc: 0.554960310459137\n",
      "Epoch [46/50], Loss: 0.4235, Train Acc: 1.0, Test Acc: 0.5503968000411987\n",
      "Epoch [47/50], Loss: 0.4240, Train Acc: 1.0, Test Acc: 0.5547618865966797\n",
      "Epoch [48/50], Loss: 0.4231, Train Acc: 1.0, Test Acc: 0.5623015761375427\n",
      "Epoch [49/50], Loss: 0.4225, Train Acc: 1.0, Test Acc: 0.5634920597076416\n",
      "Epoch [50/50], Loss: 0.4243, Train Acc: 1.0, Test Acc: 0.5517857074737549\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-04 00:38:02,463] Trial 8 finished with value: 0.5664682388305664 and parameters: {'batch_size': 1860, 'lr': 0.006104835968801536}. Best is trial 8 with value: 0.5664682388305664.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best acc: 0.4942460358142853 epoch 0\n",
      "Epoch [1/50], Loss: 0.8771, Train Acc: 0.4722222089767456, Test Acc: 0.4942460358142853\n",
      "New best acc: 0.5021825432777405 epoch 1\n",
      "Epoch [2/50], Loss: 0.8545, Train Acc: 0.5111111402511597, Test Acc: 0.5021825432777405\n",
      "New best acc: 0.5057539939880371 epoch 2\n",
      "Epoch [3/50], Loss: 0.8487, Train Acc: 0.4749999940395355, Test Acc: 0.5057539939880371\n",
      "New best acc: 0.5063492059707642 epoch 3\n",
      "Epoch [4/50], Loss: 0.8737, Train Acc: 0.5222222208976746, Test Acc: 0.5063492059707642\n",
      "Epoch [5/50], Loss: 0.8413, Train Acc: 0.5388888716697693, Test Acc: 0.5057539939880371\n",
      "Epoch [6/50], Loss: 0.8278, Train Acc: 0.5138888955116272, Test Acc: 0.5007936358451843\n",
      "Epoch [7/50], Loss: 0.8606, Train Acc: 0.5111111402511597, Test Acc: 0.5027777552604675\n",
      "Epoch [8/50], Loss: 0.8314, Train Acc: 0.4861111044883728, Test Acc: 0.5061507821083069\n",
      "Epoch [9/50], Loss: 0.8311, Train Acc: 0.5333333611488342, Test Acc: 0.5029761791229248\n",
      "Epoch [10/50], Loss: 0.8195, Train Acc: 0.5, Test Acc: 0.48948413133621216\n",
      "Epoch [11/50], Loss: 0.8200, Train Acc: 0.5277777910232544, Test Acc: 0.5035714507102966\n",
      "Epoch [12/50], Loss: 0.8206, Train Acc: 0.5111111402511597, Test Acc: 0.5003968477249146\n",
      "Epoch [13/50], Loss: 0.8189, Train Acc: 0.5111111402511597, Test Acc: 0.5029761791229248\n",
      "Epoch [14/50], Loss: 0.8107, Train Acc: 0.5249999761581421, Test Acc: 0.49444442987442017\n",
      "Epoch [15/50], Loss: 0.8214, Train Acc: 0.5138888955116272, Test Acc: 0.5031746029853821\n",
      "New best acc: 0.5107142925262451 epoch 15\n",
      "Epoch [16/50], Loss: 0.8144, Train Acc: 0.5666666626930237, Test Acc: 0.5107142925262451\n",
      "New best acc: 0.5144841074943542 epoch 16\n",
      "Epoch [17/50], Loss: 0.8076, Train Acc: 0.5, Test Acc: 0.5144841074943542\n",
      "Epoch [18/50], Loss: 0.8040, Train Acc: 0.5166666507720947, Test Acc: 0.5021825432777405\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-04 00:38:06,498] Trial 9 finished with value: 0.5144841074943542 and parameters: {'batch_size': 1178, 'lr': 3.4751299347875914e-05}. Best is trial 8 with value: 0.5664682388305664.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best acc: 0.5156745910644531 epoch 0\n",
      "Epoch [1/50], Loss: 0.8444, Train Acc: 0.4833333194255829, Test Acc: 0.5156745910644531\n",
      "Epoch [2/50], Loss: 0.8042, Train Acc: 0.5027777552604675, Test Acc: 0.5001984238624573\n",
      "Epoch [3/50], Loss: 0.7744, Train Acc: 0.5305555462837219, Test Acc: 0.5047619342803955\n",
      "Epoch [4/50], Loss: 0.7520, Train Acc: 0.550000011920929, Test Acc: 0.5029761791229248\n",
      "Epoch [5/50], Loss: 0.7321, Train Acc: 0.6138888597488403, Test Acc: 0.5105158686637878\n",
      "Epoch [6/50], Loss: 0.7193, Train Acc: 0.5583333373069763, Test Acc: 0.5081349015235901\n",
      "Epoch [7/50], Loss: 0.7087, Train Acc: 0.5555555820465088, Test Acc: 0.5059523582458496\n",
      "Epoch [8/50], Loss: 0.6913, Train Acc: 0.5583333373069763, Test Acc: 0.5053571462631226\n",
      "Epoch [9/50], Loss: 0.6872, Train Acc: 0.6138888597488403, Test Acc: 0.5152778029441833\n",
      "Epoch [10/50], Loss: 0.6692, Train Acc: 0.605555534362793, Test Acc: 0.511904776096344\n",
      "Epoch [11/50], Loss: 0.6607, Train Acc: 0.5027777552604675, Test Acc: 0.5047619342803955\n",
      "New best acc: 0.519444465637207 epoch 11\n",
      "Epoch [12/50], Loss: 0.6459, Train Acc: 0.5805555582046509, Test Acc: 0.519444465637207\n",
      "Epoch [13/50], Loss: 0.6330, Train Acc: 0.574999988079071, Test Acc: 0.5152778029441833\n",
      "Epoch [14/50], Loss: 0.6297, Train Acc: 0.5888888835906982, Test Acc: 0.512499988079071\n",
      "Epoch [15/50], Loss: 0.6130, Train Acc: 0.605555534362793, Test Acc: 0.5156745910644531\n",
      "New best acc: 0.5289682745933533 epoch 15\n",
      "Epoch [16/50], Loss: 0.6050, Train Acc: 0.6305555701255798, Test Acc: 0.5289682745933533\n",
      "Epoch [17/50], Loss: 0.6123, Train Acc: 0.625, Test Acc: 0.5117063522338867\n",
      "Epoch [18/50], Loss: 0.5960, Train Acc: 0.6611111164093018, Test Acc: 0.5190476179122925\n",
      "Epoch [19/50], Loss: 0.5928, Train Acc: 0.6861110925674438, Test Acc: 0.5204365253448486\n",
      "New best acc: 0.5361111164093018 epoch 19\n",
      "Epoch [20/50], Loss: 0.5843, Train Acc: 0.6472222208976746, Test Acc: 0.5361111164093018\n",
      "Epoch [21/50], Loss: 0.5943, Train Acc: 0.6611111164093018, Test Acc: 0.524404764175415\n",
      "Epoch [22/50], Loss: 0.5802, Train Acc: 0.7194444537162781, Test Acc: 0.5307539701461792\n",
      "New best acc: 0.5369047522544861 epoch 22\n",
      "Epoch [23/50], Loss: 0.5789, Train Acc: 0.7250000238418579, Test Acc: 0.5369047522544861\n",
      "Epoch [24/50], Loss: 0.5714, Train Acc: 0.7194444537162781, Test Acc: 0.523809552192688\n",
      "Epoch [25/50], Loss: 0.5668, Train Acc: 0.7555555701255798, Test Acc: 0.5333333611488342\n",
      "Epoch [26/50], Loss: 0.5699, Train Acc: 0.7472222447395325, Test Acc: 0.5224206447601318\n",
      "Epoch [27/50], Loss: 0.5618, Train Acc: 0.730555534362793, Test Acc: 0.5313491821289062\n",
      "Epoch [28/50], Loss: 0.5644, Train Acc: 0.7166666388511658, Test Acc: 0.5265873074531555\n",
      "New best acc: 0.5454365015029907 epoch 28\n",
      "Epoch [29/50], Loss: 0.5503, Train Acc: 0.7027778029441833, Test Acc: 0.5454365015029907\n",
      "Epoch [30/50], Loss: 0.5554, Train Acc: 0.7555555701255798, Test Acc: 0.5329365134239197\n",
      "Epoch [31/50], Loss: 0.5553, Train Acc: 0.7861111164093018, Test Acc: 0.5251984000205994\n",
      "Epoch [32/50], Loss: 0.5504, Train Acc: 0.7777777910232544, Test Acc: 0.5353174805641174\n",
      "Epoch [33/50], Loss: 0.5436, Train Acc: 0.8111110925674438, Test Acc: 0.5398809313774109\n",
      "Epoch [34/50], Loss: 0.5402, Train Acc: 0.8388888835906982, Test Acc: 0.5398809313774109\n",
      "Epoch [35/50], Loss: 0.5358, Train Acc: 0.8166666626930237, Test Acc: 0.5394841432571411\n",
      "Epoch [36/50], Loss: 0.5333, Train Acc: 0.8083333373069763, Test Acc: 0.5283730030059814\n",
      "Epoch [37/50], Loss: 0.5295, Train Acc: 0.8416666388511658, Test Acc: 0.5408729910850525\n",
      "Epoch [38/50], Loss: 0.5314, Train Acc: 0.8333333134651184, Test Acc: 0.5321428775787354\n",
      "New best acc: 0.5519841313362122 epoch 38\n",
      "Epoch [39/50], Loss: 0.5228, Train Acc: 0.8611111044883728, Test Acc: 0.5519841313362122\n",
      "Epoch [40/50], Loss: 0.5242, Train Acc: 0.855555534362793, Test Acc: 0.5424603223800659\n",
      "Epoch [41/50], Loss: 0.5175, Train Acc: 0.8777777552604675, Test Acc: 0.524404764175415\n",
      "Epoch [42/50], Loss: 0.5148, Train Acc: 0.8666666746139526, Test Acc: 0.5414682626724243\n",
      "Epoch [43/50], Loss: 0.5184, Train Acc: 0.8833333253860474, Test Acc: 0.5480158925056458\n",
      "Epoch [44/50], Loss: 0.5116, Train Acc: 0.9027777910232544, Test Acc: 0.5476190447807312\n",
      "Epoch [45/50], Loss: 0.5077, Train Acc: 0.9111111164093018, Test Acc: 0.5432539582252502\n",
      "New best acc: 0.5529761910438538 epoch 45\n",
      "Epoch [46/50], Loss: 0.5004, Train Acc: 0.9083333611488342, Test Acc: 0.5529761910438538\n",
      "Epoch [47/50], Loss: 0.5049, Train Acc: 0.925000011920929, Test Acc: 0.5428571701049805\n",
      "Epoch [48/50], Loss: 0.4977, Train Acc: 0.9361110925674438, Test Acc: 0.5482142567634583\n",
      "Epoch [49/50], Loss: 0.4972, Train Acc: 0.9388889074325562, Test Acc: 0.5496031641960144\n",
      "Epoch [50/50], Loss: 0.4971, Train Acc: 0.925000011920929, Test Acc: 0.5450396537780762\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-04 00:38:16,570] Trial 10 finished with value: 0.5529761910438538 and parameters: {'batch_size': 2048, 'lr': 0.0005407917575683703}. Best is trial 8 with value: 0.5664682388305664.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best acc: 0.5134920477867126 epoch 0\n",
      "Epoch [1/50], Loss: 0.8493, Train Acc: 0.5305555462837219, Test Acc: 0.5134920477867126\n",
      "New best acc: 0.5236111283302307 epoch 1\n",
      "Epoch [2/50], Loss: 1.9260, Train Acc: 0.6222222447395325, Test Acc: 0.5236111283302307\n",
      "Epoch [3/50], Loss: 0.7104, Train Acc: 0.605555534362793, Test Acc: 0.5123015642166138\n",
      "Epoch [4/50], Loss: 0.6783, Train Acc: 0.5694444179534912, Test Acc: 0.5166666507720947\n",
      "Epoch [5/50], Loss: 0.7658, Train Acc: 0.6388888955116272, Test Acc: 0.5144841074943542\n",
      "Epoch [6/50], Loss: 0.7212, Train Acc: 0.6583333611488342, Test Acc: 0.5222222208976746\n",
      "Epoch [7/50], Loss: 0.6831, Train Acc: 0.6472222208976746, Test Acc: 0.5136904716491699\n",
      "Epoch [8/50], Loss: 0.6355, Train Acc: 0.7027778029441833, Test Acc: 0.5234127044677734\n",
      "New best acc: 0.5295634865760803 epoch 8\n",
      "Epoch [9/50], Loss: 0.6023, Train Acc: 0.6833333373069763, Test Acc: 0.5295634865760803\n",
      "New best acc: 0.5341269969940186 epoch 9\n",
      "Epoch [10/50], Loss: 0.5764, Train Acc: 0.7361111044883728, Test Acc: 0.5341269969940186\n",
      "New best acc: 0.5371031761169434 epoch 10\n",
      "Epoch [11/50], Loss: 0.5676, Train Acc: 0.7888888716697693, Test Acc: 0.5371031761169434\n",
      "New best acc: 0.5476190447807312 epoch 11\n",
      "Epoch [12/50], Loss: 0.5611, Train Acc: 0.7861111164093018, Test Acc: 0.5476190447807312\n",
      "New best acc: 0.5488095283508301 epoch 12\n",
      "Epoch [13/50], Loss: 0.5593, Train Acc: 0.800000011920929, Test Acc: 0.5488095283508301\n",
      "Epoch [14/50], Loss: 0.5503, Train Acc: 0.8166666626930237, Test Acc: 0.5468254089355469\n",
      "New best acc: 0.5535714030265808 epoch 14\n",
      "Epoch [15/50], Loss: 0.5456, Train Acc: 0.855555534362793, Test Acc: 0.5535714030265808\n",
      "Epoch [16/50], Loss: 0.5514, Train Acc: 0.8583333492279053, Test Acc: 0.5436508059501648\n",
      "Epoch [17/50], Loss: 0.5393, Train Acc: 0.8611111044883728, Test Acc: 0.5527777671813965\n",
      "Epoch [18/50], Loss: 0.5361, Train Acc: 0.8999999761581421, Test Acc: 0.5444444417953491\n",
      "Epoch [19/50], Loss: 0.5233, Train Acc: 0.8972222208976746, Test Acc: 0.538690447807312\n",
      "Epoch [20/50], Loss: 0.5177, Train Acc: 0.9055555462837219, Test Acc: 0.5442460179328918\n",
      "Epoch [21/50], Loss: 0.5085, Train Acc: 0.9388889074325562, Test Acc: 0.5509920716285706\n",
      "Epoch [22/50], Loss: 0.5031, Train Acc: 0.9222221970558167, Test Acc: 0.5533730387687683\n",
      "New best acc: 0.5553571581840515 epoch 22\n",
      "Epoch [23/50], Loss: 0.4998, Train Acc: 0.9555555582046509, Test Acc: 0.5553571581840515\n",
      "Epoch [24/50], Loss: 0.4921, Train Acc: 0.949999988079071, Test Acc: 0.550595223903656\n",
      "Epoch [25/50], Loss: 0.4874, Train Acc: 0.9638888835906982, Test Acc: 0.5545634627342224\n",
      "Epoch [26/50], Loss: 0.4822, Train Acc: 0.9694444537162781, Test Acc: 0.5529761910438538\n",
      "New best acc: 0.5557539463043213 epoch 26\n",
      "Epoch [27/50], Loss: 0.4817, Train Acc: 0.9611111283302307, Test Acc: 0.5557539463043213\n",
      "New best acc: 0.5603174567222595 epoch 27\n",
      "Epoch [28/50], Loss: 0.4766, Train Acc: 0.980555534362793, Test Acc: 0.5603174567222595\n",
      "Epoch [29/50], Loss: 0.4679, Train Acc: 0.9750000238418579, Test Acc: 0.5525793433189392\n",
      "Epoch [30/50], Loss: 0.4689, Train Acc: 0.9888888597488403, Test Acc: 0.5597222447395325\n",
      "Epoch [31/50], Loss: 0.4685, Train Acc: 0.9888888597488403, Test Acc: 0.5583333373069763\n",
      "Epoch [32/50], Loss: 0.4638, Train Acc: 0.9888888597488403, Test Acc: 0.5494047403335571\n",
      "Epoch [33/50], Loss: 0.4560, Train Acc: 0.9916666746139526, Test Acc: 0.5593253970146179\n",
      "New best acc: 0.5658730268478394 epoch 33\n",
      "Epoch [34/50], Loss: 0.4564, Train Acc: 0.9916666746139526, Test Acc: 0.5658730268478394\n",
      "Epoch [35/50], Loss: 0.4606, Train Acc: 0.9944444298744202, Test Acc: 0.557539701461792\n",
      "Epoch [36/50], Loss: 0.4567, Train Acc: 0.980555534362793, Test Acc: 0.5617063641548157\n",
      "Epoch [37/50], Loss: 0.4493, Train Acc: 0.9972222447395325, Test Acc: 0.5557539463043213\n",
      "Epoch [38/50], Loss: 0.4449, Train Acc: 0.9916666746139526, Test Acc: 0.5529761910438538\n",
      "Epoch [39/50], Loss: 0.4451, Train Acc: 0.9888888597488403, Test Acc: 0.5474206209182739\n",
      "Epoch [40/50], Loss: 0.4451, Train Acc: 0.9972222447395325, Test Acc: 0.5565476417541504\n",
      "Epoch [41/50], Loss: 0.4408, Train Acc: 0.9916666746139526, Test Acc: 0.5557539463043213\n",
      "Epoch [42/50], Loss: 0.4405, Train Acc: 1.0, Test Acc: 0.5521825551986694\n",
      "Epoch [43/50], Loss: 0.4387, Train Acc: 0.9861111044883728, Test Acc: 0.5601190328598022\n",
      "Epoch [44/50], Loss: 0.4378, Train Acc: 0.9944444298744202, Test Acc: 0.5609126687049866\n",
      "Epoch [45/50], Loss: 0.4361, Train Acc: 0.9972222447395325, Test Acc: 0.5537698268890381\n",
      "Epoch [46/50], Loss: 0.4381, Train Acc: 1.0, Test Acc: 0.5569444298744202\n",
      "Epoch [47/50], Loss: 0.4355, Train Acc: 0.9888888597488403, Test Acc: 0.5559523701667786\n",
      "Epoch [48/50], Loss: 0.4345, Train Acc: 0.9888888597488403, Test Acc: 0.5583333373069763\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-04 00:38:26,713] Trial 11 finished with value: 0.5658730268478394 and parameters: {'batch_size': 1817, 'lr': 0.009757767589753429}. Best is trial 8 with value: 0.5664682388305664.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [49/50], Loss: 0.4407, Train Acc: 1.0, Test Acc: 0.5519841313362122\n",
      "Epoch [50/50], Loss: 0.4292, Train Acc: 0.9944444298744202, Test Acc: 0.5561507940292358\n",
      "New best acc: 0.5214285850524902 epoch 0\n",
      "Epoch [1/50], Loss: 0.8414, Train Acc: 0.5666666626930237, Test Acc: 0.5214285850524902\n",
      "New best acc: 0.5265873074531555 epoch 1\n",
      "Epoch [2/50], Loss: 1.4175, Train Acc: 0.5694444179534912, Test Acc: 0.5265873074531555\n",
      "Epoch [3/50], Loss: 0.6820, Train Acc: 0.5694444179534912, Test Acc: 0.52182537317276\n",
      "New best acc: 0.5343254208564758 epoch 3\n",
      "Epoch [4/50], Loss: 0.6435, Train Acc: 0.574999988079071, Test Acc: 0.5343254208564758\n",
      "Epoch [5/50], Loss: 0.6917, Train Acc: 0.6777777671813965, Test Acc: 0.5315476059913635\n",
      "Epoch [6/50], Loss: 0.6879, Train Acc: 0.6722221970558167, Test Acc: 0.5333333611488342\n",
      "Epoch [7/50], Loss: 0.6710, Train Acc: 0.644444465637207, Test Acc: 0.5305555462837219\n",
      "Epoch [8/50], Loss: 0.6510, Train Acc: 0.6777777671813965, Test Acc: 0.5343254208564758\n",
      "New best acc: 0.5444444417953491 epoch 8\n",
      "Epoch [9/50], Loss: 0.5997, Train Acc: 0.730555534362793, Test Acc: 0.5444444417953491\n",
      "Epoch [10/50], Loss: 0.5737, Train Acc: 0.7250000238418579, Test Acc: 0.54067462682724\n",
      "New best acc: 0.5482142567634583 epoch 10\n",
      "Epoch [11/50], Loss: 0.5705, Train Acc: 0.7861111164093018, Test Acc: 0.5482142567634583\n",
      "Epoch [12/50], Loss: 0.5487, Train Acc: 0.75, Test Acc: 0.5390872955322266\n",
      "Epoch [13/50], Loss: 0.5513, Train Acc: 0.7916666865348816, Test Acc: 0.5436508059501648\n",
      "New best acc: 0.5513888597488403 epoch 13\n",
      "Epoch [14/50], Loss: 0.5400, Train Acc: 0.8083333373069763, Test Acc: 0.5513888597488403\n",
      "Epoch [15/50], Loss: 0.5275, Train Acc: 0.8583333492279053, Test Acc: 0.5458333492279053\n",
      "Epoch [16/50], Loss: 0.5245, Train Acc: 0.8833333253860474, Test Acc: 0.5513888597488403\n",
      "Epoch [17/50], Loss: 0.5223, Train Acc: 0.8833333253860474, Test Acc: 0.5474206209182739\n",
      "Epoch [18/50], Loss: 0.5040, Train Acc: 0.8916666507720947, Test Acc: 0.5507936477661133\n",
      "New best acc: 0.5539682507514954 epoch 18\n",
      "Epoch [19/50], Loss: 0.4962, Train Acc: 0.9277777671813965, Test Acc: 0.5539682507514954\n",
      "New best acc: 0.561904788017273 epoch 19\n",
      "Epoch [20/50], Loss: 0.4860, Train Acc: 0.949999988079071, Test Acc: 0.561904788017273\n",
      "Epoch [21/50], Loss: 0.4885, Train Acc: 0.9555555582046509, Test Acc: 0.5519841313362122\n",
      "Epoch [22/50], Loss: 0.4783, Train Acc: 0.9694444537162781, Test Acc: 0.5591269731521606\n",
      "Epoch [23/50], Loss: 0.4774, Train Acc: 0.9861111044883728, Test Acc: 0.5509920716285706\n",
      "Epoch [24/50], Loss: 0.4798, Train Acc: 0.9777777791023254, Test Acc: 0.5547618865966797\n",
      "Epoch [25/50], Loss: 0.4712, Train Acc: 0.9666666388511658, Test Acc: 0.545634925365448\n",
      "Epoch [26/50], Loss: 0.4610, Train Acc: 0.9777777791023254, Test Acc: 0.5585317611694336\n",
      "Epoch [27/50], Loss: 0.4555, Train Acc: 0.9833333492279053, Test Acc: 0.5472221970558167\n",
      "Epoch [28/50], Loss: 0.4519, Train Acc: 0.980555534362793, Test Acc: 0.5519841313362122\n",
      "Epoch [29/50], Loss: 0.4445, Train Acc: 0.9944444298744202, Test Acc: 0.5601190328598022\n",
      "Epoch [30/50], Loss: 0.4480, Train Acc: 0.9861111044883728, Test Acc: 0.5488095283508301\n",
      "Epoch [31/50], Loss: 0.4437, Train Acc: 0.9972222447395325, Test Acc: 0.5515872836112976\n",
      "Epoch [32/50], Loss: 0.4411, Train Acc: 0.9888888597488403, Test Acc: 0.5565476417541504\n",
      "Epoch [33/50], Loss: 0.4405, Train Acc: 0.9888888597488403, Test Acc: 0.5571428537368774\n",
      "Epoch [34/50], Loss: 0.4341, Train Acc: 1.0, Test Acc: 0.5436508059501648\n",
      "Epoch [35/50], Loss: 0.4382, Train Acc: 0.9888888597488403, Test Acc: 0.5466269850730896\n",
      "Epoch [36/50], Loss: 0.4317, Train Acc: 0.9916666746139526, Test Acc: 0.5484126806259155\n",
      "Epoch [37/50], Loss: 0.4314, Train Acc: 1.0, Test Acc: 0.5517857074737549\n",
      "Epoch [38/50], Loss: 0.4275, Train Acc: 0.9944444298744202, Test Acc: 0.561904788017273\n",
      "Epoch [39/50], Loss: 0.4309, Train Acc: 0.9944444298744202, Test Acc: 0.5611110925674438\n",
      "Epoch [40/50], Loss: 0.4305, Train Acc: 0.9916666746139526, Test Acc: 0.5551587343215942\n",
      "Epoch [41/50], Loss: 0.4266, Train Acc: 1.0, Test Acc: 0.553174614906311\n",
      "Epoch [42/50], Loss: 0.4249, Train Acc: 0.9944444298744202, Test Acc: 0.5551587343215942\n",
      "Epoch [43/50], Loss: 0.4253, Train Acc: 0.9916666746139526, Test Acc: 0.5529761910438538\n",
      "Epoch [44/50], Loss: 0.4295, Train Acc: 1.0, Test Acc: 0.5591269731521606\n",
      "Epoch [45/50], Loss: 0.4265, Train Acc: 0.9944444298744202, Test Acc: 0.5496031641960144\n",
      "Epoch [46/50], Loss: 0.4410, Train Acc: 0.9972222447395325, Test Acc: 0.5509920716285706\n",
      "Epoch [47/50], Loss: 0.4234, Train Acc: 1.0, Test Acc: 0.5529761910438538\n",
      "Epoch [48/50], Loss: 0.4225, Train Acc: 1.0, Test Acc: 0.5535714030265808\n",
      "Epoch [49/50], Loss: 0.4203, Train Acc: 0.9944444298744202, Test Acc: 0.5563492178916931\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-04 00:38:36,710] Trial 12 finished with value: 0.561904788017273 and parameters: {'batch_size': 1974, 'lr': 0.0076518604142367845}. Best is trial 8 with value: 0.5664682388305664.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [50/50], Loss: 0.4239, Train Acc: 0.9972222447395325, Test Acc: 0.5543650984764099\n",
      "New best acc: 0.49742063879966736 epoch 0\n",
      "Epoch [1/50], Loss: 0.8475, Train Acc: 0.5083333253860474, Test Acc: 0.49742063879966736\n",
      "New best acc: 0.5007936358451843 epoch 1\n",
      "Epoch [2/50], Loss: 0.8524, Train Acc: 0.49166667461395264, Test Acc: 0.5007936358451843\n",
      "Epoch [3/50], Loss: 0.8568, Train Acc: 0.4888888895511627, Test Acc: 0.49861112236976624\n",
      "Epoch [4/50], Loss: 0.8547, Train Acc: 0.4749999940395355, Test Acc: 0.4878968298435211\n",
      "New best acc: 0.5015873312950134 epoch 4\n",
      "Epoch [5/50], Loss: 0.8580, Train Acc: 0.4833333194255829, Test Acc: 0.5015873312950134\n",
      "New best acc: 0.509325385093689 epoch 5\n",
      "Epoch [6/50], Loss: 0.8514, Train Acc: 0.4694444537162781, Test Acc: 0.509325385093689\n",
      "Epoch [7/50], Loss: 0.8495, Train Acc: 0.5111111402511597, Test Acc: 0.49861112236976624\n",
      "Epoch [8/50], Loss: 0.8527, Train Acc: 0.49444442987442017, Test Acc: 0.4912698268890381\n",
      "Epoch [9/50], Loss: 0.8423, Train Acc: 0.4749999940395355, Test Acc: 0.4992063343524933\n",
      "Epoch [10/50], Loss: 0.8526, Train Acc: 0.5083333253860474, Test Acc: 0.48908731341362\n",
      "Epoch [11/50], Loss: 0.8516, Train Acc: 0.4972222149372101, Test Acc: 0.4878968298435211\n",
      "Epoch [12/50], Loss: 0.8472, Train Acc: 0.5166666507720947, Test Acc: 0.5007936358451843\n",
      "Epoch [13/50], Loss: 0.8511, Train Acc: 0.5, Test Acc: 0.49662697315216064\n",
      "Epoch [14/50], Loss: 0.8479, Train Acc: 0.46666666865348816, Test Acc: 0.5059523582458496\n",
      "Epoch [15/50], Loss: 0.8532, Train Acc: 0.47777777910232544, Test Acc: 0.49742063879966736\n",
      "Epoch [16/50], Loss: 0.8531, Train Acc: 0.4749999940395355, Test Acc: 0.49761903285980225\n",
      "Epoch [17/50], Loss: 0.8466, Train Acc: 0.5027777552604675, Test Acc: 0.5061507821083069\n",
      "Epoch [18/50], Loss: 0.8480, Train Acc: 0.4861111044883728, Test Acc: 0.5031746029853821\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-04 00:38:40,593] Trial 13 finished with value: 0.509325385093689 and parameters: {'batch_size': 1673, 'lr': 1.0044708819290543e-06}. Best is trial 8 with value: 0.5664682388305664.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best acc: 0.5101190209388733 epoch 0\n",
      "Epoch [1/50], Loss: 0.8633, Train Acc: 0.5388888716697693, Test Acc: 0.5101190209388733\n",
      "Epoch [2/50], Loss: 0.7746, Train Acc: 0.5944444537162781, Test Acc: 0.5045635104179382\n",
      "New best acc: 0.5142857432365417 epoch 2\n",
      "Epoch [3/50], Loss: 0.7310, Train Acc: 0.5805555582046509, Test Acc: 0.5142857432365417\n",
      "New best acc: 0.516269862651825 epoch 3\n",
      "Epoch [4/50], Loss: 0.6937, Train Acc: 0.6416666507720947, Test Acc: 0.516269862651825\n",
      "New best acc: 0.5269841551780701 epoch 4\n",
      "Epoch [5/50], Loss: 0.6622, Train Acc: 0.6111111044883728, Test Acc: 0.5269841551780701\n",
      "Epoch [6/50], Loss: 0.6283, Train Acc: 0.644444465637207, Test Acc: 0.5206349492073059\n",
      "New best acc: 0.5285714268684387 epoch 6\n",
      "Epoch [7/50], Loss: 0.6054, Train Acc: 0.6805555820465088, Test Acc: 0.5285714268684387\n",
      "Epoch [8/50], Loss: 0.5938, Train Acc: 0.6666666865348816, Test Acc: 0.5271825194358826\n",
      "New best acc: 0.5414682626724243 epoch 8\n",
      "Epoch [9/50], Loss: 0.5928, Train Acc: 0.6916666626930237, Test Acc: 0.5414682626724243\n",
      "Epoch [10/50], Loss: 0.5838, Train Acc: 0.6861110925674438, Test Acc: 0.5279762148857117\n",
      "Epoch [11/50], Loss: 0.5665, Train Acc: 0.7250000238418579, Test Acc: 0.538690447807312\n",
      "Epoch [12/50], Loss: 0.5578, Train Acc: 0.7222222089767456, Test Acc: 0.5347222089767456\n",
      "New best acc: 0.5464285612106323 epoch 12\n",
      "Epoch [13/50], Loss: 0.5531, Train Acc: 0.769444465637207, Test Acc: 0.5464285612106323\n",
      "Epoch [14/50], Loss: 0.5509, Train Acc: 0.7833333611488342, Test Acc: 0.5414682626724243\n",
      "Epoch [15/50], Loss: 0.5345, Train Acc: 0.8194444179534912, Test Acc: 0.538690447807312\n",
      "New best acc: 0.5474206209182739 epoch 15\n",
      "Epoch [16/50], Loss: 0.5259, Train Acc: 0.7888888716697693, Test Acc: 0.5474206209182739\n",
      "Epoch [17/50], Loss: 0.5162, Train Acc: 0.8444444537162781, Test Acc: 0.5418650507926941\n",
      "New best acc: 0.5541666746139526 epoch 17\n",
      "Epoch [18/50], Loss: 0.5147, Train Acc: 0.8666666746139526, Test Acc: 0.5541666746139526\n",
      "Epoch [19/50], Loss: 0.5096, Train Acc: 0.9361110925674438, Test Acc: 0.5444444417953491\n",
      "New best acc: 0.5569444298744202 epoch 19\n",
      "Epoch [20/50], Loss: 0.5027, Train Acc: 0.9055555462837219, Test Acc: 0.5569444298744202\n",
      "Epoch [21/50], Loss: 0.5288, Train Acc: 0.9194444417953491, Test Acc: 0.5543650984764099\n",
      "Epoch [22/50], Loss: 0.4911, Train Acc: 0.9305555820465088, Test Acc: 0.5470238327980042\n",
      "Epoch [23/50], Loss: 0.4854, Train Acc: 0.9222221970558167, Test Acc: 0.5468254089355469\n",
      "Epoch [24/50], Loss: 0.4879, Train Acc: 0.9555555582046509, Test Acc: 0.5515872836112976\n",
      "Epoch [25/50], Loss: 0.4801, Train Acc: 0.9666666388511658, Test Acc: 0.5464285612106323\n",
      "Epoch [26/50], Loss: 0.4737, Train Acc: 0.9722222089767456, Test Acc: 0.5543650984764099\n",
      "New best acc: 0.5605158805847168 epoch 26\n",
      "Epoch [27/50], Loss: 0.4757, Train Acc: 0.980555534362793, Test Acc: 0.5605158805847168\n",
      "Epoch [28/50], Loss: 0.4729, Train Acc: 0.9722222089767456, Test Acc: 0.5603174567222595\n",
      "Epoch [29/50], Loss: 0.4640, Train Acc: 0.9861111044883728, Test Acc: 0.5573412775993347\n",
      "New best acc: 0.5632936358451843 epoch 29\n",
      "Epoch [30/50], Loss: 0.4628, Train Acc: 0.9861111044883728, Test Acc: 0.5632936358451843\n",
      "Epoch [31/50], Loss: 0.4576, Train Acc: 0.9944444298744202, Test Acc: 0.5611110925674438\n",
      "Epoch [32/50], Loss: 0.4587, Train Acc: 0.9888888597488403, Test Acc: 0.5557539463043213\n",
      "New best acc: 0.5634920597076416 epoch 32\n",
      "Epoch [33/50], Loss: 0.4542, Train Acc: 0.9972222447395325, Test Acc: 0.5634920597076416\n",
      "Epoch [34/50], Loss: 0.4485, Train Acc: 0.9944444298744202, Test Acc: 0.5539682507514954\n",
      "Epoch [35/50], Loss: 0.4465, Train Acc: 0.9972222447395325, Test Acc: 0.5535714030265808\n",
      "Epoch [36/50], Loss: 0.4480, Train Acc: 0.9944444298744202, Test Acc: 0.5626984238624573\n",
      "Epoch [37/50], Loss: 0.4419, Train Acc: 1.0, Test Acc: 0.5625\n",
      "Epoch [38/50], Loss: 0.4402, Train Acc: 1.0, Test Acc: 0.5587301850318909\n",
      "Epoch [39/50], Loss: 0.4372, Train Acc: 0.9916666746139526, Test Acc: 0.5593253970146179\n",
      "Epoch [40/50], Loss: 0.4368, Train Acc: 0.9861111044883728, Test Acc: 0.5565476417541504\n",
      "Epoch [41/50], Loss: 0.4389, Train Acc: 0.9944444298744202, Test Acc: 0.5541666746139526\n",
      "Epoch [42/50], Loss: 0.4383, Train Acc: 0.9972222447395325, Test Acc: 0.559920608997345\n",
      "Epoch [43/50], Loss: 0.4330, Train Acc: 1.0, Test Acc: 0.5563492178916931\n",
      "Epoch [44/50], Loss: 0.4296, Train Acc: 0.9944444298744202, Test Acc: 0.5609126687049866\n",
      "Epoch [45/50], Loss: 0.4257, Train Acc: 1.0, Test Acc: 0.5515872836112976\n",
      "Epoch [46/50], Loss: 0.4271, Train Acc: 0.9916666746139526, Test Acc: 0.5589285492897034\n",
      "Epoch [47/50], Loss: 0.4277, Train Acc: 0.9972222447395325, Test Acc: 0.559920608997345\n",
      "Epoch [48/50], Loss: 0.4266, Train Acc: 0.9972222447395325, Test Acc: 0.5625\n",
      "New best acc: 0.5692460536956787 epoch 48\n",
      "Epoch [49/50], Loss: 0.4238, Train Acc: 0.9944444298744202, Test Acc: 0.5692460536956787\n",
      "Epoch [50/50], Loss: 0.4214, Train Acc: 0.9972222447395325, Test Acc: 0.5569444298744202\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-04 00:38:50,751] Trial 14 finished with value: 0.5692460536956787 and parameters: {'batch_size': 1738, 'lr': 0.0016801991703897096}. Best is trial 14 with value: 0.5692460536956787.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best acc: 0.49067461490631104 epoch 0\n",
      "Epoch [1/50], Loss: 0.8568, Train Acc: 0.5694444179534912, Test Acc: 0.49067461490631104\n",
      "New best acc: 0.5136904716491699 epoch 1\n",
      "Epoch [2/50], Loss: 0.7923, Train Acc: 0.5527777671813965, Test Acc: 0.5136904716491699\n",
      "New best acc: 0.5184524059295654 epoch 2\n",
      "Epoch [3/50], Loss: 0.7525, Train Acc: 0.5416666865348816, Test Acc: 0.5184524059295654\n",
      "Epoch [4/50], Loss: 0.7334, Train Acc: 0.5333333611488342, Test Acc: 0.5123015642166138\n",
      "Epoch [5/50], Loss: 0.7253, Train Acc: 0.5416666865348816, Test Acc: 0.5146825313568115\n",
      "Epoch [6/50], Loss: 0.7102, Train Acc: 0.5916666388511658, Test Acc: 0.5136904716491699\n",
      "Epoch [7/50], Loss: 0.6951, Train Acc: 0.5555555820465088, Test Acc: 0.5061507821083069\n",
      "Epoch [8/50], Loss: 0.6846, Train Acc: 0.5833333134651184, Test Acc: 0.5134920477867126\n",
      "Epoch [9/50], Loss: 0.6676, Train Acc: 0.5916666388511658, Test Acc: 0.5138888955116272\n",
      "New best acc: 0.5289682745933533 epoch 9\n",
      "Epoch [10/50], Loss: 0.6527, Train Acc: 0.6277777552604675, Test Acc: 0.5289682745933533\n",
      "Epoch [11/50], Loss: 0.6265, Train Acc: 0.605555534362793, Test Acc: 0.5154761672019958\n",
      "Epoch [12/50], Loss: 0.6268, Train Acc: 0.6194444298744202, Test Acc: 0.5265873074531555\n",
      "Epoch [13/50], Loss: 0.6180, Train Acc: 0.6499999761581421, Test Acc: 0.5150793790817261\n",
      "New best acc: 0.5355158448219299 epoch 13\n",
      "Epoch [14/50], Loss: 0.6069, Train Acc: 0.6833333373069763, Test Acc: 0.5355158448219299\n",
      "Epoch [15/50], Loss: 0.6016, Train Acc: 0.6916666626930237, Test Acc: 0.5232142806053162\n",
      "Epoch [16/50], Loss: 0.6010, Train Acc: 0.6722221970558167, Test Acc: 0.5285714268684387\n",
      "Epoch [17/50], Loss: 0.5946, Train Acc: 0.6833333373069763, Test Acc: 0.524404764175415\n",
      "New best acc: 0.5376983880996704 epoch 17\n",
      "Epoch [18/50], Loss: 0.5792, Train Acc: 0.7194444537162781, Test Acc: 0.5376983880996704\n",
      "Epoch [19/50], Loss: 0.5716, Train Acc: 0.730555534362793, Test Acc: 0.5351190567016602\n",
      "Epoch [20/50], Loss: 0.5695, Train Acc: 0.7111111283302307, Test Acc: 0.5263888835906982\n",
      "Epoch [21/50], Loss: 0.5656, Train Acc: 0.7555555701255798, Test Acc: 0.5305555462837219\n",
      "New best acc: 0.5394841432571411 epoch 21\n",
      "Epoch [22/50], Loss: 0.5654, Train Acc: 0.75, Test Acc: 0.5394841432571411\n",
      "Epoch [23/50], Loss: 0.5670, Train Acc: 0.7527777552604675, Test Acc: 0.5341269969940186\n",
      "Epoch [24/50], Loss: 0.5550, Train Acc: 0.7833333611488342, Test Acc: 0.5349206328392029\n",
      "New best acc: 0.5414682626724243 epoch 24\n",
      "Epoch [25/50], Loss: 0.5532, Train Acc: 0.7749999761581421, Test Acc: 0.5414682626724243\n",
      "Epoch [26/50], Loss: 0.5491, Train Acc: 0.8416666388511658, Test Acc: 0.5373015999794006\n",
      "New best acc: 0.5440475940704346 epoch 26\n",
      "Epoch [27/50], Loss: 0.5539, Train Acc: 0.8138889074325562, Test Acc: 0.5440475940704346\n",
      "New best acc: 0.5488095283508301 epoch 27\n",
      "Epoch [28/50], Loss: 0.5393, Train Acc: 0.8166666626930237, Test Acc: 0.5488095283508301\n",
      "Epoch [29/50], Loss: 0.5394, Train Acc: 0.7722222208976746, Test Acc: 0.541269838809967\n",
      "Epoch [30/50], Loss: 0.5318, Train Acc: 0.8472222089767456, Test Acc: 0.5450396537780762\n",
      "Epoch [31/50], Loss: 0.5310, Train Acc: 0.8277778029441833, Test Acc: 0.5488095283508301\n",
      "Epoch [32/50], Loss: 0.5278, Train Acc: 0.8694444298744202, Test Acc: 0.5474206209182739\n",
      "Epoch [33/50], Loss: 0.5236, Train Acc: 0.8722222447395325, Test Acc: 0.5482142567634583\n",
      "New best acc: 0.5494047403335571 epoch 33\n",
      "Epoch [34/50], Loss: 0.5177, Train Acc: 0.8972222208976746, Test Acc: 0.5494047403335571\n",
      "New best acc: 0.5521825551986694 epoch 34\n",
      "Epoch [35/50], Loss: 0.5150, Train Acc: 0.9111111164093018, Test Acc: 0.5521825551986694\n",
      "Epoch [36/50], Loss: 0.5103, Train Acc: 0.8916666507720947, Test Acc: 0.5426587462425232\n",
      "New best acc: 0.5525793433189392 epoch 36\n",
      "Epoch [37/50], Loss: 0.5053, Train Acc: 0.9027777910232544, Test Acc: 0.5525793433189392\n",
      "Epoch [38/50], Loss: 0.5013, Train Acc: 0.9111111164093018, Test Acc: 0.5396825671195984\n",
      "New best acc: 0.5527777671813965 epoch 38\n",
      "Epoch [39/50], Loss: 0.4995, Train Acc: 0.9111111164093018, Test Acc: 0.5527777671813965\n",
      "New best acc: 0.5623015761375427 epoch 39\n",
      "Epoch [40/50], Loss: 0.4943, Train Acc: 0.9305555820465088, Test Acc: 0.5623015761375427\n",
      "Epoch [41/50], Loss: 0.4907, Train Acc: 0.9277777671813965, Test Acc: 0.5525793433189392\n",
      "Epoch [42/50], Loss: 0.4907, Train Acc: 0.9638888835906982, Test Acc: 0.5519841313362122\n",
      "Epoch [43/50], Loss: 0.4849, Train Acc: 0.9694444537162781, Test Acc: 0.5563492178916931\n",
      "Epoch [44/50], Loss: 0.4868, Train Acc: 0.949999988079071, Test Acc: 0.5559523701667786\n",
      "New best acc: 0.5628968477249146 epoch 44\n",
      "Epoch [45/50], Loss: 0.4789, Train Acc: 0.9694444537162781, Test Acc: 0.5628968477249146\n",
      "Epoch [46/50], Loss: 0.4758, Train Acc: 0.9694444537162781, Test Acc: 0.5533730387687683\n",
      "Epoch [47/50], Loss: 0.4733, Train Acc: 0.9694444537162781, Test Acc: 0.5591269731521606\n",
      "Epoch [48/50], Loss: 0.4738, Train Acc: 0.980555534362793, Test Acc: 0.5551587343215942\n",
      "Epoch [49/50], Loss: 0.4707, Train Acc: 0.9750000238418579, Test Acc: 0.5583333373069763\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-04 00:39:00,938] Trial 15 finished with value: 0.5628968477249146 and parameters: {'batch_size': 1612, 'lr': 0.0006890576317264964}. Best is trial 14 with value: 0.5692460536956787.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [50/50], Loss: 0.4674, Train Acc: 0.9833333492279053, Test Acc: 0.5573412775993347\n",
      "New best acc: 0.4992063343524933 epoch 0\n",
      "Epoch [1/50], Loss: 0.8625, Train Acc: 0.5444444417953491, Test Acc: 0.4992063343524933\n",
      "New best acc: 0.5047619342803955 epoch 1\n",
      "Epoch [2/50], Loss: 0.7674, Train Acc: 0.5333333611488342, Test Acc: 0.5047619342803955\n",
      "New best acc: 0.5079365372657776 epoch 2\n",
      "Epoch [3/50], Loss: 0.7165, Train Acc: 0.5333333611488342, Test Acc: 0.5079365372657776\n",
      "New best acc: 0.5206349492073059 epoch 3\n",
      "Epoch [4/50], Loss: 0.6690, Train Acc: 0.6305555701255798, Test Acc: 0.5206349492073059\n",
      "New best acc: 0.5242063403129578 epoch 4\n",
      "Epoch [5/50], Loss: 0.6402, Train Acc: 0.625, Test Acc: 0.5242063403129578\n",
      "Epoch [6/50], Loss: 0.6129, Train Acc: 0.6333333253860474, Test Acc: 0.523809552192688\n",
      "New best acc: 0.5299603343009949 epoch 6\n",
      "Epoch [7/50], Loss: 0.5905, Train Acc: 0.6638888716697693, Test Acc: 0.5299603343009949\n",
      "New best acc: 0.5307539701461792 epoch 7\n",
      "Epoch [8/50], Loss: 0.5787, Train Acc: 0.7277777791023254, Test Acc: 0.5307539701461792\n",
      "New best acc: 0.5317460298538208 epoch 8\n",
      "Epoch [9/50], Loss: 0.5638, Train Acc: 0.7333333492279053, Test Acc: 0.5317460298538208\n",
      "New best acc: 0.5507936477661133 epoch 9\n",
      "Epoch [10/50], Loss: 0.5587, Train Acc: 0.7722222208976746, Test Acc: 0.5507936477661133\n",
      "Epoch [11/50], Loss: 0.5489, Train Acc: 0.7888888716697693, Test Acc: 0.5420634746551514\n",
      "New best acc: 0.5543650984764099 epoch 11\n",
      "Epoch [12/50], Loss: 0.5416, Train Acc: 0.800000011920929, Test Acc: 0.5543650984764099\n",
      "Epoch [13/50], Loss: 0.5306, Train Acc: 0.8416666388511658, Test Acc: 0.5369047522544861\n",
      "Epoch [14/50], Loss: 0.5274, Train Acc: 0.875, Test Acc: 0.5440475940704346\n",
      "Epoch [15/50], Loss: 0.5159, Train Acc: 0.8638888597488403, Test Acc: 0.5535714030265808\n",
      "New best acc: 0.5553571581840515 epoch 15\n",
      "Epoch [16/50], Loss: 0.5096, Train Acc: 0.8833333253860474, Test Acc: 0.5553571581840515\n",
      "New best acc: 0.5634920597076416 epoch 16\n",
      "Epoch [17/50], Loss: 0.5016, Train Acc: 0.894444465637207, Test Acc: 0.5634920597076416\n",
      "Epoch [18/50], Loss: 0.5010, Train Acc: 0.9222221970558167, Test Acc: 0.5577380657196045\n",
      "Epoch [19/50], Loss: 0.4914, Train Acc: 0.949999988079071, Test Acc: 0.5521825551986694\n",
      "Epoch [20/50], Loss: 0.4895, Train Acc: 0.9472222328186035, Test Acc: 0.5537698268890381\n",
      "Epoch [21/50], Loss: 0.4801, Train Acc: 0.9555555582046509, Test Acc: 0.5545634627342224\n",
      "Epoch [22/50], Loss: 0.4778, Train Acc: 0.9638888835906982, Test Acc: 0.5577380657196045\n",
      "Epoch [23/50], Loss: 0.4740, Train Acc: 0.9583333134651184, Test Acc: 0.5551587343215942\n",
      "Epoch [24/50], Loss: 0.4703, Train Acc: 0.9777777791023254, Test Acc: 0.5472221970558167\n",
      "Epoch [25/50], Loss: 0.4661, Train Acc: 0.9861111044883728, Test Acc: 0.5527777671813965\n",
      "Epoch [26/50], Loss: 0.4623, Train Acc: 0.980555534362793, Test Acc: 0.557539701461792\n",
      "Epoch [27/50], Loss: 0.4639, Train Acc: 0.9888888597488403, Test Acc: 0.5537698268890381\n",
      "Epoch [28/50], Loss: 0.4618, Train Acc: 0.9888888597488403, Test Acc: 0.5511904954910278\n",
      "Epoch [29/50], Loss: 0.4571, Train Acc: 0.9861111044883728, Test Acc: 0.5527777671813965\n",
      "Epoch [30/50], Loss: 0.4574, Train Acc: 0.9888888597488403, Test Acc: 0.5571428537368774\n",
      "Epoch [31/50], Loss: 0.4526, Train Acc: 0.9888888597488403, Test Acc: 0.5539682507514954\n",
      "Epoch [32/50], Loss: 0.4498, Train Acc: 0.9916666746139526, Test Acc: 0.5609126687049866\n",
      "Epoch [33/50], Loss: 0.4552, Train Acc: 0.9916666746139526, Test Acc: 0.5569444298744202\n",
      "Epoch [34/50], Loss: 0.4491, Train Acc: 0.9972222447395325, Test Acc: 0.5537698268890381\n",
      "Epoch [35/50], Loss: 0.4436, Train Acc: 1.0, Test Acc: 0.5565476417541504\n",
      "Epoch [36/50], Loss: 0.4471, Train Acc: 0.9944444298744202, Test Acc: 0.5609126687049866\n",
      "Epoch [37/50], Loss: 0.4426, Train Acc: 0.9944444298744202, Test Acc: 0.5557539463043213\n",
      "Epoch [38/50], Loss: 0.4392, Train Acc: 0.9944444298744202, Test Acc: 0.5587301850318909\n",
      "Epoch [39/50], Loss: 0.4386, Train Acc: 0.9972222447395325, Test Acc: 0.5585317611694336\n",
      "Epoch [40/50], Loss: 0.4367, Train Acc: 1.0, Test Acc: 0.558134913444519\n",
      "Epoch [41/50], Loss: 0.4333, Train Acc: 0.9944444298744202, Test Acc: 0.5559523701667786\n",
      "Epoch [42/50], Loss: 0.4345, Train Acc: 0.9972222447395325, Test Acc: 0.5587301850318909\n",
      "Epoch [43/50], Loss: 0.4340, Train Acc: 0.9916666746139526, Test Acc: 0.5601190328598022\n",
      "New best acc: 0.5684523582458496 epoch 43\n",
      "Epoch [44/50], Loss: 0.4330, Train Acc: 0.9972222447395325, Test Acc: 0.5684523582458496\n",
      "Epoch [45/50], Loss: 0.4259, Train Acc: 0.9944444298744202, Test Acc: 0.5605158805847168\n",
      "Epoch [46/50], Loss: 0.4257, Train Acc: 0.9916666746139526, Test Acc: 0.563095211982727\n",
      "Epoch [47/50], Loss: 0.4253, Train Acc: 0.9944444298744202, Test Acc: 0.5571428537368774\n",
      "Epoch [48/50], Loss: 0.4206, Train Acc: 1.0, Test Acc: 0.5563492178916931\n",
      "Epoch [49/50], Loss: 0.4213, Train Acc: 1.0, Test Acc: 0.5601190328598022\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-04 00:39:11,063] Trial 16 finished with value: 0.5684523582458496 and parameters: {'batch_size': 1530, 'lr': 0.002308478596187016}. Best is trial 14 with value: 0.5692460536956787.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [50/50], Loss: 0.4244, Train Acc: 0.9944444298744202, Test Acc: 0.5567460060119629\n",
      "New best acc: 0.5061507821083069 epoch 0\n",
      "Epoch [1/50], Loss: 0.8512, Train Acc: 0.49444442987442017, Test Acc: 0.5061507821083069\n",
      "Epoch [2/50], Loss: 0.8286, Train Acc: 0.45277777314186096, Test Acc: 0.49662697315216064\n",
      "Epoch [3/50], Loss: 0.8063, Train Acc: 0.519444465637207, Test Acc: 0.5\n",
      "New best acc: 0.5085317492485046 epoch 3\n",
      "Epoch [4/50], Loss: 0.7813, Train Acc: 0.5111111402511597, Test Acc: 0.5085317492485046\n",
      "New best acc: 0.5111111402511597 epoch 4\n",
      "Epoch [5/50], Loss: 0.7713, Train Acc: 0.5138888955116272, Test Acc: 0.5111111402511597\n",
      "Epoch [6/50], Loss: 0.7558, Train Acc: 0.4972222149372101, Test Acc: 0.5007936358451843\n",
      "New best acc: 0.5196428298950195 epoch 6\n",
      "Epoch [7/50], Loss: 0.7401, Train Acc: 0.5694444179534912, Test Acc: 0.5196428298950195\n",
      "Epoch [8/50], Loss: 0.7419, Train Acc: 0.5694444179534912, Test Acc: 0.5019841194152832\n",
      "Epoch [9/50], Loss: 0.7335, Train Acc: 0.5611110925674438, Test Acc: 0.504960298538208\n",
      "Epoch [10/50], Loss: 0.7153, Train Acc: 0.5055555701255798, Test Acc: 0.5041666626930237\n",
      "Epoch [11/50], Loss: 0.7188, Train Acc: 0.5583333373069763, Test Acc: 0.5055555701255798\n",
      "Epoch [12/50], Loss: 0.7089, Train Acc: 0.550000011920929, Test Acc: 0.5109127163887024\n",
      "Epoch [13/50], Loss: 0.7070, Train Acc: 0.5944444537162781, Test Acc: 0.4980158805847168\n",
      "Epoch [14/50], Loss: 0.6951, Train Acc: 0.6083333492279053, Test Acc: 0.5134920477867126\n",
      "Epoch [15/50], Loss: 0.6921, Train Acc: 0.5277777910232544, Test Acc: 0.5115079283714294\n",
      "New best acc: 0.528769850730896 epoch 15\n",
      "Epoch [16/50], Loss: 0.6868, Train Acc: 0.5944444537162781, Test Acc: 0.528769850730896\n",
      "Epoch [17/50], Loss: 0.6852, Train Acc: 0.5861111283302307, Test Acc: 0.5186507701873779\n",
      "Epoch [18/50], Loss: 0.6754, Train Acc: 0.6027777791023254, Test Acc: 0.5081349015235901\n",
      "Epoch [19/50], Loss: 0.6666, Train Acc: 0.6111111044883728, Test Acc: 0.5121031999588013\n",
      "Epoch [20/50], Loss: 0.6661, Train Acc: 0.5805555582046509, Test Acc: 0.5142857432365417\n",
      "Epoch [21/50], Loss: 0.6452, Train Acc: 0.5527777671813965, Test Acc: 0.5206349492073059\n",
      "Epoch [22/50], Loss: 0.6456, Train Acc: 0.5805555582046509, Test Acc: 0.5148809552192688\n",
      "Epoch [23/50], Loss: 0.6386, Train Acc: 0.5944444537162781, Test Acc: 0.5138888955116272\n",
      "Epoch [24/50], Loss: 0.6429, Train Acc: 0.6000000238418579, Test Acc: 0.5251984000205994\n",
      "Epoch [25/50], Loss: 0.6249, Train Acc: 0.5861111283302307, Test Acc: 0.5132936239242554\n",
      "Epoch [26/50], Loss: 0.6251, Train Acc: 0.6222222447395325, Test Acc: 0.5170634984970093\n",
      "Epoch [27/50], Loss: 0.6201, Train Acc: 0.6361111402511597, Test Acc: 0.5047619342803955\n",
      "New best acc: 0.5315476059913635 epoch 27\n",
      "Epoch [28/50], Loss: 0.6132, Train Acc: 0.625, Test Acc: 0.5315476059913635\n",
      "Epoch [29/50], Loss: 0.6074, Train Acc: 0.6499999761581421, Test Acc: 0.5222222208976746\n",
      "Epoch [30/50], Loss: 0.5945, Train Acc: 0.6638888716697693, Test Acc: 0.5204365253448486\n",
      "New best acc: 0.533134937286377 epoch 30\n",
      "Epoch [31/50], Loss: 0.6078, Train Acc: 0.6583333611488342, Test Acc: 0.533134937286377\n",
      "Epoch [32/50], Loss: 0.5909, Train Acc: 0.6638888716697693, Test Acc: 0.5186507701873779\n",
      "Epoch [33/50], Loss: 0.5966, Train Acc: 0.6944444179534912, Test Acc: 0.5317460298538208\n",
      "Epoch [34/50], Loss: 0.5892, Train Acc: 0.6333333253860474, Test Acc: 0.5307539701461792\n",
      "Epoch [35/50], Loss: 0.5943, Train Acc: 0.6777777671813965, Test Acc: 0.5285714268684387\n",
      "Epoch [36/50], Loss: 0.5856, Train Acc: 0.7250000238418579, Test Acc: 0.5275793671607971\n",
      "Epoch [37/50], Loss: 0.5788, Train Acc: 0.6944444179534912, Test Acc: 0.5273809432983398\n",
      "Epoch [38/50], Loss: 0.5774, Train Acc: 0.7444444298744202, Test Acc: 0.5156745910644531\n",
      "New best acc: 0.5339285731315613 epoch 38\n",
      "Epoch [39/50], Loss: 0.5782, Train Acc: 0.6638888716697693, Test Acc: 0.5339285731315613\n",
      "Epoch [40/50], Loss: 0.5834, Train Acc: 0.7277777791023254, Test Acc: 0.523809552192688\n",
      "New best acc: 0.5384920835494995 epoch 40\n",
      "Epoch [41/50], Loss: 0.5776, Train Acc: 0.6777777671813965, Test Acc: 0.5384920835494995\n",
      "Epoch [42/50], Loss: 0.5647, Train Acc: 0.7388888597488403, Test Acc: 0.5230158567428589\n",
      "Epoch [43/50], Loss: 0.5672, Train Acc: 0.75, Test Acc: 0.5263888835906982\n",
      "Epoch [44/50], Loss: 0.5697, Train Acc: 0.7388888597488403, Test Acc: 0.5309523940086365\n",
      "New best acc: 0.5402777791023254 epoch 44\n",
      "Epoch [45/50], Loss: 0.5616, Train Acc: 0.7527777552604675, Test Acc: 0.5402777791023254\n",
      "New best acc: 0.5432539582252502 epoch 45\n",
      "Epoch [46/50], Loss: 0.5507, Train Acc: 0.7527777552604675, Test Acc: 0.5432539582252502\n",
      "New best acc: 0.5519841313362122 epoch 46\n",
      "Epoch [47/50], Loss: 0.5660, Train Acc: 0.7527777552604675, Test Acc: 0.5519841313362122\n",
      "Epoch [48/50], Loss: 0.5573, Train Acc: 0.7388888597488403, Test Acc: 0.5281745791435242\n",
      "Epoch [49/50], Loss: 0.5571, Train Acc: 0.7638888955116272, Test Acc: 0.5357142686843872\n",
      "Epoch [50/50], Loss: 0.5564, Train Acc: 0.7666666507720947, Test Acc: 0.5311508178710938\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-04 00:39:21,118] Trial 17 finished with value: 0.5519841313362122 and parameters: {'batch_size': 1544, 'lr': 0.00028669913937777523}. Best is trial 14 with value: 0.5692460536956787.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best acc: 0.5091269612312317 epoch 0\n",
      "Epoch [1/50], Loss: 0.8448, Train Acc: 0.5055555701255798, Test Acc: 0.5091269612312317\n",
      "Epoch [2/50], Loss: 0.7629, Train Acc: 0.5611110925674438, Test Acc: 0.5009920597076416\n",
      "Epoch [3/50], Loss: 0.7187, Train Acc: 0.5888888835906982, Test Acc: 0.5073412656784058\n",
      "New best acc: 0.5130952596664429 epoch 3\n",
      "Epoch [4/50], Loss: 0.6954, Train Acc: 0.5972222089767456, Test Acc: 0.5130952596664429\n",
      "New best acc: 0.521230161190033 epoch 4\n",
      "Epoch [5/50], Loss: 0.6591, Train Acc: 0.6027777791023254, Test Acc: 0.521230161190033\n",
      "New best acc: 0.5295634865760803 epoch 5\n",
      "Epoch [6/50], Loss: 0.6361, Train Acc: 0.6000000238418579, Test Acc: 0.5295634865760803\n",
      "Epoch [7/50], Loss: 0.6128, Train Acc: 0.6583333611488342, Test Acc: 0.5134920477867126\n",
      "Epoch [8/50], Loss: 0.5944, Train Acc: 0.6166666746139526, Test Acc: 0.5224206447601318\n",
      "New best acc: 0.5378968119621277 epoch 8\n",
      "Epoch [9/50], Loss: 0.5886, Train Acc: 0.6861110925674438, Test Acc: 0.5378968119621277\n",
      "Epoch [10/50], Loss: 0.5782, Train Acc: 0.7194444537162781, Test Acc: 0.5285714268684387\n",
      "New best acc: 0.5416666865348816 epoch 10\n",
      "Epoch [11/50], Loss: 0.5667, Train Acc: 0.7555555701255798, Test Acc: 0.5416666865348816\n",
      "Epoch [12/50], Loss: 0.5680, Train Acc: 0.7666666507720947, Test Acc: 0.533134937286377\n",
      "New best acc: 0.5448412895202637 epoch 12\n",
      "Epoch [13/50], Loss: 0.5527, Train Acc: 0.7972221970558167, Test Acc: 0.5448412895202637\n",
      "New best acc: 0.5450396537780762 epoch 13\n",
      "Epoch [14/50], Loss: 0.5586, Train Acc: 0.7722222208976746, Test Acc: 0.5450396537780762\n",
      "Epoch [15/50], Loss: 0.5345, Train Acc: 0.8166666626930237, Test Acc: 0.5426587462425232\n",
      "New best acc: 0.5515872836112976 epoch 15\n",
      "Epoch [16/50], Loss: 0.5339, Train Acc: 0.8444444537162781, Test Acc: 0.5515872836112976\n",
      "Epoch [17/50], Loss: 0.5220, Train Acc: 0.8444444537162781, Test Acc: 0.5494047403335571\n",
      "Epoch [18/50], Loss: 0.5167, Train Acc: 0.8888888955116272, Test Acc: 0.5428571701049805\n",
      "New best acc: 0.553174614906311 epoch 18\n",
      "Epoch [19/50], Loss: 0.5137, Train Acc: 0.9111111164093018, Test Acc: 0.553174614906311\n",
      "New best acc: 0.5561507940292358 epoch 19\n",
      "Epoch [20/50], Loss: 0.5024, Train Acc: 0.9222221970558167, Test Acc: 0.5561507940292358\n",
      "Epoch [21/50], Loss: 0.4960, Train Acc: 0.9333333373069763, Test Acc: 0.5468254089355469\n",
      "Epoch [22/50], Loss: 0.4939, Train Acc: 0.9361110925674438, Test Acc: 0.5442460179328918\n",
      "New best acc: 0.5605158805847168 epoch 22\n",
      "Epoch [23/50], Loss: 0.4901, Train Acc: 0.9361110925674438, Test Acc: 0.5605158805847168\n",
      "Epoch [24/50], Loss: 0.4848, Train Acc: 0.9611111283302307, Test Acc: 0.5527777671813965\n",
      "New best acc: 0.5609126687049866 epoch 24\n",
      "Epoch [25/50], Loss: 0.4813, Train Acc: 0.980555534362793, Test Acc: 0.5609126687049866\n",
      "Epoch [26/50], Loss: 0.4738, Train Acc: 0.980555534362793, Test Acc: 0.5507936477661133\n",
      "Epoch [27/50], Loss: 0.4737, Train Acc: 0.9833333492279053, Test Acc: 0.5535714030265808\n",
      "Epoch [28/50], Loss: 0.4654, Train Acc: 0.980555534362793, Test Acc: 0.5507936477661133\n",
      "Epoch [29/50], Loss: 0.4639, Train Acc: 0.9833333492279053, Test Acc: 0.5557539463043213\n",
      "Epoch [30/50], Loss: 0.4605, Train Acc: 0.9888888597488403, Test Acc: 0.5490079522132874\n",
      "Epoch [31/50], Loss: 0.4568, Train Acc: 0.9861111044883728, Test Acc: 0.5527777671813965\n",
      "Epoch [32/50], Loss: 0.4582, Train Acc: 0.9833333492279053, Test Acc: 0.5579364895820618\n",
      "Epoch [33/50], Loss: 0.4534, Train Acc: 0.9888888597488403, Test Acc: 0.5484126806259155\n",
      "Epoch [34/50], Loss: 0.4484, Train Acc: 0.9888888597488403, Test Acc: 0.559920608997345\n",
      "Epoch [35/50], Loss: 0.4485, Train Acc: 0.9944444298744202, Test Acc: 0.5547618865966797\n",
      "Epoch [36/50], Loss: 0.4431, Train Acc: 0.9888888597488403, Test Acc: 0.5585317611694336\n",
      "Epoch [37/50], Loss: 0.4449, Train Acc: 0.9833333492279053, Test Acc: 0.5535714030265808\n",
      "Epoch [38/50], Loss: 0.4421, Train Acc: 0.9972222447395325, Test Acc: 0.557539701461792\n",
      "Epoch [39/50], Loss: 0.4450, Train Acc: 0.9916666746139526, Test Acc: 0.5563492178916931\n",
      "Epoch [40/50], Loss: 0.4376, Train Acc: 0.9972222447395325, Test Acc: 0.5488095283508301\n",
      "Epoch [41/50], Loss: 0.4364, Train Acc: 0.9972222447395325, Test Acc: 0.5561507940292358\n",
      "Epoch [42/50], Loss: 0.4333, Train Acc: 0.9916666746139526, Test Acc: 0.5569444298744202\n",
      "New best acc: 0.5623015761375427 epoch 42\n",
      "Epoch [43/50], Loss: 0.4292, Train Acc: 0.9972222447395325, Test Acc: 0.5623015761375427\n",
      "Epoch [44/50], Loss: 0.4301, Train Acc: 0.9944444298744202, Test Acc: 0.5595238208770752\n",
      "Epoch [45/50], Loss: 0.4353, Train Acc: 0.9944444298744202, Test Acc: 0.5565476417541504\n",
      "Epoch [46/50], Loss: 0.4255, Train Acc: 0.9944444298744202, Test Acc: 0.559920608997345\n",
      "Epoch [47/50], Loss: 0.4227, Train Acc: 0.9972222447395325, Test Acc: 0.5541666746139526\n",
      "Epoch [48/50], Loss: 0.4230, Train Acc: 1.0, Test Acc: 0.5523809790611267\n",
      "Epoch [49/50], Loss: 0.4234, Train Acc: 0.9972222447395325, Test Acc: 0.5519841313362122\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-04 00:39:31,165] Trial 18 finished with value: 0.5623015761375427 and parameters: {'batch_size': 636, 'lr': 0.0017073184922181198}. Best is trial 14 with value: 0.5692460536956787.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [50/50], Loss: 0.4193, Train Acc: 0.9944444298744202, Test Acc: 0.5519841313362122\n",
      "New best acc: 0.49940475821495056 epoch 0\n",
      "Epoch [1/50], Loss: 0.8423, Train Acc: 0.5638889074325562, Test Acc: 0.49940475821495056\n",
      "New best acc: 0.5013889074325562 epoch 1\n",
      "Epoch [2/50], Loss: 0.8234, Train Acc: 0.5027777552604675, Test Acc: 0.5013889074325562\n",
      "Epoch [3/50], Loss: 0.8058, Train Acc: 0.49444442987442017, Test Acc: 0.48948413133621216\n",
      "Epoch [4/50], Loss: 0.7886, Train Acc: 0.5083333253860474, Test Acc: 0.49761903285980225\n",
      "New best acc: 0.5146825313568115 epoch 4\n",
      "Epoch [5/50], Loss: 0.7826, Train Acc: 0.5166666507720947, Test Acc: 0.5146825313568115\n",
      "Epoch [6/50], Loss: 0.7751, Train Acc: 0.5361111164093018, Test Acc: 0.5089285969734192\n",
      "Epoch [7/50], Loss: 0.7617, Train Acc: 0.519444465637207, Test Acc: 0.502579391002655\n",
      "Epoch [8/50], Loss: 0.7570, Train Acc: 0.5583333373069763, Test Acc: 0.4968253970146179\n",
      "Epoch [9/50], Loss: 0.7400, Train Acc: 0.5305555462837219, Test Acc: 0.5065476298332214\n",
      "New best acc: 0.5152778029441833 epoch 9\n",
      "Epoch [10/50], Loss: 0.7419, Train Acc: 0.5388888716697693, Test Acc: 0.5152778029441833\n",
      "Epoch [11/50], Loss: 0.7327, Train Acc: 0.5333333611488342, Test Acc: 0.5007936358451843\n",
      "Epoch [12/50], Loss: 0.7299, Train Acc: 0.5416666865348816, Test Acc: 0.5009920597076416\n",
      "New best acc: 0.521230161190033 epoch 12\n",
      "Epoch [13/50], Loss: 0.7190, Train Acc: 0.5666666626930237, Test Acc: 0.521230161190033\n",
      "Epoch [14/50], Loss: 0.7209, Train Acc: 0.5472221970558167, Test Acc: 0.5055555701255798\n",
      "New best acc: 0.5230158567428589 epoch 14\n",
      "Epoch [15/50], Loss: 0.7046, Train Acc: 0.5611110925674438, Test Acc: 0.5230158567428589\n",
      "Epoch [16/50], Loss: 0.7000, Train Acc: 0.5527777671813965, Test Acc: 0.507539689540863\n",
      "Epoch [17/50], Loss: 0.7020, Train Acc: 0.5888888835906982, Test Acc: 0.5071428418159485\n",
      "Epoch [18/50], Loss: 0.6910, Train Acc: 0.5361111164093018, Test Acc: 0.5033730268478394\n",
      "Epoch [19/50], Loss: 0.6877, Train Acc: 0.6111111044883728, Test Acc: 0.5198412537574768\n",
      "Epoch [20/50], Loss: 0.6786, Train Acc: 0.6305555701255798, Test Acc: 0.5061507821083069\n",
      "Epoch [21/50], Loss: 0.6852, Train Acc: 0.6027777791023254, Test Acc: 0.5138888955116272\n",
      "Epoch [22/50], Loss: 0.6703, Train Acc: 0.6166666746139526, Test Acc: 0.5144841074943542\n",
      "Epoch [23/50], Loss: 0.6674, Train Acc: 0.6166666746139526, Test Acc: 0.5186507701873779\n",
      "Epoch [24/50], Loss: 0.6570, Train Acc: 0.5777778029441833, Test Acc: 0.519444465637207\n",
      "Epoch [25/50], Loss: 0.6588, Train Acc: 0.5833333134651184, Test Acc: 0.5087301731109619\n",
      "Epoch [26/50], Loss: 0.6601, Train Acc: 0.5611110925674438, Test Acc: 0.5164682269096375\n",
      "Epoch [27/50], Loss: 0.6455, Train Acc: 0.5416666865348816, Test Acc: 0.5178571343421936\n",
      "Epoch [28/50], Loss: 0.6452, Train Acc: 0.5777778029441833, Test Acc: 0.5117063522338867\n",
      "New best acc: 0.5240079164505005 epoch 28\n",
      "Epoch [29/50], Loss: 0.6420, Train Acc: 0.5888888835906982, Test Acc: 0.5240079164505005\n",
      "Epoch [30/50], Loss: 0.6324, Train Acc: 0.6000000238418579, Test Acc: 0.5047619342803955\n",
      "Epoch [31/50], Loss: 0.6306, Train Acc: 0.5666666626930237, Test Acc: 0.5208333134651184\n",
      "Epoch [32/50], Loss: 0.6295, Train Acc: 0.6222222447395325, Test Acc: 0.5089285969734192\n",
      "Epoch [33/50], Loss: 0.6295, Train Acc: 0.6222222447395325, Test Acc: 0.5224206447601318\n",
      "New best acc: 0.5319444537162781 epoch 33\n",
      "Epoch [34/50], Loss: 0.6215, Train Acc: 0.6083333492279053, Test Acc: 0.5319444537162781\n",
      "Epoch [35/50], Loss: 0.6121, Train Acc: 0.605555534362793, Test Acc: 0.5279762148857117\n",
      "Epoch [36/50], Loss: 0.6176, Train Acc: 0.625, Test Acc: 0.5174603462219238\n",
      "Epoch [37/50], Loss: 0.6125, Train Acc: 0.6277777552604675, Test Acc: 0.5242063403129578\n",
      "Epoch [38/50], Loss: 0.6057, Train Acc: 0.6305555701255798, Test Acc: 0.5140873193740845\n",
      "Epoch [39/50], Loss: 0.6066, Train Acc: 0.6111111044883728, Test Acc: 0.5269841551780701\n",
      "Epoch [40/50], Loss: 0.6010, Train Acc: 0.6416666507720947, Test Acc: 0.5113095045089722\n",
      "Epoch [41/50], Loss: 0.6007, Train Acc: 0.644444465637207, Test Acc: 0.5291666388511658\n",
      "Epoch [42/50], Loss: 0.6049, Train Acc: 0.6472222208976746, Test Acc: 0.5105158686637878\n",
      "Epoch [43/50], Loss: 0.5955, Train Acc: 0.6277777552604675, Test Acc: 0.5188491940498352\n",
      "New best acc: 0.5349206328392029 epoch 43\n",
      "Epoch [44/50], Loss: 0.5971, Train Acc: 0.6388888955116272, Test Acc: 0.5349206328392029\n",
      "Epoch [45/50], Loss: 0.5901, Train Acc: 0.6305555701255798, Test Acc: 0.5232142806053162\n",
      "Epoch [46/50], Loss: 0.5977, Train Acc: 0.6111111044883728, Test Acc: 0.5303571224212646\n",
      "Epoch [47/50], Loss: 0.5869, Train Acc: 0.6666666865348816, Test Acc: 0.5107142925262451\n",
      "Epoch [48/50], Loss: 0.5919, Train Acc: 0.699999988079071, Test Acc: 0.5321428775787354\n",
      "Epoch [49/50], Loss: 0.5863, Train Acc: 0.6694444417953491, Test Acc: 0.5277777910232544\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-04 00:39:41,235] Trial 19 finished with value: 0.5349206328392029 and parameters: {'batch_size': 1469, 'lr': 0.00020622740903339162}. Best is trial 14 with value: 0.5692460536956787.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [50/50], Loss: 0.5802, Train Acc: 0.6388888955116272, Test Acc: 0.5198412537574768\n",
      "{'batch_size': 1738, 'lr': 0.0016801991703897096}\n"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=20)\n",
    "print(study.best_params)\n",
    "# {'batch_size': 578, 'lr': 0.0004021431860941115}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human 1 best acc: 0.894444465637207\n",
      "Human 2 best acc: 0.8861111402511597\n",
      "Human 3 best acc: 0.9111111164093018\n",
      "Human 4 best acc: 0.7749999761581421\n",
      "Human 5 best acc: 0.8583333492279053\n",
      "Human 6 best acc: 0.9416666626930237\n",
      "Human 7 best acc: 0.5805555582046509\n",
      "Human 8 best acc: 0.5722222328186035\n",
      "Human 9 best acc: 0.8416666388511658\n",
      "Human 10 best acc: 0.8833333253860474\n",
      "Human 11 best acc: 0.8666666746139526\n",
      "Human 12 best acc: 0.9194444417953491\n",
      "Human 13 best acc: 0.8222222328186035\n",
      "Human 14 best acc: 0.5555555820465088\n",
      "Mean acc: 0.8077380061149597\n",
      "Human 0 best acc: 0.9166666865348816\n",
      "Human 2 best acc: 0.9111111164093018\n",
      "Human 3 best acc: 0.8999999761581421\n",
      "Human 4 best acc: 0.7666666507720947\n",
      "Human 5 best acc: 0.8444444537162781\n",
      "Human 6 best acc: 0.9305555820465088\n",
      "Human 7 best acc: 0.8777777552604675\n",
      "Human 8 best acc: 0.8500000238418579\n",
      "Human 9 best acc: 0.8805555701255798\n",
      "Human 10 best acc: 0.8888888955116272\n",
      "Human 11 best acc: 0.8444444537162781\n",
      "Human 12 best acc: 0.9333333373069763\n",
      "Human 13 best acc: 0.8388888835906982\n",
      "Human 14 best acc: 0.5861111283302307\n",
      "Mean acc: 0.8313491940498352\n",
      "Human 0 best acc: 0.9027777910232544\n",
      "Human 1 best acc: 0.8722222447395325\n",
      "Human 3 best acc: 0.9166666865348816\n",
      "Human 4 best acc: 0.5638889074325562\n",
      "Human 5 best acc: 0.8527777791023254\n",
      "Human 6 best acc: 0.9333333373069763\n",
      "Human 7 best acc: 0.5472221970558167\n",
      "Human 8 best acc: 0.8777777552604675\n",
      "Human 9 best acc: 0.875\n",
      "Human 10 best acc: 0.9027777910232544\n",
      "Human 11 best acc: 0.8277778029441833\n",
      "Human 12 best acc: 0.9527778029441833\n",
      "Human 13 best acc: 0.8305555582046509\n",
      "Human 14 best acc: 0.5638889074325562\n",
      "Mean acc: 0.8261243104934692\n",
      "Human 0 best acc: 0.8861111402511597\n",
      "Human 1 best acc: 0.8999999761581421\n",
      "Human 2 best acc: 0.8694444298744202\n",
      "Human 4 best acc: 0.7972221970558167\n",
      "Human 5 best acc: 0.8805555701255798\n",
      "Human 6 best acc: 0.9444444179534912\n",
      "Human 7 best acc: 0.5444444417953491\n",
      "Human 8 best acc: 0.5694444179534912\n",
      "Human 9 best acc: 0.8638888597488403\n",
      "Human 10 best acc: 0.8888888955116272\n",
      "Human 11 best acc: 0.8611111044883728\n",
      "Human 12 best acc: 0.9222221970558167\n",
      "Human 13 best acc: 0.8583333492279053\n",
      "Human 14 best acc: 0.5305555462837219\n",
      "Mean acc: 0.8216765522956848\n",
      "Human 0 best acc: 0.855555534362793\n",
      "Human 1 best acc: 0.8972222208976746\n",
      "Human 2 best acc: 0.9111111164093018\n",
      "Human 3 best acc: 0.9027777910232544\n",
      "Human 5 best acc: 0.8583333492279053\n",
      "Human 6 best acc: 0.9361110925674438\n",
      "Human 7 best acc: 0.8694444298744202\n",
      "Human 8 best acc: 0.8583333492279053\n",
      "Human 9 best acc: 0.8305555582046509\n",
      "Human 10 best acc: 0.8861111402511597\n",
      "Human 11 best acc: 0.8500000238418579\n",
      "Human 12 best acc: 0.949999988079071\n",
      "Human 13 best acc: 0.8500000238418579\n",
      "Human 14 best acc: 0.550000011920929\n",
      "Mean acc: 0.8288491368293762\n",
      "Human 0 best acc: 0.8777777552604675\n",
      "Human 1 best acc: 0.8694444298744202\n",
      "Human 2 best acc: 0.8888888955116272\n",
      "Human 3 best acc: 0.8999999761581421\n",
      "Human 4 best acc: 0.7833333611488342\n",
      "Human 6 best acc: 0.9277777671813965\n",
      "Human 7 best acc: 0.5361111164093018\n",
      "Human 8 best acc: 0.855555534362793\n",
      "Human 9 best acc: 0.8388888835906982\n",
      "Human 10 best acc: 0.8722222447395325\n",
      "Human 11 best acc: 0.8722222447395325\n",
      "Human 12 best acc: 0.9472222328186035\n",
      "Human 13 best acc: 0.8222222328186035\n",
      "Human 14 best acc: 0.5861111283302307\n",
      "Mean acc: 0.8285383582115173\n",
      "Human 0 best acc: 0.9027777910232544\n",
      "Human 1 best acc: 0.9055555462837219\n",
      "Human 2 best acc: 0.8999999761581421\n",
      "Human 3 best acc: 0.8999999761581421\n",
      "Human 4 best acc: 0.7888888716697693\n",
      "Human 5 best acc: 0.8861111402511597\n",
      "Human 7 best acc: 0.5305555462837219\n",
      "Human 8 best acc: 0.5694444179534912\n",
      "Human 9 best acc: 0.8333333134651184\n",
      "Human 10 best acc: 0.9138888716697693\n",
      "Human 11 best acc: 0.824999988079071\n",
      "Human 12 best acc: 0.9277777671813965\n",
      "Human 13 best acc: 0.8388888835906982\n",
      "Human 14 best acc: 0.5527777671813965\n",
      "Mean acc: 0.8252267837524414\n",
      "Human 0 best acc: 0.894444465637207\n",
      "Human 1 best acc: 0.8999999761581421\n",
      "Human 2 best acc: 0.8777777552604675\n",
      "Human 3 best acc: 0.9166666865348816\n",
      "Human 4 best acc: 0.7916666865348816\n",
      "Human 5 best acc: 0.8388888835906982\n",
      "Human 6 best acc: 0.9194444417953491\n",
      "Human 8 best acc: 0.8888888955116272\n",
      "Human 9 best acc: 0.8833333253860474\n",
      "Human 10 best acc: 0.875\n",
      "Human 11 best acc: 0.8583333492279053\n",
      "Human 12 best acc: 0.9166666865348816\n",
      "Human 13 best acc: 0.8611111044883728\n",
      "Human 14 best acc: 0.5722222328186035\n",
      "Mean acc: 0.8291667103767395\n",
      "Human 0 best acc: 0.8916666507720947\n",
      "Human 1 best acc: 0.9055555462837219\n",
      "Human 2 best acc: 0.8972222208976746\n",
      "Human 3 best acc: 0.9083333611488342\n",
      "Human 4 best acc: 0.7749999761581421\n",
      "Human 5 best acc: 0.8833333253860474\n",
      "Human 6 best acc: 0.949999988079071\n",
      "Human 7 best acc: 0.5305555462837219\n",
      "Human 9 best acc: 0.855555534362793\n",
      "Human 10 best acc: 0.8694444298744202\n",
      "Human 11 best acc: 0.8638888597488403\n",
      "Human 12 best acc: 0.949999988079071\n",
      "Human 13 best acc: 0.8666666746139526\n",
      "Human 14 best acc: 0.5583333373069763\n",
      "Mean acc: 0.8299382328987122\n",
      "Human 0 best acc: 0.875\n",
      "Human 1 best acc: 0.8972222208976746\n",
      "Human 2 best acc: 0.8722222447395325\n",
      "Human 3 best acc: 0.8999999761581421\n",
      "Human 4 best acc: 0.7777777910232544\n",
      "Human 5 best acc: 0.8416666388511658\n",
      "Human 6 best acc: 0.925000011920929\n",
      "Human 7 best acc: 0.5472221970558167\n",
      "Human 8 best acc: 0.8444444537162781\n",
      "Human 10 best acc: 0.9222221970558167\n",
      "Human 11 best acc: 0.8500000238418579\n",
      "Human 12 best acc: 0.9194444417953491\n",
      "Human 13 best acc: 0.8194444179534912\n",
      "Human 14 best acc: 0.5416666865348816\n",
      "Mean acc: 0.8293253779411316\n",
      "Human 0 best acc: 0.8916666507720947\n",
      "Human 1 best acc: 0.8888888955116272\n",
      "Human 2 best acc: 0.8777777552604675\n",
      "Human 3 best acc: 0.9361110925674438\n",
      "Human 4 best acc: 0.7527777552604675\n",
      "Human 5 best acc: 0.8416666388511658\n",
      "Human 6 best acc: 0.9194444417953491\n",
      "Human 7 best acc: 0.5638889074325562\n",
      "Human 8 best acc: 0.5694444179534912\n",
      "Human 9 best acc: 0.8694444298744202\n",
      "Human 11 best acc: 0.8638888597488403\n",
      "Human 12 best acc: 0.9388889074325562\n",
      "Human 13 best acc: 0.8500000238418579\n",
      "Human 14 best acc: 0.5666666626930237\n",
      "Mean acc: 0.8275071382522583\n",
      "Human 0 best acc: 0.9222221970558167\n",
      "Human 1 best acc: 0.8583333492279053\n",
      "Human 2 best acc: 0.8999999761581421\n",
      "Human 3 best acc: 0.9277777671813965\n",
      "Human 4 best acc: 0.7722222208976746\n",
      "Human 5 best acc: 0.8388888835906982\n",
      "Human 6 best acc: 0.9361110925674438\n",
      "Human 7 best acc: 0.5444444417953491\n",
      "Human 8 best acc: 0.875\n",
      "Human 9 best acc: 0.8277778029441833\n",
      "Human 10 best acc: 0.894444465637207\n",
      "Human 12 best acc: 0.9333333373069763\n",
      "Human 13 best acc: 0.8527777791023254\n",
      "Human 14 best acc: 0.6027777791023254\n",
      "Mean acc: 0.8281084895133972\n",
      "Human 0 best acc: 0.9361110925674438\n",
      "Human 1 best acc: 0.9222221970558167\n",
      "Human 2 best acc: 0.8777777552604675\n",
      "Human 3 best acc: 0.9194444417953491\n",
      "Human 4 best acc: 0.7444444298744202\n",
      "Human 5 best acc: 0.8666666746139526\n",
      "Human 6 best acc: 0.9388889074325562\n",
      "Human 7 best acc: 0.8611111044883728\n",
      "Human 8 best acc: 0.8916666507720947\n",
      "Human 9 best acc: 0.8527777791023254\n",
      "Human 10 best acc: 0.9055555462837219\n",
      "Human 11 best acc: 0.8472222089767456\n",
      "Human 13 best acc: 0.8416666388511658\n",
      "Human 14 best acc: 0.5777778029441833\n",
      "Mean acc: 0.8302503228187561\n",
      "Human 0 best acc: 0.8999999761581421\n",
      "Human 1 best acc: 0.8777777552604675\n",
      "Human 2 best acc: 0.8999999761581421\n",
      "Human 3 best acc: 0.925000011920929\n",
      "Human 4 best acc: 0.7833333611488342\n",
      "Human 5 best acc: 0.8833333253860474\n",
      "Human 6 best acc: 0.9388889074325562\n",
      "Human 7 best acc: 0.8861111402511597\n",
      "Human 8 best acc: 0.8805555701255798\n",
      "Human 9 best acc: 0.8500000238418579\n",
      "Human 10 best acc: 0.8916666507720947\n",
      "Human 11 best acc: 0.8444444537162781\n",
      "Human 12 best acc: 0.9305555820465088\n",
      "Human 14 best acc: 0.5916666388511658\n",
      "Mean acc: 0.8325963616371155\n",
      "Human 0 best acc: 0.9222221970558167\n",
      "Human 1 best acc: 0.9027777910232544\n",
      "Human 2 best acc: 0.8999999761581421\n",
      "Human 3 best acc: 0.9138888716697693\n",
      "Human 4 best acc: 0.7583333253860474\n",
      "Human 5 best acc: 0.8444444537162781\n",
      "Human 6 best acc: 0.9277777671813965\n",
      "Human 7 best acc: 0.5138888955116272\n",
      "Human 8 best acc: 0.8777777552604675\n",
      "Human 9 best acc: 0.5916666388511658\n",
      "Human 10 best acc: 0.9111111164093018\n",
      "Human 11 best acc: 0.8416666388511658\n",
      "Human 12 best acc: 0.9444444179534912\n",
      "Human 13 best acc: 0.8666666746139526\n",
      "Mean acc: 0.8328835368156433\n"
     ]
    }
   ],
   "source": [
    "accs = []\n",
    "for excluded_human in range(15):\n",
    "    data, labels, groups = load_dataset(\"all_features_4sec_epoch.npy\")\n",
    "    data, labels, groups = flatten_data(data, labels, groups)\n",
    "    scaler = StandardScaler()\n",
    "    data = scaler.fit_transform(data)\n",
    "    data, labels, groups = select_emotions(data, labels, groups, 0, 2)\n",
    "    indices = groups != excluded_human\n",
    "    data = data[indices]\n",
    "    labels = labels[indices]\n",
    "    groups = groups[indices]\n",
    "\n",
    "    for human_test in range(15):\n",
    "        if human_test == excluded_human:\n",
    "            continue\n",
    "        train_data, train_labels, test_data, test_labels = train_test_split(data, labels, groups, human_test)\n",
    "        # Split data into training and testing sets\n",
    "\n",
    "        # Convert to tensors and create dataloaders\n",
    "        batch_size_train = 1024\n",
    "        batch_size_test = 1738\n",
    "\n",
    "        train_data_tensor = torch.tensor(train_data, dtype=torch.float32)\n",
    "        train_labels_tensor = torch.tensor(train_labels, dtype=torch.float32)[..., None]\n",
    "        train_dataset = TensorDataset(train_data_tensor, train_labels_tensor)\n",
    "        train_dataloader = DataLoader(train_dataset, batch_size=batch_size_train, shuffle=True)\n",
    "\n",
    "        test_data_tensor = torch.tensor(test_data, dtype=torch.float32)\n",
    "        test_labels_tensor = torch.tensor(test_labels, dtype=torch.float32)[..., None]\n",
    "        test_dataset = TensorDataset(test_data_tensor, test_labels_tensor)\n",
    "        test_dataloader = DataLoader(test_dataset, batch_size=batch_size_test, shuffle=False)\n",
    "\n",
    "        # Parameters for the autoencoder\n",
    "        lr = 0.0016801991703897096\n",
    "        input_dim = data.shape[1]\n",
    "        encoding_dim = 128  # Set the desired encoding dimension\n",
    "\n",
    "        # Initialize the autoencoder\n",
    "        autoencoder = Autoencoder(input_dim, encoding_dim)\n",
    "\n",
    "        # Initialize weights of the autoencoder\n",
    "        def init_weights(m):\n",
    "            if type(m) == torch.nn.Linear:\n",
    "                torch.nn.init.xavier_uniform_(m.weight)\n",
    "                m.bias.data.fill_(0.01)\n",
    "        autoencoder.apply(init_weights)\n",
    "\n",
    "        # Loss function and optimizer\n",
    "        criterion_enc = torch.nn.MSELoss()\n",
    "        criterion_cls = torch.nn.BCELoss()\n",
    "        optimizer = optim.Adam(autoencoder.parameters(), lr=lr)\n",
    "\n",
    "        # Training loop\n",
    "        num_epochs = 50\n",
    "        best_acc = 0\n",
    "        for epoch in range(num_epochs):\n",
    "            for data_batch, labels_batch in dataloader:\n",
    "                optimizer.zero_grad()\n",
    "                reconstructed, cls = autoencoder(data_batch)\n",
    "                loss1 = criterion_cls(cls, labels_batch) * 0.1\n",
    "                loss2 = criterion_enc(reconstructed, data_batch)\n",
    "                loss = loss1 + loss2\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                reconstructed, cls = autoencoder(data_tensor)\n",
    "                cls = cls > 0.5\n",
    "                train_acc = torch.sum(cls == data_labels) / data_labels.shape[0]\n",
    "                # test acc\n",
    "\n",
    "                reconstructed, cls = autoencoder(test_data_tensor)\n",
    "                cls = cls > 0.5\n",
    "                test_acc = torch.sum(cls == test_labels_tensor) / test_labels.shape[0]\n",
    "                if epoch > 6 and test_acc < 0.5:\n",
    "                    break\n",
    "                if test_acc > best_acc:\n",
    "                    best_acc = test_acc\n",
    "                    torch.save(autoencoder.state_dict(), f\"models/best_autoencoder_{excluded_human}_{human_test}.pt\")\n",
    "                    # print(f\"New best acc: {best_acc} epoch {epoch}\")\n",
    "            # print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}, Train Acc: {train_acc.item()}, Test Acc: {test_acc.item()}')\n",
    "        print(f\"Human {human_test} best acc: {best_acc}\")\n",
    "        accs.append(best_acc)\n",
    "    print(f\"Mean acc: {np.mean(accs)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human 1 best acc: 0.7277777791023254\n",
      "Human 2 best acc: 0.7333333492279053\n",
      "Human 3 best acc: 0.7055555582046509\n",
      "Human 4 best acc: 0.5472221970558167\n",
      "Human 5 best acc: 0.7611111402511597\n",
      "Human 6 best acc: 0.75\n",
      "Human 7 best acc: 0.5416666865348816\n",
      "Human 8 best acc: 0.5333333611488342\n",
      "Human 9 best acc: 0.7416666746139526\n",
      "Human 10 best acc: 0.574999988079071\n",
      "Human 11 best acc: 0.6944444179534912\n",
      "Human 12 best acc: 0.5277777910232544\n",
      "Human 13 best acc: 0.5472221970558167\n",
      "Human 14 best acc: 0.6166666746139526\n",
      "Mean acc: 0.6430555582046509\n",
      "Human 0 best acc: 0.7250000238418579\n",
      "Human 2 best acc: 0.7194444537162781\n",
      "Human 3 best acc: 0.7277777791023254\n",
      "Human 4 best acc: 0.5388888716697693\n",
      "Human 5 best acc: 0.7388888597488403\n",
      "Human 6 best acc: 0.7527777552604675\n",
      "Human 7 best acc: 0.5388888716697693\n",
      "Human 8 best acc: 0.5583333373069763\n",
      "Human 9 best acc: 0.7222222089767456\n",
      "Human 10 best acc: 0.5583333373069763\n",
      "Human 11 best acc: 0.699999988079071\n",
      "Human 12 best acc: 0.5333333611488342\n",
      "Human 13 best acc: 0.5305555462837219\n",
      "Human 14 best acc: 0.625\n",
      "Mean acc: 0.6406745910644531\n",
      "Human 0 best acc: 0.6666666865348816\n",
      "Human 1 best acc: 0.7194444537162781\n",
      "Human 3 best acc: 0.7250000238418579\n",
      "Human 4 best acc: 0.5555555820465088\n",
      "Human 5 best acc: 0.5888888835906982\n",
      "Human 6 best acc: 0.7333333492279053\n",
      "Human 7 best acc: 0.5277777910232544\n",
      "Human 8 best acc: 0.5555555820465088\n",
      "Human 9 best acc: 0.7083333134651184\n",
      "Human 10 best acc: 0.574999988079071\n",
      "Human 11 best acc: 0.699999988079071\n",
      "Human 12 best acc: 0.5277777910232544\n",
      "Human 13 best acc: 0.5416666865348816\n",
      "Human 14 best acc: 0.6083333492279053\n",
      "Mean acc: 0.6238095164299011\n",
      "Human 0 best acc: 0.7027778029441833\n",
      "Human 1 best acc: 0.6972222328186035\n",
      "Human 2 best acc: 0.7333333492279053\n",
      "Human 4 best acc: 0.7083333134651184\n",
      "Human 5 best acc: 0.7722222208976746\n",
      "Human 6 best acc: 0.75\n",
      "Human 7 best acc: 0.5166666507720947\n",
      "Human 8 best acc: 0.5222222208976746\n",
      "Human 9 best acc: 0.7277777791023254\n",
      "Human 10 best acc: 0.6722221970558167\n",
      "Human 11 best acc: 0.7111111283302307\n",
      "Human 12 best acc: 0.5444444417953491\n",
      "Human 13 best acc: 0.550000011920929\n",
      "Human 14 best acc: 0.605555534362793\n",
      "Mean acc: 0.658134937286377\n",
      "Human 0 best acc: 0.6916666626930237\n",
      "Human 1 best acc: 0.7055555582046509\n",
      "Human 2 best acc: 0.7444444298744202\n",
      "Human 3 best acc: 0.7333333492279053\n",
      "Human 5 best acc: 0.7638888955116272\n",
      "Human 6 best acc: 0.7555555701255798\n",
      "Human 7 best acc: 0.5388888716697693\n",
      "Human 8 best acc: 0.5555555820465088\n",
      "Human 9 best acc: 0.7361111044883728\n",
      "Human 10 best acc: 0.5722222328186035\n",
      "Human 11 best acc: 0.675000011920929\n",
      "Human 12 best acc: 0.5388888716697693\n",
      "Human 13 best acc: 0.5138888955116272\n",
      "Human 14 best acc: 0.6138888597488403\n",
      "Mean acc: 0.6527777910232544\n",
      "Human 0 best acc: 0.6722221970558167\n",
      "Human 1 best acc: 0.7361111044883728\n",
      "Human 2 best acc: 0.7361111044883728\n",
      "Human 3 best acc: 0.7166666388511658\n",
      "Human 4 best acc: 0.6888889074325562\n",
      "Human 6 best acc: 0.7638888955116272\n",
      "Human 7 best acc: 0.5416666865348816\n",
      "Human 8 best acc: 0.5638889074325562\n",
      "Human 9 best acc: 0.7277777791023254\n",
      "Human 10 best acc: 0.5722222328186035\n",
      "Human 11 best acc: 0.6888889074325562\n",
      "Human 12 best acc: 0.5416666865348816\n",
      "Human 13 best acc: 0.5388888716697693\n",
      "Human 14 best acc: 0.625\n",
      "Mean acc: 0.6509920358657837\n",
      "Human 0 best acc: 0.6638888716697693\n",
      "Human 1 best acc: 0.7388888597488403\n",
      "Human 2 best acc: 0.7472222447395325\n",
      "Human 3 best acc: 0.7166666388511658\n",
      "Human 4 best acc: 0.6916666626930237\n",
      "Human 5 best acc: 0.5388888716697693\n",
      "Human 7 best acc: 0.5361111164093018\n",
      "Human 8 best acc: 0.5527777671813965\n",
      "Human 9 best acc: 0.7416666746139526\n",
      "Human 10 best acc: 0.6666666865348816\n",
      "Human 11 best acc: 0.5833333134651184\n",
      "Human 12 best acc: 0.5472221970558167\n",
      "Human 13 best acc: 0.5222222208976746\n",
      "Human 14 best acc: 0.6138888597488403\n",
      "Mean acc: 0.6329364776611328\n",
      "Human 0 best acc: 0.5444444417953491\n",
      "Human 1 best acc: 0.7277777791023254\n",
      "Human 2 best acc: 0.75\n",
      "Human 3 best acc: 0.7166666388511658\n",
      "Human 4 best acc: 0.7027778029441833\n",
      "Human 5 best acc: 0.7333333492279053\n",
      "Human 6 best acc: 0.7583333253860474\n",
      "Human 8 best acc: 0.5638889074325562\n",
      "Human 9 best acc: 0.730555534362793\n",
      "Human 10 best acc: 0.675000011920929\n",
      "Human 11 best acc: 0.675000011920929\n",
      "Human 12 best acc: 0.7527777552604675\n",
      "Human 13 best acc: 0.5472221970558167\n",
      "Human 14 best acc: 0.5972222089767456\n",
      "Mean acc: 0.6767857670783997\n",
      "Human 0 best acc: 0.550000011920929\n",
      "Human 1 best acc: 0.6888889074325562\n",
      "Human 2 best acc: 0.7083333134651184\n",
      "Human 3 best acc: 0.5166666507720947\n",
      "Human 4 best acc: 0.6944444179534912\n",
      "Human 5 best acc: 0.7749999761581421\n",
      "Human 6 best acc: 0.7638888955116272\n",
      "Human 7 best acc: 0.5444444417953491\n",
      "Human 9 best acc: 0.5611110925674438\n",
      "Human 10 best acc: 0.6666666865348816\n",
      "Human 11 best acc: 0.7027778029441833\n",
      "Human 12 best acc: 0.5277777910232544\n",
      "Human 13 best acc: 0.5249999761581421\n",
      "Human 14 best acc: 0.6388888955116272\n",
      "Mean acc: 0.6331349015235901\n",
      "Human 0 best acc: 0.6805555820465088\n",
      "Human 1 best acc: 0.7222222089767456\n",
      "Human 2 best acc: 0.7277777791023254\n",
      "Human 3 best acc: 0.7222222089767456\n",
      "Human 4 best acc: 0.6833333373069763\n",
      "Human 5 best acc: 0.7416666746139526\n",
      "Human 6 best acc: 0.7472222447395325\n",
      "Human 7 best acc: 0.7194444537162781\n",
      "Human 8 best acc: 0.7055555582046509\n",
      "Human 10 best acc: 0.5944444537162781\n",
      "Human 11 best acc: 0.699999988079071\n",
      "Human 12 best acc: 0.5277777910232544\n",
      "Human 13 best acc: 0.5333333611488342\n",
      "Human 14 best acc: 0.6166666746139526\n",
      "Mean acc: 0.6730159521102905\n",
      "Human 0 best acc: 0.7166666388511658\n",
      "Human 1 best acc: 0.7083333134651184\n",
      "Human 2 best acc: 0.7805555462837219\n",
      "Human 3 best acc: 0.5583333373069763\n",
      "Human 4 best acc: 0.675000011920929\n",
      "Human 5 best acc: 0.7611111402511597\n",
      "Human 6 best acc: 0.7749999761581421\n",
      "Human 7 best acc: 0.5638889074325562\n",
      "Human 8 best acc: 0.7444444298744202\n",
      "Human 9 best acc: 0.699999988079071\n",
      "Human 11 best acc: 0.6916666626930237\n",
      "Human 12 best acc: 0.5388888716697693\n",
      "Human 13 best acc: 0.5388888716697693\n",
      "Human 14 best acc: 0.6583333611488342\n",
      "Mean acc: 0.6722221970558167\n",
      "Human 0 best acc: 0.5694444179534912\n",
      "Human 1 best acc: 0.7166666388511658\n",
      "Human 2 best acc: 0.7388888597488403\n",
      "Human 3 best acc: 0.5694444179534912\n",
      "Human 4 best acc: 0.5472221970558167\n",
      "Human 5 best acc: 0.7555555701255798\n",
      "Human 6 best acc: 0.7472222447395325\n",
      "Human 7 best acc: 0.5222222208976746\n",
      "Human 8 best acc: 0.5694444179534912\n",
      "Human 9 best acc: 0.7388888597488403\n",
      "Human 10 best acc: 0.5416666865348816\n",
      "Human 12 best acc: 0.5388888716697693\n",
      "Human 13 best acc: 0.5388888716697693\n",
      "Human 14 best acc: 0.6194444298744202\n",
      "Mean acc: 0.622420608997345\n",
      "Human 0 best acc: 0.6944444179534912\n",
      "Human 1 best acc: 0.6972222328186035\n",
      "Human 2 best acc: 0.7277777791023254\n",
      "Human 3 best acc: 0.7333333492279053\n",
      "Human 4 best acc: 0.6777777671813965\n",
      "Human 5 best acc: 0.7722222208976746\n",
      "Human 6 best acc: 0.7666666507720947\n",
      "Human 7 best acc: 0.5222222208976746\n",
      "Human 8 best acc: 0.5444444417953491\n",
      "Human 9 best acc: 0.7361111044883728\n",
      "Human 10 best acc: 0.6555555462837219\n",
      "Human 11 best acc: 0.7111111283302307\n",
      "Human 13 best acc: 0.5416666865348816\n",
      "Human 14 best acc: 0.6555555462837219\n",
      "Mean acc: 0.6740080118179321\n",
      "Human 0 best acc: 0.6833333373069763\n",
      "Human 1 best acc: 0.699999988079071\n",
      "Human 2 best acc: 0.7416666746139526\n",
      "Human 3 best acc: 0.5444444417953491\n",
      "Human 4 best acc: 0.5416666865348816\n",
      "Human 5 best acc: 0.7583333253860474\n",
      "Human 6 best acc: 0.7527777552604675\n",
      "Human 7 best acc: 0.5249999761581421\n",
      "Human 8 best acc: 0.5472221970558167\n",
      "Human 9 best acc: 0.7111111283302307\n",
      "Human 10 best acc: 0.6888889074325562\n",
      "Human 11 best acc: 0.699999988079071\n",
      "Human 12 best acc: 0.5416666865348816\n",
      "Human 14 best acc: 0.625\n",
      "Mean acc: 0.6472221612930298\n",
      "Human 0 best acc: 0.6777777671813965\n",
      "Human 1 best acc: 0.7166666388511658\n",
      "Human 2 best acc: 0.7416666746139526\n",
      "Human 3 best acc: 0.5722222328186035\n",
      "Human 4 best acc: 0.6916666626930237\n",
      "Human 5 best acc: 0.7416666746139526\n",
      "Human 6 best acc: 0.7444444298744202\n",
      "Human 7 best acc: 0.5583333373069763\n",
      "Human 8 best acc: 0.7055555582046509\n",
      "Human 9 best acc: 0.7166666388511658\n",
      "Human 10 best acc: 0.5583333373069763\n",
      "Human 11 best acc: 0.7111111283302307\n",
      "Human 12 best acc: 0.5138888955116272\n",
      "Human 13 best acc: 0.5333333611488342\n",
      "Mean acc: 0.6559524536132812\n",
      "Human 1 best acc: 0.6972222328186035\n",
      "Human 2 best acc: 0.7194444537162781\n",
      "Human 3 best acc: 0.5611110925674438\n",
      "Human 4 best acc: 0.5388888716697693\n",
      "Human 5 best acc: 0.7333333492279053\n",
      "Human 6 best acc: 0.7250000238418579\n",
      "Human 7 best acc: 0.5416666865348816\n",
      "Human 8 best acc: 0.6916666626930237\n",
      "Human 9 best acc: 0.7250000238418579\n",
      "Human 10 best acc: 0.49166667461395264\n",
      "Human 11 best acc: 0.6611111164093018\n",
      "Human 12 best acc: 0.5277777910232544\n",
      "Human 13 best acc: 0.5277777910232544\n",
      "Human 14 best acc: 0.5805555582046509\n",
      "Mean acc: 0.6230158805847168\n",
      "Human 0 best acc: 0.6666666865348816\n",
      "Human 2 best acc: 0.6861110925674438\n",
      "Human 3 best acc: 0.5333333611488342\n",
      "Human 4 best acc: 0.5305555462837219\n",
      "Human 5 best acc: 0.7472222447395325\n",
      "Human 6 best acc: 0.7027778029441833\n",
      "Human 7 best acc: 0.5583333373069763\n",
      "Human 8 best acc: 0.5416666865348816\n",
      "Human 9 best acc: 0.7277777791023254\n",
      "Human 10 best acc: 0.5277777910232544\n",
      "Human 11 best acc: 0.7083333134651184\n",
      "Human 12 best acc: 0.550000011920929\n",
      "Human 13 best acc: 0.6694444417953491\n",
      "Human 14 best acc: 0.5722222328186035\n",
      "Mean acc: 0.6230159401893616\n",
      "Human 0 best acc: 0.5638889074325562\n",
      "Human 1 best acc: 0.675000011920929\n",
      "Human 3 best acc: 0.5805555582046509\n",
      "Human 4 best acc: 0.5555555820465088\n",
      "Human 5 best acc: 0.7555555701255798\n",
      "Human 6 best acc: 0.7055555582046509\n",
      "Human 7 best acc: 0.5805555582046509\n",
      "Human 8 best acc: 0.5444444417953491\n",
      "Human 9 best acc: 0.7583333253860474\n",
      "Human 10 best acc: 0.5249999761581421\n",
      "Human 11 best acc: 0.7111111283302307\n",
      "Human 12 best acc: 0.7083333134651184\n",
      "Human 13 best acc: 0.550000011920929\n",
      "Human 14 best acc: 0.605555534362793\n",
      "Mean acc: 0.6299603581428528\n",
      "Human 0 best acc: 0.5583333373069763\n",
      "Human 1 best acc: 0.6777777671813965\n",
      "Human 2 best acc: 0.7472222447395325\n",
      "Human 4 best acc: 0.5333333611488342\n",
      "Human 5 best acc: 0.7222222089767456\n",
      "Human 6 best acc: 0.7222222089767456\n",
      "Human 7 best acc: 0.5361111164093018\n",
      "Human 8 best acc: 0.5638889074325562\n",
      "Human 9 best acc: 0.7250000238418579\n",
      "Human 10 best acc: 0.5305555462837219\n",
      "Human 11 best acc: 0.6888889074325562\n",
      "Human 12 best acc: 0.5416666865348816\n",
      "Human 13 best acc: 0.7055555582046509\n",
      "Human 14 best acc: 0.6027777791023254\n",
      "Mean acc: 0.632539689540863\n",
      "Human 0 best acc: 0.699999988079071\n",
      "Human 1 best acc: 0.675000011920929\n",
      "Human 2 best acc: 0.699999988079071\n",
      "Human 3 best acc: 0.5416666865348816\n",
      "Human 5 best acc: 0.7055555582046509\n",
      "Human 6 best acc: 0.7111111283302307\n",
      "Human 7 best acc: 0.5138888955116272\n",
      "Human 8 best acc: 0.6944444179534912\n",
      "Human 9 best acc: 0.7250000238418579\n",
      "Human 10 best acc: 0.5305555462837219\n",
      "Human 11 best acc: 0.7027778029441833\n",
      "Human 12 best acc: 0.5777778029441833\n",
      "Human 13 best acc: 0.6499999761581421\n",
      "Human 14 best acc: 0.5472221970558167\n",
      "Mean acc: 0.6410714387893677\n",
      "Human 0 best acc: 0.6888889074325562\n",
      "Human 1 best acc: 0.6944444179534912\n",
      "Human 2 best acc: 0.6833333373069763\n",
      "Human 3 best acc: 0.5388888716697693\n",
      "Human 4 best acc: 0.5305555462837219\n",
      "Human 6 best acc: 0.7333333492279053\n",
      "Human 7 best acc: 0.5361111164093018\n",
      "Human 8 best acc: 0.6777777671813965\n",
      "Human 9 best acc: 0.7250000238418579\n",
      "Human 10 best acc: 0.5444444417953491\n",
      "Human 11 best acc: 0.6972222328186035\n",
      "Human 12 best acc: 0.7027778029441833\n",
      "Human 13 best acc: 0.6527777910232544\n",
      "Human 14 best acc: 0.6166666746139526\n",
      "Mean acc: 0.644444465637207\n",
      "Human 0 best acc: 0.675000011920929\n",
      "Human 1 best acc: 0.6694444417953491\n",
      "Human 2 best acc: 0.574999988079071\n",
      "Human 3 best acc: 0.5361111164093018\n",
      "Human 4 best acc: 0.5388888716697693\n",
      "Human 5 best acc: 0.7250000238418579\n",
      "Human 7 best acc: 0.5388888716697693\n",
      "Human 8 best acc: 0.6972222328186035\n",
      "Human 9 best acc: 0.699999988079071\n",
      "Human 10 best acc: 0.5472221970558167\n",
      "Human 11 best acc: 0.6888889074325562\n",
      "Human 12 best acc: 0.5527777671813965\n",
      "Human 13 best acc: 0.6666666865348816\n",
      "Human 14 best acc: 0.5805555582046509\n",
      "Mean acc: 0.6208333969116211\n",
      "Human 0 best acc: 0.6722221970558167\n",
      "Human 1 best acc: 0.675000011920929\n",
      "Human 2 best acc: 0.7194444537162781\n",
      "Human 3 best acc: 0.5416666865348816\n",
      "Human 4 best acc: 0.550000011920929\n",
      "Human 5 best acc: 0.7222222089767456\n",
      "Human 6 best acc: 0.7194444537162781\n",
      "Human 8 best acc: 0.5444444417953491\n",
      "Human 9 best acc: 0.7527777552604675\n",
      "Human 10 best acc: 0.5444444417953491\n",
      "Human 11 best acc: 0.6861110925674438\n",
      "Human 12 best acc: 0.7333333492279053\n",
      "Human 13 best acc: 0.6666666865348816\n",
      "Human 14 best acc: 0.5972222089767456\n",
      "Mean acc: 0.6517857313156128\n",
      "Human 0 best acc: 0.6583333611488342\n",
      "Human 1 best acc: 0.675000011920929\n",
      "Human 2 best acc: 0.7055555582046509\n",
      "Human 3 best acc: 0.5666666626930237\n",
      "Human 4 best acc: 0.5333333611488342\n",
      "Human 5 best acc: 0.7361111044883728\n",
      "Human 6 best acc: 0.7250000238418579\n",
      "Human 7 best acc: 0.5583333373069763\n",
      "Human 9 best acc: 0.730555534362793\n",
      "Human 10 best acc: 0.5249999761581421\n",
      "Human 11 best acc: 0.7138888835906982\n",
      "Human 12 best acc: 0.7222222089767456\n",
      "Human 13 best acc: 0.675000011920929\n",
      "Human 14 best acc: 0.574999988079071\n",
      "Mean acc: 0.6500000357627869\n",
      "Human 0 best acc: 0.6694444417953491\n",
      "Human 1 best acc: 0.6722221970558167\n",
      "Human 2 best acc: 0.7083333134651184\n",
      "Human 3 best acc: 0.5277777910232544\n",
      "Human 4 best acc: 0.4972222149372101\n",
      "Human 5 best acc: 0.7722222208976746\n",
      "Human 6 best acc: 0.7138888835906982\n",
      "Human 7 best acc: 0.5388888716697693\n",
      "Human 8 best acc: 0.6944444179534912\n",
      "Human 10 best acc: 0.5305555462837219\n",
      "Human 11 best acc: 0.6861110925674438\n",
      "Human 12 best acc: 0.550000011920929\n",
      "Human 13 best acc: 0.6638888716697693\n",
      "Human 14 best acc: 0.5666666626930237\n",
      "Mean acc: 0.6279762387275696\n",
      "Human 0 best acc: 0.5722222328186035\n",
      "Human 1 best acc: 0.6916666626930237\n",
      "Human 2 best acc: 0.6805555820465088\n",
      "Human 3 best acc: 0.519444465637207\n",
      "Human 4 best acc: 0.5305555462837219\n",
      "Human 5 best acc: 0.7194444537162781\n",
      "Human 6 best acc: 0.7138888835906982\n",
      "Human 7 best acc: 0.550000011920929\n",
      "Human 8 best acc: 0.6777777671813965\n",
      "Human 9 best acc: 0.7361111044883728\n",
      "Human 11 best acc: 0.7083333134651184\n",
      "Human 12 best acc: 0.7611111402511597\n",
      "Human 13 best acc: 0.5611110925674438\n",
      "Human 14 best acc: 0.5888888835906982\n",
      "Mean acc: 0.6436508297920227\n",
      "Human 0 best acc: 0.6777777671813965\n",
      "Human 1 best acc: 0.7055555582046509\n",
      "Human 2 best acc: 0.6916666626930237\n",
      "Human 3 best acc: 0.5305555462837219\n",
      "Human 4 best acc: 0.5666666626930237\n",
      "Human 5 best acc: 0.7472222447395325\n",
      "Human 6 best acc: 0.6972222328186035\n",
      "Human 7 best acc: 0.5388888716697693\n",
      "Human 8 best acc: 0.675000011920929\n",
      "Human 9 best acc: 0.7472222447395325\n",
      "Human 10 best acc: 0.5333333611488342\n",
      "Human 12 best acc: 0.5361111164093018\n",
      "Human 13 best acc: 0.6777777671813965\n",
      "Human 14 best acc: 0.5944444537162781\n",
      "Mean acc: 0.6371031999588013\n",
      "Human 0 best acc: 0.6527777910232544\n",
      "Human 1 best acc: 0.6694444417953491\n",
      "Human 2 best acc: 0.6805555820465088\n",
      "Human 3 best acc: 0.5416666865348816\n",
      "Human 4 best acc: 0.5472221970558167\n",
      "Human 5 best acc: 0.7250000238418579\n",
      "Human 6 best acc: 0.7055555582046509\n",
      "Human 7 best acc: 0.5611110925674438\n",
      "Human 8 best acc: 0.6916666626930237\n",
      "Human 9 best acc: 0.5722222328186035\n",
      "Human 10 best acc: 0.5388888716697693\n",
      "Human 11 best acc: 0.6944444179534912\n",
      "Human 13 best acc: 0.5666666626930237\n",
      "Human 14 best acc: 0.5861111283302307\n",
      "Mean acc: 0.6238095164299011\n",
      "Human 0 best acc: 0.6611111164093018\n",
      "Human 1 best acc: 0.6638888716697693\n",
      "Human 2 best acc: 0.7194444537162781\n",
      "Human 3 best acc: 0.5472221970558167\n",
      "Human 4 best acc: 0.5111111402511597\n",
      "Human 5 best acc: 0.7388888597488403\n",
      "Human 6 best acc: 0.7194444537162781\n",
      "Human 7 best acc: 0.5249999761581421\n",
      "Human 8 best acc: 0.5222222208976746\n",
      "Human 9 best acc: 0.7333333492279053\n",
      "Human 10 best acc: 0.5277777910232544\n",
      "Human 11 best acc: 0.7083333134651184\n",
      "Human 12 best acc: 0.5583333373069763\n",
      "Human 14 best acc: 0.5888888835906982\n",
      "Mean acc: 0.6232142448425293\n",
      "Human 0 best acc: 0.6583333611488342\n",
      "Human 1 best acc: 0.6555555462837219\n",
      "Human 2 best acc: 0.7138888835906982\n",
      "Human 3 best acc: 0.5222222208976746\n",
      "Human 4 best acc: 0.5277777910232544\n",
      "Human 5 best acc: 0.7055555582046509\n",
      "Human 6 best acc: 0.7194444537162781\n",
      "Human 7 best acc: 0.5444444417953491\n",
      "Human 8 best acc: 0.5333333611488342\n",
      "Human 9 best acc: 0.5916666388511658\n",
      "Human 10 best acc: 0.550000011920929\n",
      "Human 11 best acc: 0.6972222328186035\n",
      "Human 12 best acc: 0.7250000238418579\n",
      "Human 13 best acc: 0.5444444417953491\n",
      "Mean acc: 0.620634913444519\n",
      "Human 1 best acc: 0.5444444417953491\n",
      "Human 2 best acc: 0.6694444417953491\n",
      "Human 3 best acc: 0.7416666746139526\n",
      "Human 4 best acc: 0.6027777791023254\n",
      "Human 5 best acc: 0.5555555820465088\n",
      "Human 6 best acc: 0.7027778029441833\n",
      "Human 7 best acc: 0.5249999761581421\n",
      "Human 8 best acc: 0.6805555820465088\n",
      "Human 9 best acc: 0.6611111164093018\n",
      "Human 10 best acc: 0.7805555462837219\n",
      "Human 11 best acc: 0.5416666865348816\n",
      "Human 12 best acc: 0.7083333134651184\n",
      "Human 13 best acc: 0.7250000238418579\n",
      "Human 14 best acc: 0.5277777910232544\n",
      "Mean acc: 0.6404762268066406\n",
      "Human 0 best acc: 0.7583333253860474\n",
      "Human 2 best acc: 0.6944444179534912\n",
      "Human 3 best acc: 0.7388888597488403\n",
      "Human 4 best acc: 0.6694444417953491\n",
      "Human 5 best acc: 0.5472221970558167\n",
      "Human 6 best acc: 0.7416666746139526\n",
      "Human 7 best acc: 0.5527777671813965\n",
      "Human 8 best acc: 0.6888889074325562\n",
      "Human 9 best acc: 0.5472221970558167\n",
      "Human 10 best acc: 0.7749999761581421\n",
      "Human 11 best acc: 0.6916666626930237\n",
      "Human 12 best acc: 0.7388888597488403\n",
      "Human 13 best acc: 0.7277777791023254\n",
      "Human 14 best acc: 0.5305555462837219\n",
      "Mean acc: 0.6716269850730896\n",
      "Human 0 best acc: 0.7638888955116272\n",
      "Human 1 best acc: 0.5722222328186035\n",
      "Human 3 best acc: 0.730555534362793\n",
      "Human 4 best acc: 0.5305555462837219\n",
      "Human 5 best acc: 0.6638888716697693\n",
      "Human 6 best acc: 0.730555534362793\n",
      "Human 7 best acc: 0.5555555820465088\n",
      "Human 8 best acc: 0.550000011920929\n",
      "Human 9 best acc: 0.5555555820465088\n",
      "Human 10 best acc: 0.7611111402511597\n",
      "Human 11 best acc: 0.6888889074325562\n",
      "Human 12 best acc: 0.7166666388511658\n",
      "Human 13 best acc: 0.7277777791023254\n",
      "Human 14 best acc: 0.5027777552604675\n",
      "Mean acc: 0.6464285850524902\n",
      "Human 0 best acc: 0.7611111402511597\n",
      "Human 1 best acc: 0.5694444179534912\n",
      "Human 2 best acc: 0.6694444417953491\n",
      "Human 4 best acc: 0.6638888716697693\n",
      "Human 5 best acc: 0.5555555820465088\n",
      "Human 6 best acc: 0.699999988079071\n",
      "Human 7 best acc: 0.5583333373069763\n",
      "Human 8 best acc: 0.5388888716697693\n",
      "Human 9 best acc: 0.5555555820465088\n",
      "Human 10 best acc: 0.7722222208976746\n",
      "Human 11 best acc: 0.5361111164093018\n",
      "Human 12 best acc: 0.7416666746139526\n",
      "Human 13 best acc: 0.7277777791023254\n",
      "Human 14 best acc: 0.5333333611488342\n",
      "Mean acc: 0.634523868560791\n",
      "Human 0 best acc: 0.7222222089767456\n",
      "Human 1 best acc: 0.5666666626930237\n",
      "Human 2 best acc: 0.6638888716697693\n",
      "Human 3 best acc: 0.7333333492279053\n",
      "Human 5 best acc: 0.6777777671813965\n",
      "Human 6 best acc: 0.7222222089767456\n",
      "Human 7 best acc: 0.5944444537162781\n",
      "Human 8 best acc: 0.6805555820465088\n",
      "Human 9 best acc: 0.574999988079071\n",
      "Human 10 best acc: 0.7666666507720947\n",
      "Human 11 best acc: 0.6805555820465088\n",
      "Human 12 best acc: 0.7277777791023254\n",
      "Human 13 best acc: 0.7333333492279053\n",
      "Human 14 best acc: 0.4972222149372101\n",
      "Mean acc: 0.6672618985176086\n",
      "Human 0 best acc: 0.7361111044883728\n",
      "Human 1 best acc: 0.5527777671813965\n",
      "Human 2 best acc: 0.5555555820465088\n",
      "Human 3 best acc: 0.75\n",
      "Human 4 best acc: 0.5583333373069763\n",
      "Human 6 best acc: 0.730555534362793\n",
      "Human 7 best acc: 0.5305555462837219\n",
      "Human 8 best acc: 0.5444444417953491\n",
      "Human 9 best acc: 0.5694444179534912\n",
      "Human 10 best acc: 0.7388888597488403\n",
      "Human 11 best acc: 0.6777777671813965\n",
      "Human 12 best acc: 0.7472222447395325\n",
      "Human 13 best acc: 0.7333333492279053\n",
      "Human 14 best acc: 0.550000011920929\n",
      "Mean acc: 0.6410714387893677\n",
      "Human 0 best acc: 0.7333333492279053\n",
      "Human 1 best acc: 0.5694444179534912\n",
      "Human 2 best acc: 0.5666666626930237\n",
      "Human 3 best acc: 0.7416666746139526\n",
      "Human 4 best acc: 0.7166666388511658\n",
      "Human 5 best acc: 0.6388888955116272\n",
      "Human 7 best acc: 0.5111111402511597\n",
      "Human 8 best acc: 0.5583333373069763\n",
      "Human 9 best acc: 0.6611111164093018\n",
      "Human 10 best acc: 0.769444465637207\n",
      "Human 11 best acc: 0.6888889074325562\n",
      "Human 12 best acc: 0.7027778029441833\n",
      "Human 13 best acc: 0.730555534362793\n",
      "Human 14 best acc: 0.5138888955116272\n",
      "Mean acc: 0.6501984000205994\n",
      "Human 0 best acc: 0.730555534362793\n",
      "Human 1 best acc: 0.6916666626930237\n",
      "Human 2 best acc: 0.5777778029441833\n",
      "Human 3 best acc: 0.7583333253860474\n",
      "Human 4 best acc: 0.5166666507720947\n",
      "Human 5 best acc: 0.6527777910232544\n",
      "Human 6 best acc: 0.7416666746139526\n",
      "Human 8 best acc: 0.6888889074325562\n",
      "Human 9 best acc: 0.6805555820465088\n",
      "Human 10 best acc: 0.7638888955116272\n",
      "Human 11 best acc: 0.7027778029441833\n",
      "Human 12 best acc: 0.7222222089767456\n",
      "Human 13 best acc: 0.7333333492279053\n",
      "Human 14 best acc: 0.4694444537162781\n",
      "Mean acc: 0.6736111044883728\n",
      "Human 0 best acc: 0.7194444537162781\n",
      "Human 1 best acc: 0.7361111044883728\n",
      "Human 2 best acc: 0.6499999761581421\n",
      "Human 3 best acc: 0.7527777552604675\n",
      "Human 4 best acc: 0.6805555820465088\n",
      "Human 5 best acc: 0.6416666507720947\n",
      "Human 6 best acc: 0.7416666746139526\n",
      "Human 7 best acc: 0.5555555820465088\n",
      "Human 9 best acc: 0.5416666865348816\n",
      "Human 10 best acc: 0.5916666388511658\n",
      "Human 11 best acc: 0.5388888716697693\n",
      "Human 12 best acc: 0.7416666746139526\n",
      "Human 13 best acc: 0.7416666746139526\n",
      "Human 14 best acc: 0.4833333194255829\n",
      "Mean acc: 0.651190459728241\n",
      "Human 0 best acc: 0.7388888597488403\n",
      "Human 1 best acc: 0.7083333134651184\n",
      "Human 2 best acc: 0.5277777910232544\n",
      "Human 3 best acc: 0.7416666746139526\n",
      "Human 4 best acc: 0.5666666626930237\n",
      "Human 5 best acc: 0.6527777910232544\n",
      "Human 6 best acc: 0.7361111044883728\n",
      "Human 7 best acc: 0.5388888716697693\n",
      "Human 8 best acc: 0.6916666626930237\n",
      "Human 10 best acc: 0.7583333253860474\n",
      "Human 11 best acc: 0.6638888716697693\n",
      "Human 12 best acc: 0.7250000238418579\n",
      "Human 13 best acc: 0.7111111283302307\n",
      "Human 14 best acc: 0.5222222208976746\n",
      "Mean acc: 0.6630952954292297\n",
      "Human 0 best acc: 0.7250000238418579\n",
      "Human 1 best acc: 0.5333333611488342\n",
      "Human 2 best acc: 0.6527777910232544\n",
      "Human 3 best acc: 0.7611111402511597\n",
      "Human 4 best acc: 0.5083333253860474\n",
      "Human 5 best acc: 0.5305555462837219\n",
      "Human 6 best acc: 0.7416666746139526\n",
      "Human 7 best acc: 0.5527777671813965\n",
      "Human 8 best acc: 0.5611110925674438\n",
      "Human 9 best acc: 0.6611111164093018\n",
      "Human 11 best acc: 0.675000011920929\n",
      "Human 12 best acc: 0.7416666746139526\n",
      "Human 13 best acc: 0.75\n",
      "Human 14 best acc: 0.5027777552604675\n",
      "Mean acc: 0.6355159878730774\n",
      "Human 0 best acc: 0.7361111044883728\n",
      "Human 1 best acc: 0.6861110925674438\n",
      "Human 2 best acc: 0.7027778029441833\n",
      "Human 3 best acc: 0.7416666746139526\n",
      "Human 4 best acc: 0.6666666865348816\n",
      "Human 5 best acc: 0.5472221970558167\n",
      "Human 6 best acc: 0.7222222089767456\n",
      "Human 7 best acc: 0.5472221970558167\n",
      "Human 8 best acc: 0.5694444179534912\n",
      "Human 9 best acc: 0.6694444417953491\n",
      "Human 10 best acc: 0.75\n",
      "Human 12 best acc: 0.7472222447395325\n",
      "Human 13 best acc: 0.7277777791023254\n",
      "Human 14 best acc: 0.5277777910232544\n",
      "Mean acc: 0.6672618985176086\n",
      "Human 0 best acc: 0.7388888597488403\n",
      "Human 1 best acc: 0.6944444179534912\n",
      "Human 2 best acc: 0.6861110925674438\n",
      "Human 3 best acc: 0.75\n",
      "Human 4 best acc: 0.5611110925674438\n",
      "Human 5 best acc: 0.574999988079071\n",
      "Human 6 best acc: 0.730555534362793\n",
      "Human 7 best acc: 0.5444444417953491\n",
      "Human 8 best acc: 0.5861111283302307\n",
      "Human 9 best acc: 0.675000011920929\n",
      "Human 10 best acc: 0.7555555701255798\n",
      "Human 11 best acc: 0.5333333611488342\n",
      "Human 13 best acc: 0.7444444298744202\n",
      "Human 14 best acc: 0.5111111402511597\n",
      "Mean acc: 0.6490079164505005\n",
      "Human 0 best acc: 0.7361111044883728\n",
      "Human 1 best acc: 0.5694444179534912\n",
      "Human 2 best acc: 0.6722221970558167\n",
      "Human 3 best acc: 0.7194444537162781\n",
      "Human 4 best acc: 0.6944444179534912\n",
      "Human 5 best acc: 0.5361111164093018\n",
      "Human 6 best acc: 0.5777778029441833\n",
      "Human 7 best acc: 0.5305555462837219\n",
      "Human 8 best acc: 0.550000011920929\n",
      "Human 9 best acc: 0.5583333373069763\n",
      "Human 10 best acc: 0.769444465637207\n",
      "Human 11 best acc: 0.5277777910232544\n",
      "Human 12 best acc: 0.7444444298744202\n",
      "Human 14 best acc: 0.5472221970558167\n",
      "Mean acc: 0.6238095164299011\n",
      "Human 0 best acc: 0.75\n",
      "Human 1 best acc: 0.6805555820465088\n",
      "Human 2 best acc: 0.5472221970558167\n",
      "Human 3 best acc: 0.730555534362793\n",
      "Human 4 best acc: 0.5777778029441833\n",
      "Human 5 best acc: 0.6777777671813965\n",
      "Human 6 best acc: 0.7222222089767456\n",
      "Human 7 best acc: 0.5388888716697693\n",
      "Human 8 best acc: 0.6777777671813965\n",
      "Human 9 best acc: 0.6916666626930237\n",
      "Human 10 best acc: 0.7611111402511597\n",
      "Human 11 best acc: 0.5611110925674438\n",
      "Human 12 best acc: 0.7027778029441833\n",
      "Human 13 best acc: 0.730555534362793\n",
      "Mean acc: 0.6678571105003357\n",
      "Human 1 best acc: 0.5444444417953491\n",
      "Human 2 best acc: 0.49166667461395264\n",
      "Human 3 best acc: 0.5361111164093018\n",
      "Human 4 best acc: 0.5138888955116272\n",
      "Human 5 best acc: 0.5166666507720947\n",
      "Human 6 best acc: 0.5638889074325562\n",
      "Human 7 best acc: 0.5055555701255798\n",
      "Human 8 best acc: 0.5222222208976746\n",
      "Human 9 best acc: 0.574999988079071\n",
      "Human 10 best acc: 0.5222222208976746\n",
      "Human 11 best acc: 0.5638889074325562\n",
      "Human 12 best acc: 0.5444444417953491\n",
      "Human 13 best acc: 0.5583333373069763\n",
      "Human 14 best acc: 0.5249999761581421\n",
      "Mean acc: 0.5345238447189331\n",
      "Human 0 best acc: 0.5388888716697693\n",
      "Human 2 best acc: 0.5166666507720947\n",
      "Human 3 best acc: 0.5527777671813965\n",
      "Human 4 best acc: 0.5277777910232544\n",
      "Human 5 best acc: 0.550000011920929\n",
      "Human 6 best acc: 0.5\n",
      "Human 7 best acc: 0.49444442987442017\n",
      "Human 8 best acc: 0.5305555462837219\n",
      "Human 9 best acc: 0.5249999761581421\n",
      "Human 10 best acc: 0.5472221970558167\n",
      "Human 11 best acc: 0.550000011920929\n",
      "Human 12 best acc: 0.5777778029441833\n",
      "Human 13 best acc: 0.5944444537162781\n",
      "Human 14 best acc: 0.5333333611488342\n",
      "Mean acc: 0.5384920835494995\n",
      "Human 0 best acc: 0.5777778029441833\n",
      "Human 1 best acc: 0.5138888955116272\n",
      "Human 3 best acc: 0.5416666865348816\n",
      "Human 4 best acc: 0.5083333253860474\n",
      "Human 5 best acc: 0.5416666865348816\n",
      "Human 6 best acc: 0.5416666865348816\n",
      "Human 7 best acc: 0.519444465637207\n",
      "Human 8 best acc: 0.5666666626930237\n",
      "Human 9 best acc: 0.5527777671813965\n",
      "Human 10 best acc: 0.5111111402511597\n",
      "Human 11 best acc: 0.574999988079071\n",
      "Human 12 best acc: 0.550000011920929\n",
      "Human 13 best acc: 0.5666666626930237\n",
      "Human 14 best acc: 0.5277777910232544\n",
      "Mean acc: 0.5424603223800659\n",
      "Human 0 best acc: 0.5722222328186035\n",
      "Human 1 best acc: 0.5361111164093018\n",
      "Human 2 best acc: 0.49166667461395264\n",
      "Human 4 best acc: 0.5472221970558167\n",
      "Human 5 best acc: 0.5361111164093018\n",
      "Human 6 best acc: 0.5388888716697693\n",
      "Human 7 best acc: 0.5666666626930237\n",
      "Human 8 best acc: 0.5083333253860474\n",
      "Human 9 best acc: 0.5305555462837219\n",
      "Human 10 best acc: 0.5527777671813965\n",
      "Human 11 best acc: 0.5388888716697693\n",
      "Human 12 best acc: 0.5666666626930237\n",
      "Human 13 best acc: 0.550000011920929\n",
      "Human 14 best acc: 0.519444465637207\n",
      "Mean acc: 0.5396825671195984\n",
      "Human 0 best acc: 0.5111111402511597\n",
      "Human 1 best acc: 0.550000011920929\n",
      "Human 2 best acc: 0.5083333253860474\n",
      "Human 3 best acc: 0.5166666507720947\n",
      "Human 5 best acc: 0.5333333611488342\n",
      "Human 6 best acc: 0.5249999761581421\n",
      "Human 7 best acc: 0.5388888716697693\n",
      "Human 8 best acc: 0.5305555462837219\n",
      "Human 9 best acc: 0.5444444417953491\n",
      "Human 10 best acc: 0.5361111164093018\n",
      "Human 11 best acc: 0.5472221970558167\n",
      "Human 12 best acc: 0.550000011920929\n",
      "Human 13 best acc: 0.5944444537162781\n",
      "Human 14 best acc: 0.5249999761581421\n",
      "Mean acc: 0.5365079641342163\n",
      "Human 0 best acc: 0.5277777910232544\n",
      "Human 1 best acc: 0.5388888716697693\n",
      "Human 2 best acc: 0.5166666507720947\n",
      "Human 3 best acc: 0.5333333611488342\n",
      "Human 4 best acc: 0.5361111164093018\n",
      "Human 6 best acc: 0.5361111164093018\n",
      "Human 7 best acc: 0.5277777910232544\n",
      "Human 8 best acc: 0.5305555462837219\n",
      "Human 9 best acc: 0.5527777671813965\n",
      "Human 10 best acc: 0.5333333611488342\n",
      "Human 11 best acc: 0.550000011920929\n",
      "Human 12 best acc: 0.5416666865348816\n",
      "Human 13 best acc: 0.574999988079071\n",
      "Human 14 best acc: 0.5166666507720947\n",
      "Mean acc: 0.5369047522544861\n",
      "Human 0 best acc: 0.5583333373069763\n",
      "Human 1 best acc: 0.5361111164093018\n",
      "Human 2 best acc: 0.5138888955116272\n",
      "Human 3 best acc: 0.5388888716697693\n",
      "Human 4 best acc: 0.5166666507720947\n",
      "Human 5 best acc: 0.5611110925674438\n",
      "Human 7 best acc: 0.5249999761581421\n",
      "Human 8 best acc: 0.550000011920929\n",
      "Human 9 best acc: 0.5305555462837219\n",
      "Human 10 best acc: 0.574999988079071\n",
      "Human 11 best acc: 0.550000011920929\n",
      "Human 12 best acc: 0.5444444417953491\n",
      "Human 13 best acc: 0.5722222328186035\n",
      "Human 14 best acc: 0.5277777910232544\n",
      "Mean acc: 0.5428571701049805\n",
      "Human 0 best acc: 0.5222222208976746\n",
      "Human 1 best acc: 0.5388888716697693\n",
      "Human 2 best acc: 0.5166666507720947\n",
      "Human 3 best acc: 0.5361111164093018\n",
      "Human 4 best acc: 0.5249999761581421\n",
      "Human 5 best acc: 0.550000011920929\n",
      "Human 6 best acc: 0.5444444417953491\n",
      "Human 8 best acc: 0.5416666865348816\n",
      "Human 9 best acc: 0.5222222208976746\n",
      "Human 10 best acc: 0.5222222208976746\n",
      "Human 11 best acc: 0.550000011920929\n",
      "Human 12 best acc: 0.574999988079071\n",
      "Human 13 best acc: 0.5888888835906982\n",
      "Human 14 best acc: 0.5333333611488342\n",
      "Mean acc: 0.5404761433601379\n",
      "Human 0 best acc: 0.5583333373069763\n",
      "Human 1 best acc: 0.5361111164093018\n",
      "Human 2 best acc: 0.5361111164093018\n",
      "Human 3 best acc: 0.5083333253860474\n",
      "Human 4 best acc: 0.5388888716697693\n",
      "Human 5 best acc: 0.5\n",
      "Human 6 best acc: 0.550000011920929\n",
      "Human 7 best acc: 0.5166666507720947\n",
      "Human 9 best acc: 0.5583333373069763\n",
      "Human 10 best acc: 0.49166667461395264\n",
      "Human 11 best acc: 0.5222222208976746\n",
      "Human 12 best acc: 0.5527777671813965\n",
      "Human 13 best acc: 0.5638889074325562\n",
      "Human 14 best acc: 0.5111111402511597\n",
      "Mean acc: 0.5317460298538208\n",
      "Human 0 best acc: 0.5527777671813965\n",
      "Human 1 best acc: 0.5333333611488342\n",
      "Human 2 best acc: 0.550000011920929\n",
      "Human 3 best acc: 0.5472221970558167\n",
      "Human 4 best acc: 0.5277777910232544\n",
      "Human 5 best acc: 0.5083333253860474\n",
      "Human 6 best acc: 0.5361111164093018\n",
      "Human 7 best acc: 0.5361111164093018\n",
      "Human 8 best acc: 0.5444444417953491\n",
      "Human 10 best acc: 0.5083333253860474\n",
      "Human 11 best acc: 0.5527777671813965\n",
      "Human 12 best acc: 0.5361111164093018\n",
      "Human 13 best acc: 0.5777778029441833\n",
      "Human 14 best acc: 0.550000011920929\n",
      "Mean acc: 0.5400794148445129\n",
      "Human 0 best acc: 0.5416666865348816\n",
      "Human 1 best acc: 0.5694444179534912\n",
      "Human 2 best acc: 0.5166666507720947\n",
      "Human 3 best acc: 0.5305555462837219\n",
      "Human 4 best acc: 0.5249999761581421\n",
      "Human 5 best acc: 0.5555555820465088\n",
      "Human 6 best acc: 0.5083333253860474\n",
      "Human 7 best acc: 0.5249999761581421\n",
      "Human 8 best acc: 0.574999988079071\n",
      "Human 9 best acc: 0.5277777910232544\n",
      "Human 11 best acc: 0.5388888716697693\n",
      "Human 12 best acc: 0.5583333373069763\n",
      "Human 13 best acc: 0.6111111044883728\n",
      "Human 14 best acc: 0.5583333373069763\n",
      "Mean acc: 0.5458332896232605\n",
      "Human 0 best acc: 0.5361111164093018\n",
      "Human 1 best acc: 0.5388888716697693\n",
      "Human 2 best acc: 0.5027777552604675\n",
      "Human 3 best acc: 0.5361111164093018\n",
      "Human 4 best acc: 0.5277777910232544\n",
      "Human 5 best acc: 0.5222222208976746\n",
      "Human 6 best acc: 0.5527777671813965\n",
      "Human 7 best acc: 0.5472221970558167\n",
      "Human 8 best acc: 0.5333333611488342\n",
      "Human 9 best acc: 0.5527777671813965\n",
      "Human 10 best acc: 0.519444465637207\n",
      "Human 12 best acc: 0.5611110925674438\n",
      "Human 13 best acc: 0.550000011920929\n",
      "Human 14 best acc: 0.5361111164093018\n",
      "Mean acc: 0.5369047522544861\n",
      "Human 0 best acc: 0.550000011920929\n",
      "Human 1 best acc: 0.5361111164093018\n",
      "Human 2 best acc: 0.5305555462837219\n",
      "Human 3 best acc: 0.5249999761581421\n",
      "Human 4 best acc: 0.5444444417953491\n",
      "Human 5 best acc: 0.5416666865348816\n",
      "Human 6 best acc: 0.4972222149372101\n",
      "Human 7 best acc: 0.5249999761581421\n",
      "Human 8 best acc: 0.5444444417953491\n",
      "Human 9 best acc: 0.5333333611488342\n",
      "Human 10 best acc: 0.5166666507720947\n",
      "Human 11 best acc: 0.5777778029441833\n",
      "Human 13 best acc: 0.5805555582046509\n",
      "Human 14 best acc: 0.519444465637207\n",
      "Mean acc: 0.5373015999794006\n",
      "Human 0 best acc: 0.5361111164093018\n",
      "Human 1 best acc: 0.5555555820465088\n",
      "Human 2 best acc: 0.5527777671813965\n",
      "Human 3 best acc: 0.550000011920929\n",
      "Human 4 best acc: 0.5083333253860474\n",
      "Human 5 best acc: 0.5249999761581421\n",
      "Human 6 best acc: 0.5305555462837219\n",
      "Human 7 best acc: 0.5166666507720947\n",
      "Human 8 best acc: 0.5666666626930237\n",
      "Human 9 best acc: 0.574999988079071\n",
      "Human 10 best acc: 0.519444465637207\n",
      "Human 11 best acc: 0.5555555820465088\n",
      "Human 12 best acc: 0.5583333373069763\n",
      "Human 14 best acc: 0.5222222208976746\n",
      "Mean acc: 0.5408729314804077\n",
      "Human 0 best acc: 0.5444444417953491\n",
      "Human 1 best acc: 0.5666666626930237\n",
      "Human 2 best acc: 0.5277777910232544\n",
      "Human 3 best acc: 0.519444465637207\n",
      "Human 4 best acc: 0.5388888716697693\n",
      "Human 5 best acc: 0.5638889074325562\n",
      "Human 6 best acc: 0.5527777671813965\n",
      "Human 7 best acc: 0.5166666507720947\n",
      "Human 8 best acc: 0.5305555462837219\n",
      "Human 9 best acc: 0.5138888955116272\n",
      "Human 10 best acc: 0.5222222208976746\n",
      "Human 11 best acc: 0.5611110925674438\n",
      "Human 12 best acc: 0.5416666865348816\n",
      "Human 13 best acc: 0.5888888835906982\n",
      "Mean acc: 0.5420634150505066\n",
      "Human 1 best acc: 0.5083333253860474\n",
      "Human 2 best acc: 0.4861111044883728\n",
      "Human 3 best acc: 0.4972222149372101\n",
      "Human 4 best acc: 0.5472221970558167\n",
      "Human 5 best acc: 0.5444444417953491\n",
      "Human 6 best acc: 0.5083333253860474\n",
      "Human 7 best acc: 0.519444465637207\n",
      "Human 8 best acc: 0.5416666865348816\n",
      "Human 9 best acc: 0.5277777910232544\n",
      "Human 10 best acc: 0.5083333253860474\n",
      "Human 11 best acc: 0.5583333373069763\n",
      "Human 12 best acc: 0.5416666865348816\n",
      "Human 13 best acc: 0.5222222208976746\n",
      "Human 14 best acc: 0.5416666865348816\n",
      "Mean acc: 0.5251983404159546\n",
      "Human 0 best acc: 0.5\n",
      "Human 2 best acc: 0.4972222149372101\n",
      "Human 3 best acc: 0.4972222149372101\n",
      "Human 4 best acc: 0.5111111402511597\n",
      "Human 5 best acc: 0.5249999761581421\n",
      "Human 6 best acc: 0.5361111164093018\n",
      "Human 7 best acc: 0.5277777910232544\n",
      "Human 8 best acc: 0.5249999761581421\n",
      "Human 9 best acc: 0.5138888955116272\n",
      "Human 10 best acc: 0.5138888955116272\n",
      "Human 11 best acc: 0.5472221970558167\n",
      "Human 12 best acc: 0.4749999940395355\n",
      "Human 13 best acc: 0.4861111044883728\n",
      "Human 14 best acc: 0.5722222328186035\n",
      "Mean acc: 0.5162698030471802\n",
      "Human 0 best acc: 0.5249999761581421\n",
      "Human 1 best acc: 0.5111111402511597\n",
      "Human 3 best acc: 0.48055556416511536\n",
      "Human 4 best acc: 0.49444442987442017\n",
      "Human 5 best acc: 0.519444465637207\n",
      "Human 6 best acc: 0.4972222149372101\n",
      "Human 7 best acc: 0.5583333373069763\n",
      "Human 8 best acc: 0.5138888955116272\n",
      "Human 9 best acc: 0.5222222208976746\n",
      "Human 10 best acc: 0.5361111164093018\n",
      "Human 11 best acc: 0.5527777671813965\n",
      "Human 12 best acc: 0.5305555462837219\n",
      "Human 13 best acc: 0.5138888955116272\n",
      "Human 14 best acc: 0.5416666865348816\n",
      "Mean acc: 0.521230161190033\n",
      "Human 0 best acc: 0.5\n",
      "Human 1 best acc: 0.4749999940395355\n",
      "Human 2 best acc: 0.5\n",
      "Human 4 best acc: 0.5222222208976746\n",
      "Human 5 best acc: 0.5333333611488342\n",
      "Human 6 best acc: 0.4888888895511627\n",
      "Human 7 best acc: 0.5527777671813965\n",
      "Human 8 best acc: 0.5027777552604675\n",
      "Human 9 best acc: 0.5249999761581421\n",
      "Human 10 best acc: 0.5055555701255798\n",
      "Human 11 best acc: 0.5222222208976746\n",
      "Human 12 best acc: 0.5138888955116272\n",
      "Human 13 best acc: 0.4861111044883728\n",
      "Human 14 best acc: 0.5444444417953491\n",
      "Mean acc: 0.5123016238212585\n",
      "Human 0 best acc: 0.5388888716697693\n",
      "Human 1 best acc: 0.5305555462837219\n",
      "Human 2 best acc: 0.5111111402511597\n",
      "Human 3 best acc: 0.5027777552604675\n",
      "Human 5 best acc: 0.5916666388511658\n",
      "Human 6 best acc: 0.4861111044883728\n",
      "Human 7 best acc: 0.5027777552604675\n",
      "Human 8 best acc: 0.5638889074325562\n",
      "Human 9 best acc: 0.5472221970558167\n",
      "Human 10 best acc: 0.5249999761581421\n",
      "Human 11 best acc: 0.5333333611488342\n",
      "Human 12 best acc: 0.49444442987442017\n",
      "Human 13 best acc: 0.5\n",
      "Human 14 best acc: 0.5611110925674438\n",
      "Mean acc: 0.5277777314186096\n",
      "Human 0 best acc: 0.5111111402511597\n",
      "Human 1 best acc: 0.5277777910232544\n",
      "Human 2 best acc: 0.5083333253860474\n",
      "Human 3 best acc: 0.46388888359069824\n",
      "Human 4 best acc: 0.5166666507720947\n",
      "Human 6 best acc: 0.4749999940395355\n",
      "Human 7 best acc: 0.5444444417953491\n",
      "Human 8 best acc: 0.5166666507720947\n",
      "Human 9 best acc: 0.5583333373069763\n",
      "Human 10 best acc: 0.4694444537162781\n",
      "Human 11 best acc: 0.5138888955116272\n",
      "Human 12 best acc: 0.5083333253860474\n",
      "Human 13 best acc: 0.48055556416511536\n",
      "Human 14 best acc: 0.5249999761581421\n",
      "Mean acc: 0.5085317492485046\n",
      "Human 0 best acc: 0.5166666507720947\n",
      "Human 1 best acc: 0.5249999761581421\n",
      "Human 2 best acc: 0.5083333253860474\n",
      "Human 3 best acc: 0.5\n",
      "Human 4 best acc: 0.5111111402511597\n",
      "Human 5 best acc: 0.5222222208976746\n",
      "Human 7 best acc: 0.5333333611488342\n",
      "Human 8 best acc: 0.5305555462837219\n",
      "Human 9 best acc: 0.5527777671813965\n",
      "Human 10 best acc: 0.5\n",
      "Human 11 best acc: 0.5416666865348816\n",
      "Human 12 best acc: 0.49444442987442017\n",
      "Human 13 best acc: 0.5027777552604675\n",
      "Human 14 best acc: 0.5611110925674438\n",
      "Mean acc: 0.5214285254478455\n",
      "Human 0 best acc: 0.5\n",
      "Human 1 best acc: 0.5027777552604675\n",
      "Human 2 best acc: 0.4694444537162781\n",
      "Human 3 best acc: 0.5277777910232544\n",
      "Human 4 best acc: 0.5444444417953491\n",
      "Human 5 best acc: 0.5388888716697693\n",
      "Human 6 best acc: 0.4972222149372101\n",
      "Human 8 best acc: 0.5277777910232544\n",
      "Human 9 best acc: 0.5138888955116272\n",
      "Human 10 best acc: 0.48055556416511536\n",
      "Human 11 best acc: 0.5249999761581421\n",
      "Human 12 best acc: 0.5\n",
      "Human 13 best acc: 0.4972222149372101\n",
      "Human 14 best acc: 0.5333333611488342\n",
      "Mean acc: 0.5113095045089722\n",
      "Human 0 best acc: 0.4861111044883728\n",
      "Human 1 best acc: 0.5388888716697693\n",
      "Human 2 best acc: 0.48055556416511536\n",
      "Human 3 best acc: 0.5055555701255798\n",
      "Human 4 best acc: 0.5361111164093018\n",
      "Human 5 best acc: 0.5388888716697693\n",
      "Human 6 best acc: 0.47777777910232544\n",
      "Human 7 best acc: 0.5472221970558167\n",
      "Human 9 best acc: 0.5277777910232544\n",
      "Human 10 best acc: 0.4749999940395355\n",
      "Human 11 best acc: 0.5305555462837219\n",
      "Human 12 best acc: 0.4722222089767456\n",
      "Human 13 best acc: 0.5305555462837219\n",
      "Human 14 best acc: 0.5305555462837219\n",
      "Mean acc: 0.5126984715461731\n",
      "Human 0 best acc: 0.4888888895511627\n",
      "Human 1 best acc: 0.5138888955116272\n",
      "Human 2 best acc: 0.519444465637207\n",
      "Human 3 best acc: 0.5305555462837219\n",
      "Human 4 best acc: 0.5305555462837219\n",
      "Human 5 best acc: 0.5055555701255798\n",
      "Human 6 best acc: 0.5249999761581421\n",
      "Human 7 best acc: 0.5416666865348816\n",
      "Human 8 best acc: 0.5361111164093018\n",
      "Human 10 best acc: 0.5138888955116272\n",
      "Human 11 best acc: 0.5\n",
      "Human 12 best acc: 0.5055555701255798\n",
      "Human 13 best acc: 0.5166666507720947\n",
      "Human 14 best acc: 0.5583333373069763\n",
      "Mean acc: 0.5204364657402039\n",
      "Human 0 best acc: 0.5027777552604675\n",
      "Human 1 best acc: 0.5\n",
      "Human 2 best acc: 0.4861111044883728\n",
      "Human 3 best acc: 0.4861111044883728\n",
      "Human 4 best acc: 0.5333333611488342\n",
      "Human 5 best acc: 0.5027777552604675\n",
      "Human 6 best acc: 0.5138888955116272\n",
      "Human 7 best acc: 0.5249999761581421\n",
      "Human 8 best acc: 0.5166666507720947\n",
      "Human 9 best acc: 0.5361111164093018\n",
      "Human 11 best acc: 0.5277777910232544\n",
      "Human 12 best acc: 0.47777777910232544\n",
      "Human 13 best acc: 0.4888888895511627\n",
      "Human 14 best acc: 0.5722222328186035\n",
      "Mean acc: 0.5121031403541565\n",
      "Human 0 best acc: 0.4972222149372101\n",
      "Human 1 best acc: 0.5138888955116272\n",
      "Human 2 best acc: 0.519444465637207\n",
      "Human 3 best acc: 0.4749999940395355\n",
      "Human 4 best acc: 0.519444465637207\n",
      "Human 5 best acc: 0.5333333611488342\n",
      "Human 6 best acc: 0.5166666507720947\n",
      "Human 7 best acc: 0.5249999761581421\n",
      "Human 8 best acc: 0.5111111402511597\n",
      "Human 9 best acc: 0.5083333253860474\n",
      "Human 10 best acc: 0.4583333432674408\n",
      "Human 12 best acc: 0.49444442987442017\n",
      "Human 13 best acc: 0.4972222149372101\n",
      "Human 14 best acc: 0.6111111044883728\n",
      "Mean acc: 0.5128968358039856\n",
      "Human 0 best acc: 0.5333333611488342\n",
      "Human 1 best acc: 0.5277777910232544\n",
      "Human 2 best acc: 0.5138888955116272\n",
      "Human 3 best acc: 0.47777777910232544\n",
      "Human 4 best acc: 0.5249999761581421\n",
      "Human 5 best acc: 0.5249999761581421\n",
      "Human 6 best acc: 0.4583333432674408\n",
      "Human 7 best acc: 0.5277777910232544\n",
      "Human 8 best acc: 0.5138888955116272\n",
      "Human 9 best acc: 0.5222222208976746\n",
      "Human 10 best acc: 0.5138888955116272\n",
      "Human 11 best acc: 0.5388888716697693\n",
      "Human 13 best acc: 0.5111111402511597\n",
      "Human 14 best acc: 0.5888888835906982\n",
      "Mean acc: 0.5198412537574768\n",
      "Human 0 best acc: 0.5111111402511597\n",
      "Human 1 best acc: 0.5138888955116272\n",
      "Human 2 best acc: 0.5361111164093018\n",
      "Human 3 best acc: 0.4888888895511627\n",
      "Human 4 best acc: 0.5333333611488342\n",
      "Human 5 best acc: 0.550000011920929\n",
      "Human 6 best acc: 0.5083333253860474\n",
      "Human 7 best acc: 0.5166666507720947\n",
      "Human 8 best acc: 0.5083333253860474\n",
      "Human 9 best acc: 0.5305555462837219\n",
      "Human 10 best acc: 0.5\n",
      "Human 11 best acc: 0.5305555462837219\n",
      "Human 12 best acc: 0.49166667461395264\n",
      "Human 14 best acc: 0.5583333373069763\n",
      "Mean acc: 0.5198413133621216\n",
      "Human 0 best acc: 0.5277777910232544\n",
      "Human 1 best acc: 0.5166666507720947\n",
      "Human 2 best acc: 0.4972222149372101\n",
      "Human 3 best acc: 0.49166667461395264\n",
      "Human 4 best acc: 0.519444465637207\n",
      "Human 5 best acc: 0.5027777552604675\n",
      "Human 6 best acc: 0.49444442987442017\n",
      "Human 7 best acc: 0.5138888955116272\n",
      "Human 8 best acc: 0.5305555462837219\n",
      "Human 9 best acc: 0.5249999761581421\n",
      "Human 10 best acc: 0.49444442987442017\n",
      "Human 11 best acc: 0.5583333373069763\n",
      "Human 12 best acc: 0.5305555462837219\n",
      "Human 13 best acc: 0.4972222149372101\n",
      "Mean acc: 0.5142857432365417\n"
     ]
    }
   ],
   "source": [
    "for em1 in range(4):\n",
    "    for em2 in range(em1+1, 4):\n",
    "        if em1 == 0 and em2 == 2:\n",
    "            continue\n",
    "        for excluded_human in range(15):\n",
    "            accs = []\n",
    "            data, labels, groups = load_dataset(\"all_features_4sec_epoch.npy\")\n",
    "            data, labels, groups = flatten_data(data, labels, groups)\n",
    "            scaler = StandardScaler()\n",
    "            data = scaler.fit_transform(data)\n",
    "            data, labels, groups = select_emotions(data, labels, groups, em1, em2)\n",
    "            indices = groups != excluded_human\n",
    "            data = data[indices]\n",
    "            labels = labels[indices]\n",
    "            groups = groups[indices]\n",
    "\n",
    "            for human_test in range(15):\n",
    "                if human_test == excluded_human:\n",
    "                    continue\n",
    "                train_data, train_labels, test_data, test_labels = train_test_split(data, labels, groups, human_test)\n",
    "                # Split data into training and testing sets\n",
    "\n",
    "                # Convert to tensors and create dataloaders\n",
    "                batch_size_train = 1024\n",
    "                batch_size_test = 1738\n",
    "\n",
    "                train_data_tensor = torch.tensor(train_data, dtype=torch.float32)\n",
    "                train_labels_tensor = torch.tensor(train_labels, dtype=torch.float32)[..., None]\n",
    "                train_dataset = TensorDataset(train_data_tensor, train_labels_tensor)\n",
    "                train_dataloader = DataLoader(train_dataset, batch_size=batch_size_train, shuffle=True)\n",
    "\n",
    "                test_data_tensor = torch.tensor(test_data, dtype=torch.float32)\n",
    "                test_labels_tensor = torch.tensor(test_labels, dtype=torch.float32)[..., None]\n",
    "                test_dataset = TensorDataset(test_data_tensor, test_labels_tensor)\n",
    "                test_dataloader = DataLoader(test_dataset, batch_size=batch_size_test, shuffle=False)\n",
    "\n",
    "                # Parameters for the autoencoder\n",
    "                lr = 0.0016801991703897096\n",
    "                input_dim = data.shape[1]\n",
    "                encoding_dim = 128  # Set the desired encoding dimension\n",
    "\n",
    "                # Initialize the autoencoder\n",
    "                autoencoder = Autoencoder(input_dim, encoding_dim)\n",
    "\n",
    "                # Initialize weights of the autoencoder\n",
    "                def init_weights(m):\n",
    "                    if type(m) == torch.nn.Linear:\n",
    "                        torch.nn.init.xavier_uniform_(m.weight)\n",
    "                        m.bias.data.fill_(0.01)\n",
    "                autoencoder.apply(init_weights)\n",
    "\n",
    "                # Loss function and optimizer\n",
    "                criterion_enc = torch.nn.MSELoss()\n",
    "                criterion_cls = torch.nn.BCELoss()\n",
    "                optimizer = optim.Adam(autoencoder.parameters(), lr=lr)\n",
    "\n",
    "                # Training loop\n",
    "                num_epochs = 50\n",
    "                best_acc = 0\n",
    "                for epoch in range(num_epochs):\n",
    "                    for data_batch, labels_batch in dataloader:\n",
    "                        optimizer.zero_grad()\n",
    "                        reconstructed, cls = autoencoder(data_batch)\n",
    "                        loss1 = criterion_cls(cls, labels_batch) * 0.1\n",
    "                        loss2 = criterion_enc(reconstructed, data_batch)\n",
    "                        loss = loss1 + loss2\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "                    \n",
    "                    with torch.no_grad():\n",
    "                        reconstructed, cls = autoencoder(data_tensor)\n",
    "                        cls = cls > 0.5\n",
    "                        train_acc = torch.sum(cls == data_labels) / data_labels.shape[0]\n",
    "                        # test acc\n",
    "\n",
    "                        reconstructed, cls = autoencoder(test_data_tensor)\n",
    "                        cls = cls > 0.5\n",
    "                        test_acc = torch.sum(cls == test_labels_tensor) / test_labels.shape[0]\n",
    "                        if epoch > 6 and test_acc < 0.5:\n",
    "                            break\n",
    "                        if test_acc > best_acc:\n",
    "                            best_acc = test_acc\n",
    "                            torch.save(autoencoder.state_dict(), f\"models/best_autoencoder_{em1}_{em2}_{excluded_human}_{human_test}.pt\")\n",
    "                            # print(f\"New best acc: {best_acc} epoch {epoch}\")\n",
    "                    # print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}, Train Acc: {train_acc.item()}, Test Acc: {test_acc.item()}')\n",
    "                print(f\"Human {human_test} best acc: {best_acc}\")\n",
    "                accs.append(best_acc)\n",
    "            print(f\"Mean acc: {np.mean(accs)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10800, 128)\n",
      "train_data: (5040, 128), test_data: (360, 128)\n"
     ]
    }
   ],
   "source": [
    "data, labels, groups = load_dataset(\"all_features_4sec_epoch.npy\")\n",
    "data, labels, groups = flatten_data(data, labels, groups)\n",
    "\n",
    "encdoed_data  = autoencoder.encode(torch.tensor(data, dtype=torch.float32)).detach().numpy()\n",
    "print(encdoed_data.shape)\n",
    "\n",
    "encoded_data = encdoed_data\n",
    "encoded_data, labels, groups = select_emotions(encoded_data, labels, groups, 0, 2)\n",
    "train_data, train_labels, test_data, test_labels = train_test_split(encoded_data, labels, groups, 0)\n",
    "\n",
    "print(f\"train_data: {train_data.shape}, test_data: {test_data.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 0.5083333333333331\n"
     ]
    }
   ],
   "source": [
    "accs = []\n",
    "for human_test in range(15):\n",
    "    knn = KNeighborsClassifier(n_neighbors=10)\n",
    "    knn.fit(train_data, train_labels)\n",
    "    pred = knn.predict(test_data)\n",
    "    acc = accuracy_score(test_labels, pred)\n",
    "    accs.append(acc)\n",
    "print(f\" {np.mean(accs)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, train_labels, test_data, test_labels = train_test(data, labels, test_subjects=[i])\n",
    "\n",
    "train_mask = np.logical_or((train_labels == 0), (train_labels == 2))\n",
    "test_mask = np.logical_or((test_labels == 0), (test_labels == 2))\n",
    "\n",
    "train_labels = train_labels[train_mask]\n",
    "train_data = train_data[train_mask]\n",
    "\n",
    "test_labels = test_labels[test_mask]\n",
    "test_data = test_data[test_mask]\n",
    "\n",
    "test_data = np.reshape(test_data, (test_data.shape[0], -1))\n",
    "train_data = np.reshape(train_data, (train_data.shape[0], -1))\n",
    "\n",
    "train_labels[train_labels == 0] = 0\n",
    "test_labels[test_labels == 0] = 0\n",
    "\n",
    "test_labels[test_labels == 2] = 1\n",
    "train_labels[train_labels == 2] = 1\n",
    "\n",
    "\n",
    "hidden_size = 500\n",
    "net = nn.Sequential(\n",
    "    nn.Linear(10*62*4, hidden_size),\n",
    "    nn.BatchNorm1d(hidden_size),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(0.5),\n",
    "    nn.Linear(hidden_size, 1),\n",
    "    nn.Sigmoid()\n",
    ").to('cuda')\n",
    "\n",
    "optimizer = torch.optim.AdamW(net.parameters(), lr=0.001, weight_decay=1e-5)\n",
    "loss_fn = nn.BCELoss()\n",
    "\n",
    "train_data = torch.tensor(train_data, dtype=torch.float32).to('cuda')\n",
    "train_labels = torch.tensor(train_labels, dtype=torch.long).to('cuda')\n",
    "test_data = torch.tensor(test_data, dtype=torch.float32)\n",
    "test_labels = torch.tensor(test_labels, dtype=torch.long)\n",
    "\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "# Create TensorDatasets for training and testing data\n",
    "train_dataset = TensorDataset(train_data, train_labels)\n",
    "test_dataset = TensorDataset(test_data, test_labels)\n",
    "\n",
    "# Create DataLoaders for training and testing data\n",
    "train_loader = DataLoader(train_dataset, batch_size=5000, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=1000, shuffle=False)\n",
    "\n",
    "\n",
    "# convert labels to one-hot encoding\n",
    "# train_labels = F.one_hot(train_labels, num_classes=4).float()\n",
    "# test_labels = F.one_hot(test_labels, num_classes=4).float()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_17444/537343080.py:4: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n",
      "  torch.nn.init.xavier_uniform(m.weight)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, loss 0.8660377264022827 train_accuracy 0.5043650793650793 test_accuracy 0.5\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [10080, 720]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 62\u001b[0m\n\u001b[1;32m     60\u001b[0m out \u001b[38;5;241m=\u001b[39m out[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, \u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mcpu() \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0.5\u001b[39m\n\u001b[1;32m     61\u001b[0m out \u001b[38;5;241m=\u001b[39m out\n\u001b[0;32m---> 62\u001b[0m train_acc \u001b[38;5;241m=\u001b[39m \u001b[43maccuracy_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_labels\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcpu\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;66;03m# acc = accuracy_score(torch.argmax(train_labels, dim=1).cpu(), torch.argmax(out, dim=1).cpu())\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;66;03m# test the model\u001b[39;00m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n",
      "File \u001b[0;32m/usr/lib/python3.12/site-packages/sklearn/utils/_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m    211\u001b[0m         )\n\u001b[1;32m    212\u001b[0m     ):\n\u001b[0;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[1;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[1;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[1;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[1;32m    223\u001b[0m     )\n",
      "File \u001b[0;32m/usr/lib/python3.12/site-packages/sklearn/metrics/_classification.py:213\u001b[0m, in \u001b[0;36maccuracy_score\u001b[0;34m(y_true, y_pred, normalize, sample_weight)\u001b[0m\n\u001b[1;32m    147\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Accuracy classification score.\u001b[39;00m\n\u001b[1;32m    148\u001b[0m \n\u001b[1;32m    149\u001b[0m \u001b[38;5;124;03mIn multilabel classification, this function computes subset accuracy:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    209\u001b[0m \u001b[38;5;124;03m0.5\u001b[39;00m\n\u001b[1;32m    210\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    212\u001b[0m \u001b[38;5;66;03m# Compute accuracy for each possible representation\u001b[39;00m\n\u001b[0;32m--> 213\u001b[0m y_type, y_true, y_pred \u001b[38;5;241m=\u001b[39m \u001b[43m_check_targets\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    214\u001b[0m check_consistent_length(y_true, y_pred, sample_weight)\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y_type\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmultilabel\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[0;32m/usr/lib/python3.12/site-packages/sklearn/metrics/_classification.py:85\u001b[0m, in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_check_targets\u001b[39m(y_true, y_pred):\n\u001b[1;32m     59\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Check that y_true and y_pred belong to the same classification task.\u001b[39;00m\n\u001b[1;32m     60\u001b[0m \n\u001b[1;32m     61\u001b[0m \u001b[38;5;124;03m    This converts multiclass or binary types to a common shape, and raises a\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[38;5;124;03m    y_pred : array or indicator matrix\u001b[39;00m\n\u001b[1;32m     84\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 85\u001b[0m     \u001b[43mcheck_consistent_length\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     86\u001b[0m     type_true \u001b[38;5;241m=\u001b[39m type_of_target(y_true, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_true\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     87\u001b[0m     type_pred \u001b[38;5;241m=\u001b[39m type_of_target(y_pred, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_pred\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/usr/lib/python3.12/site-packages/sklearn/utils/validation.py:457\u001b[0m, in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    455\u001b[0m uniques \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(lengths)\n\u001b[1;32m    456\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(uniques) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m--> 457\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    458\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound input variables with inconsistent numbers of samples: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    459\u001b[0m         \u001b[38;5;241m%\u001b[39m [\u001b[38;5;28mint\u001b[39m(l) \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m lengths]\n\u001b[1;32m    460\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [10080, 720]"
     ]
    }
   ],
   "source": [
    "net.train()\n",
    "def init_weights(m):\n",
    "    if isinstance(m, nn.Linear):\n",
    "        torch.nn.init.xavier_uniform(m.weight)\n",
    "        m.bias.data.fill_(0.01)\n",
    "net.apply(init_weights)\n",
    "model = net\n",
    "for epoch in range(100000):\n",
    "    net.train()\n",
    "    # clear cuda cache\n",
    "    torch.cuda.empty_cache()\n",
    "    optimizer.zero_grad()\n",
    "    out = net(train_data)\n",
    "    # print(f\"out: {out.shape}, train_labels: {train_labels.shape}, train_data: {train_data.shape}\")\n",
    "    loss = loss_fn(out[..., 0], train_labels.float())\n",
    "    \n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "            # Training loop with DataLoader\n",
    "    # for batch_data, batch_labels in train_loader:\n",
    "    #     batch_data, batch_labels = batch_data.to('cuda'), batch_labels.to('cuda')\n",
    "    #     optimizer.zero_grad()\n",
    "    #     out = model(batch_data)\n",
    "    #     loss = loss_fn(out[..., 0], batch_labels.float())\n",
    "    #     optimizer.step()\n",
    "        \n",
    "    #     loss.backward()\n",
    "\n",
    "    if epoch % 10 == 0:\n",
    "        out = out[..., 0].detach().cpu() > 0.5\n",
    "        out = out\n",
    "        acc = accuracy_score(train_labels.cpu(), out)\n",
    "        # acc = accuracy_score(torch.argmax(train_labels, dim=1).cpu(), torch.argmax(out, dim=1).cpu())\n",
    "        # test the model\n",
    "        with torch.no_grad():\n",
    "            out = net(test_data.to('cuda'))\n",
    "            # predicted_labels = torch.argmax(out, dim=1)\n",
    "            # test_non_one_hot = torch.argmax(test_labels, dim=1)\n",
    "            test_acc = accuracy_score(test_labels, out[..., 0].cpu() > 0.5)\n",
    "        print(f'Epoch {epoch}, loss {loss.item()} train_accuracy {acc} test_accuracy {test_acc}')\n",
    "        with torch.no_grad():\n",
    "            # Calculate training accuracy\n",
    "            # all_train_out = []\n",
    "            # for batch_data, _ in train_loader:\n",
    "            #     batch_data = batch_data.to('cuda')\n",
    "            #     out = model(batch_data)\n",
    "            #     all_train_out.append(out[..., 0].cpu())\n",
    "            # all_train_out = torch.cat(all_train_out)\n",
    "            # train_acc = accuracy_score(train_labels.cpu(), all_train_out > 0.5)\n",
    "            \n",
    "            # # Calculate validation accuracy\n",
    "            # all_test_out = []\n",
    "            # for batch_data, _ in test_loader:\n",
    "            #     batch_data = batch_data.to('cuda')\n",
    "            #     out = net(batch_data)\n",
    "            #     all_test_out.append(out[..., 0].cpu())\n",
    "            # all_test_out = torch.cat(all_test_out)\n",
    "            # val_acc = accuracy_score(test_labels, all_test_out > 0.5)\n",
    "            \n",
    "            out = out[..., 0].detach().cpu() > 0.5\n",
    "            out = out\n",
    "            train_acc = accuracy_score(train_labels.cpu(), out)\n",
    "            # acc = accuracy_score(torch.argmax(train_labels, dim=1).cpu(), torch.argmax(out, dim=1).cpu())\n",
    "            # test the model\n",
    "            with torch.no_grad():\n",
    "                out = net(test_data.to('cuda'))\n",
    "                # predicted_labels = torch.argmax(out, dim=1)\n",
    "                # test_non_one_hot = torch.argmax(test_labels, dim=1)\n",
    "                val_acc = accuracy_score(test_labels, out[..., 0].cpu() > 0.5)\n",
    "\n",
    "\n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            print(f'New best val accuracy: {best_val_acc} at epoch {epoch}')\n",
    "        \n",
    "        if epoch % 50 == 0:\n",
    "            print(f'Epoch {epoch}, loss {loss.item()}, train_acc {train_acc}, val_accuracy {val_acc}')\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # generate confusion matrix\n",
    "# net.eval()\n",
    "# with torch.no_grad():\n",
    "#     out = net(test_data.to('cuda'))\n",
    "#     predicted_labels = torch.argmax(out, dim=1)\n",
    "#     test_non_one_hot = torch.argmax(test_labels, dim=1)\n",
    "#     test_acc = accuracy_score(test_non_one_hot, predicted_labels.cpu())\n",
    "#     cm = confusion_matrix(test_non_one_hot, predicted_labels.cpu())\n",
    "#     print(f\"Test accuracy: {test_acc}\")\n",
    "#     print(cm)\n",
    "#     disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['0','1','2','3'])\n",
    "#     disp.plot()\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(trial):\n",
    "    hidden_size = trial.suggest_int('hidden_size', 100, 2000)\n",
    "    dropout_rate = trial.suggest_float('dropout_rate', 0.2, 0.7)\n",
    "    lr = trial.suggest_float('lr', 1e-5, 1e-1, log=True)\n",
    "    weight_decay = trial.suggest_float('weight_decay', 1e-8, 1e-3, log=True)\n",
    "    \n",
    "    # model = nn.Sequential(\n",
    "    #     nn.Linear(10*62*4, hidden_size*2),\n",
    "    #     nn.BatchNorm1d(hidden_size*2),\n",
    "    #     nn.LeakyReLU(),\n",
    "    #     nn.Dropout(dropout_rate),\n",
    "    #     nn.Linear(hidden_size*2, hidden_size),\n",
    "    #     nn.BatchNorm1d(hidden_size),\n",
    "    #     nn.LeakyReLU(),\n",
    "    #     nn.Dropout(dropout_rate),\n",
    "    #     nn.Linear(hidden_size, hidden_size//2),\n",
    "    #     nn.BatchNorm1d(hidden_size // 2),\n",
    "    #     nn.LeakyReLU(),\n",
    "    #     nn.Dropout(dropout_rate),\n",
    "    #     nn.Linear(hidden_size//2, 1),\n",
    "    #     nn.Sigmoid()\n",
    "    # ).to('cuda')\n",
    "\n",
    "    model = nn.Sequential(\n",
    "        nn.Linear(10*62*4, hidden_size),\n",
    "        nn.BatchNorm1d(hidden_size),\n",
    "        nn.ReLU(),\n",
    "        nn.Dropout(dropout_rate),\n",
    "        nn.Linear(hidden_size, 1),\n",
    "        nn.Sigmoid()\n",
    "    ).to('cuda')\n",
    "    model.apply(init_weights)\n",
    "\n",
    "\n",
    "    optimizer = torch.optim.AdamW(net.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "\n",
    "    \n",
    "    # optimizer = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "    return model, optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    model, optimizer = create_model(trial)\n",
    "    loss_fn = nn.BCELoss()\n",
    "    best_val_acc = 0.0\n",
    "    for epoch in range(500):    \n",
    "        model.train()\n",
    "        torch.cuda.empty_cache()\n",
    "        \n",
    "        # Training loop with DataLoader\n",
    "        # for batch_data, batch_labels in train_loader:\n",
    "        #     batch_data, batch_labels = batch_data.to('cuda'), batch_labels.to('cuda')\n",
    "        #     optimizer.zero_grad()\n",
    "        #     out = model(batch_data)\n",
    "        #     loss = loss_fn(out[..., 0], batch_labels.float())\n",
    "        #     optimizer.step()\n",
    "            \n",
    "        #     loss.backward()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        out = model(train_data)\n",
    "        # print(f\"out: {out.shape}, train_labels: {train_labels.shape}, train_data: {train_data.shape}\")\n",
    "        loss = loss_fn(out[..., 0], train_labels.float())\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        \n",
    "        # Validation step\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            # Calculate training accuracy\n",
    "            # all_train_out = []\n",
    "            # for batch_data, _ in train_loader:\n",
    "            #     batch_data = batch_data.to('cuda')\n",
    "            #     out = model(batch_data)\n",
    "            #     all_train_out.append(out[..., 0].cpu())\n",
    "            # all_train_out = torch.cat(all_train_out)\n",
    "            # train_acc = accuracy_score(train_labels.cpu(), all_train_out > 0.5)\n",
    "            \n",
    "            # # Calculate validation accuracy\n",
    "            # all_test_out = []\n",
    "            # for batch_data, _ in test_loader:\n",
    "            #     batch_data = batch_data.to('cuda')\n",
    "            #     out = net(batch_data)\n",
    "            #     all_test_out.append(out[..., 0].cpu())\n",
    "            # all_test_out = torch.cat(all_test_out)\n",
    "            # val_acc = accuracy_score(test_labels, all_test_out > 0.5)\n",
    "            \n",
    "            out = out[..., 0].detach().cpu() > 0.5\n",
    "            out = out\n",
    "            train_acc = accuracy_score(train_labels.cpu(), out)\n",
    "            # acc = accuracy_score(torch.argmax(train_labels, dim=1).cpu(), torch.argmax(out, dim=1).cpu())\n",
    "            # test the model\n",
    "            with torch.no_grad():\n",
    "                out = net(test_data.to('cuda'))\n",
    "                # predicted_labels = torch.argmax(out, dim=1)\n",
    "                # test_non_one_hot = torch.argmax(test_labels, dim=1)\n",
    "                val_acc = accuracy_score(test_labels, out[..., 0].cpu() > 0.5)\n",
    "\n",
    "\n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            print(f'New best val accuracy: {best_val_acc} at epoch {epoch}')\n",
    "        \n",
    "        if epoch % 50 == 0:\n",
    "            print(f'Epoch {epoch}, loss {loss.item()}, train_acc {train_acc}, val_accuracy {val_acc}')\n",
    "    \n",
    "    return best_val_acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-03 17:52:11,360] A new study created in memory with name: no-name-3cebeba2-b258-4cd1-a2e6-d30e84b1b15a\n",
      "/tmp/ipykernel_13991/1746426871.py:4: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n",
      "  torch.nn.init.xavier_uniform(m.weight)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best val accuracy: 0.5222222222222223 at epoch 0\n",
      "Epoch 0, loss 0.8216129541397095, train_acc 0.5001984126984127, val_accuracy 0.5222222222222223\n",
      "New best val accuracy: 0.5388888888888889 at epoch 1\n",
      "New best val accuracy: 0.5444444444444444 at epoch 7\n",
      "New best val accuracy: 0.55 at epoch 22\n",
      "New best val accuracy: 0.5583333333333333 at epoch 40\n",
      "New best val accuracy: 0.5611111111111111 at epoch 46\n",
      "Epoch 50, loss 0.8271164894104004, train_acc 0.4996031746031746, val_accuracy 0.5333333333333333\n",
      "New best val accuracy: 0.5638888888888889 at epoch 66\n",
      "Epoch 100, loss 0.8359272480010986, train_acc 0.49404761904761907, val_accuracy 0.5361111111111111\n",
      "Epoch 150, loss 0.835940420627594, train_acc 0.5007936507936508, val_accuracy 0.5333333333333333\n",
      "Epoch 200, loss 0.8274425864219666, train_acc 0.5063492063492063, val_accuracy 0.5361111111111111\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W 2024-06-03 17:52:21,781] Trial 0 failed with parameters: {'hidden_size': 1344, 'dropout_rate': 0.40195477741862107, 'lr': 0.017016176881559823, 'weight_decay': 4.692128365995673e-06} because of the following error: KeyboardInterrupt().\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/drakula/.local/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 196, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "                      ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_13991/4244170460.py\", line 49, in objective\n",
      "    out = out[..., 0].detach().cpu() > 0.5\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "KeyboardInterrupt\n",
      "[W 2024-06-03 17:52:21,782] Trial 0 failed with value None.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[44], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01moptuna\u001b[39;00m\n\u001b[1;32m      2\u001b[0m study \u001b[38;5;241m=\u001b[39m optuna\u001b[38;5;241m.\u001b[39mcreate_study(direction\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmaximize\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m \u001b[43mstudy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobjective\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBest hyperparameters: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstudy\u001b[38;5;241m.\u001b[39mbest_params\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/optuna/study/study.py:451\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    348\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21moptimize\u001b[39m(\n\u001b[1;32m    349\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    350\u001b[0m     func: ObjectiveFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    357\u001b[0m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    358\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    359\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[1;32m    360\u001b[0m \n\u001b[1;32m    361\u001b[0m \u001b[38;5;124;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    449\u001b[0m \u001b[38;5;124;03m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[1;32m    450\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 451\u001b[0m     \u001b[43m_optimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    452\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstudy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    453\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    454\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    455\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    456\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    457\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mIterable\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    458\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    459\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    460\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    461\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/optuna/study/_optimize.py:62\u001b[0m, in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     61\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m---> 62\u001b[0m         \u001b[43m_optimize_sequential\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     63\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     64\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[43m            \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     67\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     68\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     69\u001b[0m \u001b[43m            \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     70\u001b[0m \u001b[43m            \u001b[49m\u001b[43mreseed_sampler_rng\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     71\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtime_start\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     72\u001b[0m \u001b[43m            \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     74\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     75\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/optuna/study/_optimize.py:159\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[0;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[1;32m    156\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m    158\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 159\u001b[0m     frozen_trial \u001b[38;5;241m=\u001b[39m \u001b[43m_run_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    160\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    161\u001b[0m     \u001b[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[1;32m    162\u001b[0m     \u001b[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[1;32m    163\u001b[0m     \u001b[38;5;66;03m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[1;32m    164\u001b[0m     \u001b[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[1;32m    165\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m gc_after_trial:\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/optuna/study/_optimize.py:247\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    240\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShould not reach.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    242\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    243\u001b[0m     frozen_trial\u001b[38;5;241m.\u001b[39mstate \u001b[38;5;241m==\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mFAIL\n\u001b[1;32m    244\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m func_err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    245\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func_err, catch)\n\u001b[1;32m    246\u001b[0m ):\n\u001b[0;32m--> 247\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m func_err\n\u001b[1;32m    248\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m frozen_trial\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/optuna/study/_optimize.py:196\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m get_heartbeat_thread(trial\u001b[38;5;241m.\u001b[39m_trial_id, study\u001b[38;5;241m.\u001b[39m_storage):\n\u001b[1;32m    195\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 196\u001b[0m         value_or_values \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    197\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mTrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    198\u001b[0m         \u001b[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[1;32m    199\u001b[0m         state \u001b[38;5;241m=\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mPRUNED\n",
      "Cell \u001b[0;32mIn[43], line 49\u001b[0m, in \u001b[0;36mobjective\u001b[0;34m(trial)\u001b[0m\n\u001b[1;32m     29\u001b[0m model\u001b[38;5;241m.\u001b[39meval()\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m     31\u001b[0m     \u001b[38;5;66;03m# Calculate training accuracy\u001b[39;00m\n\u001b[1;32m     32\u001b[0m     \u001b[38;5;66;03m# all_train_out = []\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[38;5;66;03m# all_test_out = torch.cat(all_test_out)\u001b[39;00m\n\u001b[1;32m     47\u001b[0m     \u001b[38;5;66;03m# val_acc = accuracy_score(test_labels, all_test_out > 0.5)\u001b[39;00m\n\u001b[0;32m---> 49\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[43mout\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdetach\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcpu\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0.5\u001b[39m\n\u001b[1;32m     50\u001b[0m     out \u001b[38;5;241m=\u001b[39m out\n\u001b[1;32m     51\u001b[0m     train_acc \u001b[38;5;241m=\u001b[39m accuracy_score(train_labels\u001b[38;5;241m.\u001b[39mcpu(), out)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=50, n_jobs=1)\n",
    "\n",
    "\n",
    "print(f'Best hyperparameters: {study.best_params}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
